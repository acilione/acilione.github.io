{"mappings":"A,I,E,C,C,A,C,I,O,Y,A,I,O,M,K,E,A,W,I,E,C,Q,C,C,EGAA,EAAA,OAAA,cAAA,CAAA,EAAA,OAAA,wBAAA,CAAA,EAAA,OAAA,mBAAA,CAAA,EAAA,OAAA,SAAA,CAAA,cAAA,CAAAuW,EAAA,CAAA,EAAA,EAAA,CAAA,MAAA,IAAAE,GAAA,MAAA,IAAAC,GAAA,OAAA,IAAApV,GAAA,OAAA,IAAAqV,GAAA,SAAA,IAAAC,GAAA,aAAA,IAAAC,GAAA,UAAA,IAAAC,GAAA,SAAA,IAAAC,EAAA,YAAA,IAAAC,EAAA,MAAA,IAAA5U,GAAA,OAAA,IAAAE,GAAA,QAAA,IAAAE,GAAA,MAAA,IAAAE,GAAA,YAAA,IAAAE,GAAA,OAAA,IAAAE,GAAA,WAAA,IAAAE,GAAA,IAAA,IAAAE,GAAA,WAAA,IAAAE,EAAAA,EAAA,IAAA,IAAA,KAAA,EAAA,EAAAmT,EAAA,EAAA,CAAA,IAAA,CAAA,CAAA,EAAA,CAAA,WAAA,CAAA,CAAA,GCKO,SAASS,IACd,MAAO,CACL,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,WAAY,KACZ,IAAK,CAAA,EACL,MAAO,KACP,SAAU,CAAA,EACV,SAAU,KACV,OAAQ,CAAA,EACR,UAAW,KACX,WAAY,IACd,CACF,CDlBA,EAAA,OAAA,CAAA,AAAA,CAAA,CAAA,EAAA,EAAA,EAAA,KAAA,GAAA,GAAA,AAAA,UAAA,OAAA,GAAA,AAAA,YAAA,OAAA,EAAA,IAAA,IAAA,KAAA,EAAA,GAAA,AAAA,EAAA,IAAA,CAAA,EAAA,IAAA,AAAA,KAAA,IAAA,GAAA,EAAA,EAAA,EAAA,CAAA,IAAA,IAAA,CAAA,CAAA,EAAA,CAAA,WAAA,CAAA,CAAA,EAAA,EAAA,EAAA,EAAA,GAAA,EAAA,UAAA,AAAA,GAAA,OAAA,CAAA,CAAA,EAAA,EAAA,CAAA,EAAA,aAAA,CAAA,MAAA,CAAA,CAAA,GAAAT,GCoBO,IAAIQ,EAAqCC,ICpB1CI,EAAW,CAAE,KAAM,IAAM,IAAK,EAEpC,SAASC,EAAKC,CAAAA,CAAwBC,EAAM,EAAA,EAC1C,IAAI5S,EAAS,AAAiB,UAAjB,OAAO2S,EAAqBA,EAAQA,EAAM,MAAA,CACjDE,EAAM,CACV,QAAS,CAAClC,EAAuBmC,KAC/B,IAAIC,EAAY,AAAe,UAAf,OAAOD,EAAmBA,EAAMA,EAAI,MAAA,CACpD,OAAAC,EAAYA,EAAU,OAAA,CAAQzI,EAAM,KAAA,CAAO,MAC3CtK,EAASA,EAAO,OAAA,CAAQ2Q,EAAMoC,GACvBF,CACT,EACA,SAAU,IACD,IAAI,OAAO7S,EAAQ4S,EAE9B,EACA,OAAOC,CACT,CAEO,IAAMvI,EAAQ,CACnB,iBAAkB,yBAClB,kBAAmB,cACnB,uBAAwB,gBACxB,eAAgB,OAChB,WAAY,KACZ,kBAAmB,KACnB,gBAAiB,KACjB,aAAc,OACd,kBAAmB,MACnB,cAAe,MACf,oBAAqB,OACrB,UAAW,WACX,gBAAiB,oBACjB,gBAAiB,WACjB,wBAAyB,iCACzB,yBAA0B,mBAC1B,gBAAiB,OACjB,mBAAoB,0BACpB,WAAY,cACZ,gBAAiB,eACjB,QAAS,SACT,aAAc,WACd,eAAgB,OAChB,gBAAiB,aACjB,kBAAmB,YACnB,gBAAiB,YACjB,iBAAkB,aAClB,eAAgB,YAChB,UAAW,QACX,QAAS,UACT,kBAAmB,iCACnB,gBAAiB,mCACjB,kBAAmB,KACnB,gBAAiB,KACjB,kBAAmB,gCACnB,oBAAqB,gBACrB,WAAY,UACZ,cAAe,WACf,mBAAoB,oDACpB,sBAAuB,qDACvB,aAAc,6CACd,MAAO,eACP,cAAe,OACf,SAAU,MACV,UAAW,MACX,UAAW,QACX,eAAgB,WAChB,UAAW,SACX,cAAe,OACf,cAAe,MACf,cAAgB0I,AAAAA,GAAiB,AAAI,OAAO,CAAA,QAAA,EAAWA,EAAI,4BAAA,CAA+B,EAC1F,gBAAkBC,AAAAA,GAAmB,AAAI,OAAO,CAAA,KAAA,EAAQ,KAAK,GAAA,CAAI,EAAGA,EAAS,GAAE,kDAAA,CAAqD,EACpI,QAAUA,AAAAA,GAAmB,AAAI,OAAO,CAAA,KAAA,EAAQ,KAAK,GAAA,CAAI,EAAGA,EAAS,GAAE,kDAAA,CAAoD,EAC3H,iBAAmBA,AAAAA,GAAmB,AAAI,OAAO,CAAA,KAAA,EAAQ,KAAK,GAAA,CAAI,EAAGA,EAAS,GAAE,eAAA,CAAiB,EACjG,kBAAoBA,AAAAA,GAAmB,AAAI,OAAO,CAAA,KAAA,EAAQ,KAAK,GAAA,CAAI,EAAGA,EAAS,GAAE,EAAA,CAAI,EACrF,eAAiBA,AAAAA,GAAmB,AAAI,OAAO,CAAA,KAAA,EAAQ,KAAK,GAAA,CAAI,EAAGA,EAAS,GAAE,kBAAA,CAAA,CAAsB,IACtG,EASM7N,EAAK,qEAEL+N,EAAS,wBACTC,EAAe,iKACf9N,EAAWoN,EAAKU,GACnB,OAAA,CAAQ,QAASD,GACjB,OAAA,CAAQ,aAAc,qBACtB,OAAA,CAAQ,UAAW,yBACnB,OAAA,CAAQ,cAAe,WACvB,OAAA,CAAQ,WAAY,gBACpB,OAAA,CAAQ,QAAS,qBACjB,OAAA,CAAQ,WAAY,IACpB,QAAA,GACGE,EAAcX,EAAKU,GACtB,OAAA,CAAQ,QAASD,GACjB,OAAA,CAAQ,aAAc,qBACtB,OAAA,CAAQ,UAAW,yBACnB,OAAA,CAAQ,cAAe,WACvB,OAAA,CAAQ,WAAY,gBACpB,OAAA,CAAQ,QAAS,qBACjB,OAAA,CAAQ,SAAU,qCAClB,QAAA,GACGG,EAAa,uFAEbE,EAAc,mCACdvO,EAAMyN,EAAK,+GACd,OAAA,CAAQ,QAASc,GACjB,OAAA,CAAQ,QAAS,gEACjB,QAAA,GAEGjO,EAAOmN,EAAK,wCACf,OAAA,CAAQ,QAASS,GACjB,QAAA,GAEGM,EAAO,gWAMPC,EAAW,gCACXrO,EAAOqN,EACX,4dASK,KACJ,OAAA,CAAQ,UAAWgB,GACnB,OAAA,CAAQ,MAAOD,GACf,OAAA,CAAQ,YAAa,4EACrB,QAAA,GAEGhO,EAAYiN,EAAKY,GACpB,OAAA,CAAQ,KAAMlO,GACd,OAAA,CAAQ,UAAW,yBACnB,OAAA,CAAQ,YAAa,IACrB,OAAA,CAAQ,SAAU,IAClB,OAAA,CAAQ,aAAc,WACtB,OAAA,CAAQ,SAAU,kDAClB,OAAA,CAAQ,OAAQ,0BAChB,OAAA,CAAQ,OAAQ,+DAChB,OAAA,CAAQ,MAAOqO,GACf,QAAA,GAUGE,EAAc,CAClB,WATiBjB,EAAK,2CACrB,OAAA,CAAQ,YAAajN,GACrB,QAAA,GAQD,KAjFgB,wDAkFhB,IAAAR,EACA,OAlFa,8GAmFb,QAjFc,uCAkFd,GAAAG,EACA,KAAAC,EACA,SAAAC,EACA,KAAAC,EACA,QA1Fc,uBA2Fd,UAAAE,EACA,MAAOgN,EACP,KAnEgB,SAoElB,EAQMmB,EAAWlB,EACf,+JAGC,OAAA,CAAQ,KAAMtN,GACd,OAAA,CAAQ,UAAW,yBACnB,OAAA,CAAQ,aAAc,WACtB,OAAA,CAAQ,OAAQ,0BAChB,OAAA,CAAQ,SAAU,kDAClB,OAAA,CAAQ,OAAQ,0BAChB,OAAA,CAAQ,OAAQ,+DAChB,OAAA,CAAQ,MAAOqO,GACf,QAAA,GAEGI,EAAsC,CAC1C,GAAGF,CAAAA,CACH,SAAUN,EACV,MAAOO,EACP,UAAWlB,EAAKY,GACb,OAAA,CAAQ,KAAMlO,GACd,OAAA,CAAQ,UAAW,yBACnB,OAAA,CAAQ,YAAa,IACrB,OAAA,CAAQ,QAASwO,GACjB,OAAA,CAAQ,aAAc,WACtB,OAAA,CAAQ,SAAU,kDAClB,OAAA,CAAQ,OAAQ,0BAChB,OAAA,CAAQ,OAAQ,+DAChB,OAAA,CAAQ,MAAOH,GACf,QAAA,EACL,EAMMK,EAA2C,CAC/C,GAAGH,CAAAA,CACH,KAAMjB,EACJ,CAAA,sIAAA,CAEwE,EACvE,OAAA,CAAQ,UAAWgB,GACnB,OAAA,CAAQ,OAAQ,qKAIhB,QAAA,GACH,IAAK,oEACL,QAAS,yBACT,OAAQjB,EACR,SAAU,mCACV,UAAWC,EAAKY,GACb,OAAA,CAAQ,KAAMlO,GACd,OAAA,CAAQ,UAAW,CF5OxB;AE4OwB,CAAA,CAAiB,EACpC,OAAA,CAAQ,WAAYE,GACpB,OAAA,CAAQ,SAAU,IAClB,OAAA,CAAQ,aAAc,WACtB,OAAA,CAAQ,UAAW,IACnB,OAAA,CAAQ,QAAS,IACjB,OAAA,CAAQ,QAAS,IACjB,OAAA,CAAQ,OAAQ,IAChB,QAAA,EACL,EAQMsC,EAAK,wBAILoM,EAAe,gBACfC,EAAsB,kBACtBC,EAAyB,mBACzB9L,EAAcsK,EAAK,wBAAyB,KAC/C,OAAA,CAAQ,cAAeuB,GAAqB,QAAA,GAGzCE,EAA0B,qBAK1BxM,EAAY+K,EAAK,iBAAkB,KACtC,OAAA,CAAQ,OAAQ,2GAChB,OAAA,CAAQ,OAAQ,iCAChB,OAAA,CAAQ,OAAQ,kBAChB,QAAA,GAEG4B,EAAqB,gEAErBxM,EAAiB4K,EAAK4B,EAAoB,KAC7C,OAAA,CAAQ,SAAUN,GAClB,QAAA,GAEGO,EAAoB7B,EAAK4B,EAAoB,KAChD,OAAA,CAAQ,SAAUH,GAClB,QAAA,GAEGK,EACJ,wQASIzM,EAAoB2K,EAAK8B,EAAuB,MACnD,OAAA,CAAQ,iBAAkBN,GAC1B,OAAA,CAAQ,cAAeD,GACvB,OAAA,CAAQ,SAAUD,GAClB,QAAA,GAEGS,EAAuB/B,EAAK8B,EAAuB,MACtD,OAAA,CAAQ,iBApC+B,0BAqCvC,OAAA,CAAQ,cAtC4B,wBAuCpC,OAAA,CAAQ,SAAUL,GAClB,QAAA,GAGGnM,EAAoB0K,EACxB,mNAMiC,MAChC,OAAA,CAAQ,iBAAkBwB,GAC1B,OAAA,CAAQ,cAAeD,GACvB,OAAA,CAAQ,SAAUD,GAClB,QAAA,GAEGvM,EAAiBiL,EAAK,YAAa,MACtC,OAAA,CAAQ,SAAUsB,GAClB,QAAA,GAEGtM,EAAWgL,EAAK,uCACnB,OAAA,CAAQ,SAAU,gCAClB,OAAA,CAAQ,QAAS,gJACjB,QAAA,GAEGgC,EAAiBhC,EAAKgB,GAAU,OAAA,CAAQ,eAAa,UAAO,QAAA,GAC5DnL,EAAMmK,EACV,4JAMC,OAAA,CAAQ,UAAWgC,GACnB,OAAA,CAAQ,YAAa,+EACrB,QAAA,GAEGC,EAAe,wEAEfzM,EAAOwK,EAAK,qEACf,OAAA,CAAQ,QAASiC,GACjB,OAAA,CAAQ,OAAQ,2CAChB,OAAA,CAAQ,QAAS,+DACjB,QAAA,GAEGtM,EAAUqK,EAAK,2BAClB,OAAA,CAAQ,QAASiC,GACjB,OAAA,CAAQ,MAAOnB,GACf,QAAA,GAEGrL,EAASuK,EAAK,yBACjB,OAAA,CAAQ,MAAOc,GACf,QAAA,GAEGlL,EAAgBoK,EAAK,wBAAyB,KACjD,OAAA,CAAQ,UAAWrK,GACnB,OAAA,CAAQ,SAAUF,GAClB,QAAA,GAEGyM,EAA2B,qCAM3BC,GAAe,CACnB,WAAYpC,EACZ,eAAAhL,EACA,SAAAC,EACA,UAAAC,EACA,GAAAC,EACA,KA5HiB,sCA6HjB,IAAK6K,EACL,eAAA3K,EACA,kBAAAC,EACA,kBAAAC,EACA,OAlIa,8CAmIb,KAAAE,EACA,OAAAC,EACA,YAAAC,EACA,QAAAC,EACA,cAAAC,EACA,IAAAC,EACA,KAtIiB,8EAuIjB,IAAKkK,CACP,EAQMqC,GAA6C,CACjD,GAAGD,EAAAA,CACH,KAAMnC,EAAK,2BACR,OAAA,CAAQ,QAASiC,GACjB,QAAA,GACH,QAASjC,EAAK,iCACX,OAAA,CAAQ,QAASiC,GACjB,QAAA,EACL,EAMMI,GAAwC,CAC5C,GAAGF,EAAAA,CACH,kBAAmBJ,EACnB,eAAgBF,EAChB,IAAK7B,EAAK,kEACP,OAAA,CAAQ,WAAYkC,GACpB,OAAA,CAAQ,QAAS,6EACjB,QAAA,GACH,WAAY,6EACZ,IAAK,0EACL,KAAMlC,EAAK,uNACR,OAAA,CAAQ,WAAYkC,GACpB,QAAA,EACL,EAMMI,GAA2C,CAC/C,GAAGD,EAAAA,CACH,GAAIrC,EAAK9K,GAAI,OAAA,CAAQ,OAAQ,KAAK,QAAA,GAClC,KAAM8K,EAAKqC,GAAU,IAAI,EACtB,OAAA,CAAQ,OAAQ,iBAChB,OAAA,CAAQ,UAAW,KACnB,QAAA,EACL,EAMahK,GAAQ,CACnB,OAAQ4I,EACR,IAAKE,EACL,SAAUC,CACZ,EAEaxI,GAAS,CACpB,OAAQuJ,GACR,IAAKE,GACL,OAAQC,GACR,SAAUF,EACZ,EClcMG,GAAkD,CACtD,IAAK,QACL,IAAK,OACL,IAAK,OACL,IAAK,SACL,IAAK,OACP,EACMC,GAAwBC,AAAAA,GAAeF,EAAAA,CAAmBE,EAAE,CAE3D,SAASlN,GAAO5C,CAAAA,CAAc+P,CAAAA,EACnC,GAAIA,EACF,CAAA,GAAI9K,EAAM,UAAA,CAAW,IAAA,CAAKjF,GACxB,OAAOA,EAAK,OAAA,CAAQiF,EAAM,aAAA,CAAe4K,GAD3C,MAC+D,GAG3D5K,EAAM,kBAAA,CAAmB,IAAA,CAAKjF,GAChC,OAAOA,EAAK,OAAA,CAAQiF,EAAM,qBAAA,CAAuB4K,IAIrD,OAAO7P,CACT,CAgBO,SAASgQ,GAASjL,CAAAA,EACvB,GAAI,CACFA,EAAO,UAAUA,GAAM,OAAA,CAAQE,EAAM,aAAA,CAAe,IACtD,CAAA,KAAQ,CACN,OAAO,IACT,CACA,OAAOF,CACT,CAEO,SAASkL,GAAWC,CAAAA,CAAkBC,CAAAA,EAG3C,IAaEK,EAAQJ,AAbEF,EAAS,OAAA,CAAQjL,EAAM,QAAA,CAAU,CAACY,EAAOwK,EAAQC,KACzD,IAAIzH,EAAU,CAAA,EACV0H,EAAOF,EACX,KAAO,EAAEE,GAAQ,GAAKD,AAAc,OAAdA,CAAAA,CAAIC,EAAI,EAAY1H,EAAU,CAACA,EACrD,OAAIA,EAGK,IAGA,IAEX,GACY,KAAA,CAAM5D,EAAM,SAAS,EAC/BpK,EAAI,EAUR,GAPK2V,CAAAA,CAAM,EAAC,CAAE,IAAA,IACZA,EAAM,KAAA,GAEJA,EAAM,MAAA,CAAS,GAAK,CAACA,EAAM,EAAA,CAAG,KAAK,QACrCA,EAAM,GAAA,GAGJL,EACF,GAAIK,EAAM,MAAA,CAASL,EACjBK,EAAM,MAAA,CAAOL,QAEb,KAAOK,EAAM,MAAA,CAASL,GAAOK,EAAM,IAAA,CAAK,IAI5C,KAAO3V,EAAI2V,EAAM,MAAA,CAAQ3V,IAEvB2V,CAAAA,CAAM3V,EAAC,CAAI2V,CAAAA,CAAM3V,EAAC,CAAE,IAAA,GAAO,OAAA,CAAQoK,EAAM,SAAA,CAAW,KAEtD,OAAOuL,CACT,CAUO,SAASC,GAAMH,CAAAA,CAAanK,CAAAA,CAAWuK,CAAAA,EAC5C,IAAMvW,EAAImW,EAAI,MAAA,CACd,GAAInW,AAAM,IAANA,EACF,MAAO,GAIT,IAAIwW,EAAU,EAGd,KAAOA,EAAUxW,GAAG,CAClB,IAAMyW,EAAWN,EAAI,MAAA,CAAOnW,EAAIwW,EAAU,GAC1C,GAAIC,IAAazK,GAAMuK,EACrBC,GACSC,IAAazK,GAAKuK,EAC3BC,SAEA,WAJAA,GAMJ,CAEA,OAAOL,EAAI,KAAA,CAAM,EAAGnW,EAAIwW,EAC1B,CChHA,SAASG,GAAWC,CAAAA,CAAelO,CAAAA,CAA2CwC,CAAAA,CAAajN,CAAAA,CAAeoN,CAAAA,EACxG,IAAMT,EAAOlC,EAAK,IAAA,CACZmC,EAAQnC,EAAK,KAAA,EAAS,KACtBvC,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQvL,EAAM,KAAA,CAAM,iBAAA,CAAmB,KAE3DpN,CAAAA,EAAM,KAAA,CAAM,MAAA,CAAS,CAAA,EACrB,IAAM4Y,EAAoC,CACxC,KAAMD,AAAqB,MAArBA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAO,GAAa,QAAU,OAC3C,IAAA1L,EACA,KAAAN,EACA,MAAAC,EACA,KAAA1E,EACA,OAAQlI,EAAM,YAAA,CAAakI,EAC7B,EACA,OAAAlI,EAAM,KAAA,CAAM,MAAA,CAAS,CAAA,EACd4Y,CACT,CAiCO,IAAMlE,GAAN,MACL,OACA,AAAA,CAAA,KACA,AAAA,CAAA,KAEA,AAAA,aAAYtU,CAAAA,CAAuD,CACjE,IAAA,CAAK,OAAA,CAAUA,GAAWuU,CAC5B,CAEA,MAAM5D,CAAAA,CAAuC,CAC3C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,OAAA,CAAQ,IAAA,CAAK5H,GAC1C,GAAI4H,GAAOA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAS,EACzB,MAAO,CACL,KAAM,QACN,IAAKA,CAAAA,CAAI,EACX,AAAA,CAEJ,CAEA,KAAK5H,CAAAA,CAAsC,CACzC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,IAAA,CAAK,IAAA,CAAK5H,GACvC,GAAI4H,EAAK,CACP,IAAMzQ,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,gBAAA,CAAkB,IAC/D,MAAO,CACL,KAAM,OACN,IAAKA,CAAAA,CAAI,EAAC,CACV,eAAgB,WAChB,KAAO,IAAA,CAAK,OAAA,CAAQ,QAAA,CAEhBzQ,EADAmQ,GAAMnQ,EAAM;AAAA,CAAI,CAEtB,CACF,CACF,CAEA,OAAO6I,CAAAA,CAAsC,CAC3C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,CAAO,IAAA,CAAK5H,GACzC,GAAI4H,EAAK,CACP,IAAM1L,EAAM0L,CAAAA,CAAI,EAAC,CACXzQ,EAAOjF,AArEnB,SAAgCgK,CAAAA,CAAa/E,CAAAA,CAAckF,CAAAA,EACzD,IAAMyL,EAAoB5L,EAAI,KAAA,CAAMG,EAAM,KAAA,CAAM,sBAAsB,EAEtE,GAAIyL,AAAsB,OAAtBA,EACF,OAAO3Q,EAGT,IAAM4Q,EAAeD,CAAAA,CAAkB,EAAC,CAExC,OAAO3Q,EACJ,KAAA,CAAM;AAAA,CAAI,EACV,GAAA,CAAI6Q,AAAAA,IACH,IAAMC,EAAoBD,EAAK,KAAA,CAAM3L,EAAM,KAAA,CAAM,cAAc,EAC/D,GAAI4L,AAAsB,OAAtBA,EACF,OAAOD,EAGT,GAAM,CAACE,EAAY,CAAID,EAEvB,OAAIC,EAAa,MAAA,EAAUH,EAAa,MAAA,CAC/BC,EAAK,KAAA,CAAMD,EAAa,MAAM,EAGhCC,CACT,GACC,IAAA,CAAK;AAAA,CAAI,CACd,EA2C0C9L,EAAK0L,CAAAA,CAAI,EAAC,EAAK,GAAI,IAAA,CAAK,KAAK,EAEjE,MAAO,CACL,KAAM,OACN,IAAA1L,EACA,KAAM0L,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,IAAA,GAAO,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAgB,MAAQA,CAAAA,CAAI,EAAC,CACpF,KAAAzQ,CACF,CACF,CACF,CAEA,QAAQ6I,CAAAA,CAAyC,CAC/C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,OAAA,CAAQ,IAAA,CAAK5H,GAC1C,GAAI4H,EAAK,CACP,IAAIzQ,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,IAAA,GAGlB,GAAI,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAAW,IAAA,CAAKzQ,GAAO,CAC1C,IAAMgR,EAAUb,GAAMnQ,EAAM,IACxB,CAAA,CAAA,IAAA,CAAK,OAAA,CAAQ,QAAA,EAEN,CAACgR,GAAW,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKA,EAAAA,GAE3DhR,CAAAA,EAAOgR,EAAQ,IAAA,EAAA,CAEnB,CAEA,MAAO,CACL,KAAM,UACN,IAAKP,CAAAA,CAAI,EAAC,CACV,MAAOA,CAAAA,CAAI,EAAC,CAAE,MAAA,CACd,KAAAzQ,EACA,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOA,EAC5B,CACF,CACF,CAEA,GAAG6I,CAAAA,CAAoC,CACrC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,EAAA,CAAG,IAAA,CAAK5H,GACrC,GAAI4H,EACF,MAAO,CACL,KAAM,KACN,IAAKN,GAAMM,CAAAA,CAAI,EAAC,CAAG;AAAA,CAAI,CACzB,CAEJ,CAEA,WAAW5H,CAAAA,CAA4C,CACrD,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAAW,IAAA,CAAK5H,GAC7C,GAAI4H,EAAK,CACP,IAAIQ,EAAQd,GAAMM,CAAAA,CAAI,EAAC,CAAG;AAAA,CAAI,EAAE,KAAA,CAAM;AAAA,CAAI,EACtC1L,EAAM,GACN/E,EAAO,GACLgF,EAAkB,EAAC,CAEzB,KAAOiM,EAAM,MAAA,CAAS,GAAG,CACvB,IAAIC,EAAe,CAAA,EACbC,EAAe,EAAC,CAElB5W,EACJ,IAAKA,EAAI,EAAGA,EAAI0W,EAAM,MAAA,CAAQ1W,IAE5B,GAAI,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAK0W,CAAAA,CAAM1W,EAAE,EAChD4W,EAAa,IAAA,CAAKF,CAAAA,CAAM1W,EAAE,EAC1B2W,EAAe,CAAA,OAAA,GACLA,EAGV,WAFAC,EAAa,IAAA,CAAKF,CAAAA,CAAM1W,EAAE,EAK9B0W,EAAQA,EAAM,KAAA,CAAM1W,GAEpB,IAAM6W,EAAaD,EAAa,IAAA,CAAK;AAAA,CAAI,EACnCE,EAAcD,EAEjB,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,uBAAA,CAAyB;AAAA,MAAA,CAAU,EAC5D,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,wBAAA,CAA0B,GACtDrM,CAAAA,EAAMA,EAAM,CAAA,EAAGA;AAAG,EAAKqM,EAAAA,CAAU,CAAKA,EACtCpR,EAAOA,EAAO,CAAA,EAAGA;AAAI,EAAKqR,EAAAA,CAAW,CAAKA,EAI1C,IAAMrL,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,GAAA,CAM7B,GALA,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,GAAA,CAAM,CAAA,EACvB,IAAA,CAAK,KAAA,CAAM,WAAA,CAAYqL,EAAarM,EAAQ,CAAA,GAC5C,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,GAAA,CAAMgB,EAGnBiL,AAAiB,IAAjBA,EAAM,MAAA,CACR,MAGF,IAAMK,EAAYtM,EAAO,EAAA,CAAG,IAE5B,GAAIsM,GAAW,OAAS,OAEtB,MACK,GAAIA,GAAW,OAAS,aAAc,CAE3C,IACME,EAAUD,AADCD,EACQ,GAAA,CAAM;AAAA,CAAA,CAAOL,EAAM,IAAA,CAAK;AAAA,CAAI,EAC/CQ,EAAW,IAAA,CAAK,UAAA,CAAWD,EACjCxM,CAAAA,CAAAA,CAAOA,EAAO,MAAA,CAAS,EAAC,CAAIyM,EAE5B1M,EAAMA,EAAI,SAAA,CAAU,EAAGA,EAAI,MAAA,CAASwM,AALnBD,EAK4B,GAAA,CAAI,MAAM,EAAIG,EAAS,GAAA,CACpEzR,EAAOA,EAAK,SAAA,CAAU,EAAGA,EAAK,MAAA,CAASuR,AANtBD,EAM+B,IAAA,CAAK,MAAM,EAAIG,EAAS,IAAA,CACxE,KACF,CAAA,GAAWH,GAAW,OAAS,OAAQ,CAErC,IACME,EAAUD,AADCD,EACQ,GAAA,CAAM;AAAA,CAAA,CAAOL,EAAM,IAAA,CAAK;AAAA,CAAI,EAC/CQ,EAAW,IAAA,CAAK,IAAA,CAAKD,EAC3BxM,CAAAA,CAAAA,CAAOA,EAAO,MAAA,CAAS,EAAC,CAAIyM,EAE5B1M,EAAMA,EAAI,SAAA,CAAU,EAAGA,EAAI,MAAA,CAASuM,EAAU,GAAA,CAAI,MAAM,EAAIG,EAAS,GAAA,CACrEzR,EAAOA,EAAK,SAAA,CAAU,EAAGA,EAAK,MAAA,CAASuR,AANtBD,EAM+B,GAAA,CAAI,MAAM,EAAIG,EAAS,GAAA,CACvER,EAAQO,EAAQ,SAAA,CAAUxM,EAAO,EAAA,CAAG,IAAK,GAAA,CAAI,MAAM,EAAE,KAAA,CAAM;AAAA,CAAI,EAC/D,QACF,CACF,CAEA,MAAO,CACL,KAAM,aACN,IAAAD,EACA,OAAAC,EACA,KAAAhF,CACF,CACF,CACF,CAEA,KAAK6I,CAAAA,CAAsC,CACzC,IAAI4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,IAAA,CAAK,IAAA,CAAK5H,GACrC,GAAI4H,EAAK,CACP,IAAIpD,EAAOoD,CAAAA,CAAI,EAAC,CAAE,IAAA,GACZiB,EAAYrE,EAAK,MAAA,CAAS,EAE1BzN,EAAoB,CACxB,KAAM,OACN,IAAK,GACL,QAAS8R,EACT,MAAOA,EAAY,CAACrE,EAAK,KAAA,CAAM,EAAG,IAAM,GACxC,MAAO,CAAA,EACP,MAAO,EACT,AAAA,CAEAA,CAAAA,EAAOqE,EAAY,CAAA,UAAA,EAAarE,EAAK,KAAA,CAAM,IAAA,CAAG,CAAK,CAAA,EAAA,EAAKA,EAAAA,CAAI,CAExD,IAAA,CAAK,OAAA,CAAQ,QAAA,EACfA,CAAAA,EAAOqE,EAAYrE,EAAO,OAAA,EAI5B,IAAMsE,EAAY,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,aAAA,CAActE,GAC7CuE,EAAoB,CAAA,EAExB,KAAO/I,GAAK,CACV,IAAIgJ,EAAW,CAAA,EACX9M,EAAM,GACN+M,EAAe,GAKnB,GAJI,CAAErB,CAAAA,EAAMkB,EAAU,IAAA,CAAK9I,EAAAA,GAIvB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,EAAA,CAAG,IAAA,CAAKA,GAC3B,KAGF9D,CAAAA,EAAM0L,CAAAA,CAAI,EAAC,CACX5H,EAAMA,EAAI,SAAA,CAAU9D,EAAI,MAAM,EAE9B,IAAIgN,EAAOtB,CAAAA,CAAI,EAAC,CAAE,KAAA,CAAM;AAAA,CAAA,CAAM,EAAC,CAAE,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAkBzX,AAAAA,GAAc,IAAI,MAAA,CAAO,EAAIA,EAAE,MAAM,GAChHgZ,EAAWnJ,EAAI,KAAA,CAAM;AAAA,CAAA,CAAM,EAAC,CAAE,EAAC,CAC/BrN,EAAY,CAACuW,EAAK,IAAA,GAElBzE,EAAS,EAmBb,GAlBI,IAAA,CAAK,OAAA,CAAQ,QAAA,CACfA,CAAAA,EAAS,EACTwE,EAAeC,EAAK,SAAA,EAAA,EACXvW,EACT8R,EAASmD,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAS,EAEzBnD,CAAAA,AACAA,EAASA,AADTA,CAAAA,EAASmD,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAO,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAY,CAAA,EAClC,EAAI,EAAInD,EAC1BwE,EAAeC,EAAK,KAAA,CAAMzE,GAC1BA,GAAUmD,CAAAA,CAAI,EAAC,CAAE,MAAA,AAAA,EAGfjV,GAAa,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,SAAA,CAAU,IAAA,CAAKwW,IAC/CjN,CAAAA,GAAOiN,EAAW;AAAA,CAAA,CAClBnJ,EAAMA,EAAI,SAAA,CAAUmJ,EAAS,MAAA,CAAS,GACtCH,EAAW,CAAA,CAAA,EAGT,CAACA,EAAU,CACb,IAAM9T,EAAkB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgBuP,GACnDpP,EAAU,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,OAAA,CAAQoP,GACnCnP,EAAmB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,gBAAA,CAAiBmP,GACrDlP,EAAoB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkBkP,GACvDjP,EAAiB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,cAAA,CAAeiP,GAGvD,KAAOzE,GAAK,CACV,IAAMoJ,EAAUpJ,EAAI,KAAA,CAAM;AAAA,CAAA,CAAM,EAAC,CAAE,EAAC,CAChCqJ,EAgCJ,GA/BAF,EAAWC,EAKTC,EAFE,IAAA,CAAK,OAAA,CAAQ,QAAA,CACfF,EAAWA,EAAS,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,kBAAA,CAAoB,MAG3CA,EAAS,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,aAAA,CAAe,QAIrE7T,EAAiB,IAAA,CAAK6T,IAKtB5T,EAAkB,IAAA,CAAK4T,IAKvB3T,EAAe,IAAA,CAAK2T,IAKpBjU,EAAgB,IAAA,CAAKiU,IAKrB9T,EAAQ,IAAA,CAAK8T,GACf,MAGF,GAAIE,EAAoB,MAAA,CAAO,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAY,GAAK5E,GAAU,CAAC0E,EAAS,IAAA,GACnFF,GAAgB;AAAA,CAAA,CAAOI,EAAoB,KAAA,CAAM5E,OAC5C,CAgBL,GAdI9R,GAKAuW,EAAK,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,aAAA,CAAe,QAAQ,MAAA,CAAO,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAY,GAAK,GAG9F5T,EAAiB,IAAA,CAAK4T,IAGtB3T,EAAkB,IAAA,CAAK2T,IAGvB7T,EAAQ,IAAA,CAAK6T,GACf,MAGFD,GAAgB;AAAA,CAAA,CAAOE,CACzB,CAEI,AAACxW,GAAcwW,EAAS,IAAA,IAC1BxW,CAAAA,EAAY,CAAA,CAAA,EAGduJ,GAAOkN,EAAU;AAAA,CAAA,CACjBpJ,EAAMA,EAAI,SAAA,CAAUoJ,EAAQ,MAAA,CAAS,GACrCF,EAAOG,EAAoB,KAAA,CAAM5E,EACnC,CACF,CAEK1N,EAAK,KAAA,EAEJgS,CAAAA,EACFhS,EAAK,KAAA,CAAQ,CAAA,EACJ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKmF,IAC/C6M,CAAAA,EAAoB,CAAA,CAAA,CAAA,EAIxB,IAAIO,EAAiC,KACjCC,CAEA,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,EACfD,CAAAA,EAAS,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAAW,IAAA,CAAKL,EAAAA,GAExCM,CAAAA,EAAYD,AAAc,SAAdA,CAAAA,CAAO,EAAC,CACpBL,EAAeA,EAAa,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAiB,GAAA,EAI1ElS,EAAK,KAAA,CAAM,IAAA,CAAK,CACd,KAAM,YACN,IAAAmF,EACA,KAAM,CAAC,CAACoN,EACR,QAASC,EACT,MAAO,CAAA,EACP,KAAMN,EACN,OAAQ,EACV,AAAA,GAEAlS,EAAK,GAAA,EAAOmF,CACd,CAGA,IAAMsN,EAAWzS,EAAK,KAAA,CAAM,EAAA,CAAG,IAC/B,IAAIyS,EAKF,MAJAA,CAAAA,EAAS,GAAA,CAAMA,EAAS,GAAA,CAAI,OAAA,GAC5BA,EAAS,IAAA,CAAOA,EAAS,IAAA,CAAK,OAAA,GAKhCzS,EAAK,GAAA,CAAMA,EAAK,GAAA,CAAI,OAAA,GAGpB,IAAA,IAASrF,EAAI,EAAGA,EAAIqF,EAAK,KAAA,CAAM,MAAA,CAAQrF,IAIrC,GAHA,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,GAAA,CAAM,CAAA,EACvBqF,EAAK,KAAA,CAAMrF,EAAC,CAAE,MAAA,CAAS,IAAA,CAAK,KAAA,CAAM,WAAA,CAAYqF,EAAK,KAAA,CAAMrF,EAAC,CAAE,IAAA,CAAM,EAAE,EAEhE,CAACqF,EAAK,KAAA,CAAO,CAEf,IAAM0S,EAAU1S,EAAK,KAAA,CAAMrF,EAAC,CAAE,MAAA,CAAO,MAAA,CAAOvB,AAAAA,GAAKA,AAAW,UAAXA,EAAE,IAAA,CAGnD4G,CAAAA,EAAK,KAAA,CAFyB0S,EAAQ,MAAA,CAAS,GAAKA,EAAQ,IAAA,CAAKtZ,AAAAA,GAAK,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,OAAA,CAAQ,IAAA,CAAKA,EAAE,GAAG,EAG3G,CAIF,GAAI4G,EAAK,KAAA,CACP,IAAA,IAASrF,EAAI,EAAGA,EAAIqF,EAAK,KAAA,CAAM,MAAA,CAAQrF,IACrCqF,EAAK,KAAA,CAAMrF,EAAC,CAAE,KAAA,CAAQ,CAAA,EAI1B,OAAOqF,CACT,CACF,CAEA,KAAKiJ,CAAAA,CAAsC,CACzC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,IAAA,CAAK,IAAA,CAAK5H,GACvC,GAAI4H,EAQF,MAP2B,CACzB,KAAM,OACN,MAAO,CAAA,EACP,IAAKA,CAAAA,CAAI,EAAC,CACV,IAAKA,AAAW,QAAXA,CAAAA,CAAI,EAAC,EAAeA,AAAW,WAAXA,CAAAA,CAAI,EAAC,EAAkBA,AAAW,UAAXA,CAAAA,CAAI,EAAC,CACrD,KAAMA,CAAAA,CAAI,EACZ,AAAA,CAGJ,CAEA,IAAI5H,CAAAA,CAAqC,CACvC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,GAAA,CAAI,IAAA,CAAK5H,GACtC,GAAI4H,EAAK,CACP,IAAM7N,EAAM6N,CAAAA,CAAI,EAAC,CAAE,WAAA,GAAc,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,mBAAA,CAAqB,KACzEhM,EAAOgM,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAA,CAAc,MAAM,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAgB,MAAQ,GACtH/L,EAAQ+L,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,SAAA,CAAU,EAAGA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAS,GAAG,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAgB,MAAQA,CAAAA,CAAI,EAAC,CACrH,MAAO,CACL,KAAM,MACN,IAAA7N,EACA,IAAK6N,CAAAA,CAAI,EAAC,CACV,KAAAhM,EACA,MAAAC,CACF,CACF,CACF,CAEA,MAAMmE,CAAAA,CAAuC,CAC3C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,KAAA,CAAM,IAAA,CAAK5H,GAKxC,GAJI,CAAC4H,GAID,CAAC,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,cAAA,CAAe,IAAA,CAAKA,CAAAA,CAAI,EAAE,EAE9C,OAGF,IAAM+B,EAAU7C,GAAWc,CAAAA,CAAI,EAAE,EAC3BgC,EAAShC,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAiB,IAAI,KAAA,CAAM,KACpE3I,EAAO2I,CAAAA,CAAI,EAAC,EAAG,OAASA,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAmB,IAAI,KAAA,CAAM;AAAA,CAAI,EAAI,EAAC,CAE9FiC,EAAqB,CACzB,KAAM,QACN,IAAKjC,CAAAA,CAAI,EAAC,CACV,OAAQ,EAAC,CACT,MAAO,EAAC,CACR,KAAM,EACR,AAAA,EAEA,GAAI+B,EAAQ,MAAA,GAAWC,EAAO,MAAA,CAK9B,CAAA,IAAA,IAAW5K,KAAS4K,EACd,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAK5K,GACxC6K,EAAK,KAAA,CAAM,IAAA,CAAK,SACP,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,gBAAA,CAAiB,IAAA,CAAK7K,GAChD6K,EAAK,KAAA,CAAM,IAAA,CAAK,UACP,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,cAAA,CAAe,IAAA,CAAK7K,GAC9C6K,EAAK,KAAA,CAAM,IAAA,CAAK,QAEhBA,EAAK,KAAA,CAAM,IAAA,CAAK,MAIpB,IAAA,IAASnY,EAAI,EAAGA,EAAIiY,EAAQ,MAAA,CAAQjY,IAClCmY,EAAK,MAAA,CAAO,IAAA,CAAK,CACf,KAAMF,CAAAA,CAAQjY,EAAC,CACf,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOiY,CAAAA,CAAQjY,EAAE,EACpC,OAAQ,CAAA,EACR,MAAOmY,EAAK,KAAA,CAAMnY,EACpB,AAAA,GAGF,IAAA,IAAWuV,KAAOhI,EAChB4K,EAAK,IAAA,CAAK,IAAA,CAAK/C,GAAWG,EAAK4C,EAAK,MAAA,CAAO,MAAM,EAAE,GAAA,CAAI,CAACC,EAAMpY,IACrD,CAAA,CACL,KAAMoY,EACN,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOA,GAC1B,OAAQ,CAAA,EACR,MAAOD,EAAK,KAAA,CAAMnY,EACpB,AAAA,CAAA,IAIJ,OAAOmY,CAAAA,CACT,CAEA,SAAS7J,CAAAA,CAAyC,CAChD,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,QAAA,CAAS,IAAA,CAAK5H,GAC3C,GAAI4H,EACF,MAAO,CACL,KAAM,UACN,IAAKA,CAAAA,CAAI,EAAC,CACV,MAAOA,AAAqB,MAArBA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAO,GAAa,EAAI,EACtC,KAAMA,CAAAA,CAAI,EAAC,CACX,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOA,CAAAA,CAAI,EAAE,CAClC,CAEJ,CAEA,UAAU5H,CAAAA,CAA2C,CACnD,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,SAAA,CAAU,IAAA,CAAK5H,GAC5C,GAAI4H,EAAK,CACP,IAAMzQ,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAOA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAS,KAAO;AAAA,CAAA,CAC9CA,CAAAA,CAAI,EAAC,CAAE,KAAA,CAAM,EAAG,IAChBA,CAAAA,CAAI,EAAC,CACT,MAAO,CACL,KAAM,YACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAAzQ,EACA,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOA,EAC5B,CACF,CACF,CAEA,KAAK6I,CAAAA,CAAsC,CACzC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,IAAA,CAAK,IAAA,CAAK5H,GACvC,GAAI4H,EACF,MAAO,CACL,KAAM,OACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAMA,CAAAA,CAAI,EAAC,CACX,OAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAOA,CAAAA,CAAI,EAAE,CAClC,CAEJ,CAEA,OAAO5H,CAAAA,CAAwC,CAC7C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,MAAA,CAAO,IAAA,CAAK5H,GAC1C,GAAI4H,EACF,MAAO,CACL,KAAM,SACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAMA,CAAAA,CAAI,EACZ,AAAA,CAEJ,CAEA,IAAI5H,CAAAA,CAAqC,CACvC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,GAAA,CAAI,IAAA,CAAK5H,GACvC,GAAI4H,EACF,MAAI,CAAC,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,EAAU,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,SAAA,CAAU,IAAA,CAAKA,CAAAA,CAAI,EAAE,EACpE,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,CAAS,CAAA,EACjB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,EAAU,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,OAAA,CAAQ,IAAA,CAAKA,CAAAA,CAAI,EAAE,GACxE,CAAA,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,CAAS,CAAA,CAAA,EAExB,CAAC,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,EAAc,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkB,IAAA,CAAKA,CAAAA,CAAI,EAAE,EAChF,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAAa,CAAA,EACrB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,EAAc,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKA,CAAAA,CAAI,EAAE,GACpF,CAAA,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAAa,CAAA,CAAA,EAGzB,CACL,KAAM,OACN,IAAKA,CAAAA,CAAI,EAAC,CACV,OAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,MAAA,CACzB,WAAY,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CAC7B,MAAO,CAAA,EACP,KAAMA,CAAAA,CAAI,EACZ,AAAA,CAEJ,CAEA,KAAK5H,CAAAA,CAAqD,CACxD,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,IAAA,CAAK,IAAA,CAAK5H,GACxC,GAAI4H,EAAK,CACP,IAAMmC,EAAanC,CAAAA,CAAI,EAAC,CAAE,IAAA,GAC1B,GAAI,CAAC,IAAA,CAAK,OAAA,CAAQ,QAAA,EAAY,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkB,IAAA,CAAKmC,GAAa,CAEjF,GAAI,CAAE,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKA,GAC1C,OAIF,IAAMC,EAAa1C,GAAMyC,EAAW,KAAA,CAAM,EAAG,IAAK,MAClD,GAAA,AAAKA,CAAAA,EAAW,MAAA,CAASC,EAAW,MAAA,AAAA,EAAU,GAAM,EAClD,MAEJ,KAAO,CAEL,IAAMC,EAAiBvC,ADvfxB,SAA4BP,CAAAA,CAAa7Y,CAAAA,EAC9C,GAAI6Y,AAAsB,KAAtBA,EAAI,OAAA,CCsfgD,KDrftD,OAAO,GAGT,IAAI9E,EAAQ,EACZ,IAAA,IAAS3Q,EAAI,EAAGA,EAAIyV,EAAI,MAAA,CAAQzV,IAC9B,GAAIyV,AAAW,OAAXA,CAAAA,CAAIzV,EAAC,CACPA,SAAAA,GACSyV,AC8e2C,MD9e3CA,CAAAA,CAAIzV,EAAC,CACd2Q,SAAAA,GACS8E,CAAAA,CAAIzV,EAAC,GAAMpD,CAAAA,CAAE,EAAC,EACvB+T,EACIA,EAAQ,EACV,OAAO3Q,EAIb,OAAI2Q,EAAQ,EACH,GAGF,EACT,ECgekDuF,CAAAA,CAAI,EAAC,CAAG,MAClD,GAAIqC,AAAmB,KAAnBA,EAEF,OAGF,GAAIA,EAAiB,GAAI,CAEvB,IAAMC,EAAAA,AADQtC,CAAAA,AAAwB,IAAxBA,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,KAAa,EAAI,CAAA,EACtBA,CAAAA,CAAI,EAAC,CAAE,MAAA,CAASqC,CACxCrC,CAAAA,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,SAAA,CAAU,EAAGqC,GAC7BrC,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,SAAA,CAAU,EAAGsC,GAAS,IAAA,GACtCtC,CAAAA,CAAI,EAAC,CAAI,EACX,CACF,CACA,IAAIhM,EAAOgM,CAAAA,CAAI,EAAC,CACZ/L,EAAQ,GACZ,GAAI,IAAA,CAAK,OAAA,CAAQ,QAAA,CAAU,CAEzB,IAAMnC,EAAO,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkB,IAAA,CAAKkC,EAEjDlC,CAAAA,GACFkC,CAAAA,EAAOlC,CAAAA,CAAK,EAAC,CACbmC,EAAQnC,CAAAA,CAAK,EAAC,AAAD,CAEjB,MACEmC,EAAQ+L,CAAAA,CAAI,EAAC,CAAIA,CAAAA,CAAI,EAAC,CAAE,KAAA,CAAM,EAAG,IAAM,GAGzC,OAAAhM,EAAOA,EAAK,IAAA,GACR,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkB,IAAA,CAAKA,KAGxCA,EAFE,IAAA,CAAK,OAAA,CAAQ,QAAA,EAAY,CAAE,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKmO,GAE5DnO,EAAK,KAAA,CAAM,GAEXA,EAAK,KAAA,CAAM,EAAG,KAGlB+L,GAAWC,EAAK,CACrB,KAAMhM,GAAOA,EAAK,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAgB,MAC5D,MAAOC,GAAQA,EAAM,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAgB,KACjE,EAAG+L,CAAAA,CAAI,EAAC,CAAG,IAAA,CAAK,KAAA,CAAO,IAAA,CAAK,KAAK,CACnC,CACF,CAEA,QAAQ5H,CAAAA,CAAaJ,CAAAA,CAAoE,CACvF,IAAIgI,EACJ,GAAA,AAAKA,CAAAA,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,OAAA,CAAQ,IAAA,CAAK5H,EAAAA,GACpC4H,CAAAA,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,MAAA,CAAO,IAAA,CAAK5H,EAAAA,EAAO,CAC/C,IACMtG,EAAOkG,CAAAA,CAAMuK,AADCvC,AAAAA,CAAAA,CAAAA,CAAI,EAAC,EAAKA,CAAAA,CAAI,EAAC,AAAD,EAAI,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,mBAAA,CAAqB,KACtD,WAAA,GAAa,CAC3C,GAAI,CAAClO,EAAM,CACT,IAAMvC,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,MAAA,CAAO,GAC3B,MAAO,CACL,KAAM,OACN,IAAKzQ,EACL,KAAAA,CACF,CACF,CACA,OAAOwQ,GAAWC,EAAKlO,EAAMkO,CAAAA,CAAI,EAAC,CAAG,IAAA,CAAK,KAAA,CAAO,IAAA,CAAK,KAAK,CAC7D,CACF,CAEA,SAAS5H,CAAAA,CAAaoK,CAAAA,CAAmBC,EAAW,EAAA,CAA2C,CAC7F,IAAI3N,EAAQ,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,cAAA,CAAe,IAAA,CAAKsD,GAIlD,IAHI,CAAA,CAACtD,GAGDA,CAAAA,CAAM,EAAC,EAAK2N,EAAS,KAAA,CAAM,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,mBAAmB,CAAA,GAI/D,CAAA,CAFa3N,CAAAA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,AAAD,GAElB,CAAC2N,GAAY,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,WAAA,CAAY,IAAA,CAAKA,EAAAA,EAAW,CAE1E,IAAMC,EAAU,IAAI5N,CAAAA,CAAM,EAAE,CAAA,CAAE,MAAA,CAAS,EACnC6N,EAAQC,EAASC,EAAaH,EAASI,EAAgB,EAErDC,EAASjO,AAAgB,MAAhBA,CAAAA,CAAM,EAAC,CAAE,EAAC,CAAY,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,iBAAA,CAAoB,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,iBAAA,CAM7F,IALAiO,EAAO,SAAA,CAAY,EAGnBP,EAAYA,EAAU,KAAA,CAAM,GAAKpK,EAAI,MAAA,CAASsK,GAEtC5N,AAAmC,MAAnCA,CAAAA,EAAQiO,EAAO,IAAA,CAAKP,EAAAA,GAAqB,CAG/C,GAFAG,CAAAA,CAAAA,EAAS7N,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,AAAD,EAE9D,SAIb,GAFA8N,EAAU,IAAID,EAAM,CAAE,MAAA,CAElB7N,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,CAAG,CACxB+N,GAAcD,EACd,QACF,CAAA,GAAW9N,AAAAA,CAAAA,CAAAA,CAAM,EAAC,EAAKA,CAAAA,CAAM,EAAC,AAAD,GACvB4N,EAAU,GAAK,CAAGA,CAAAA,AAAAA,CAAAA,EAAUE,CAAAA,EAAW,CAAA,EAAI,CAC7CE,GAAiBF,EACjB,QACF,CAKF,GAFAC,CAAAA,GAAcD,CAAAA,EAEG,EAAG,SAGpBA,EAAU,KAAK,GAAA,CAAIA,EAASA,EAAUC,EAAaC,GAEnD,IAAME,EAAiB,IAAIlO,CAAAA,CAAM,EAAE,CAAA,CAAE,EAAC,CAAE,MAAA,CAClCR,EAAM8D,EAAI,KAAA,CAAM,EAAGsK,EAAU5N,EAAM,KAAA,CAAQkO,EAAiBJ,GAGlE,GAAI,KAAK,GAAA,CAAIF,EAASE,GAAW,EAAG,CAClC,IAAMrT,EAAO+E,EAAI,KAAA,CAAM,EAAG,IAC1B,MAAO,CACL,KAAM,KACN,IAAAA,EACA,KAAA/E,EACA,OAAQ,IAAA,CAAK,KAAA,CAAM,YAAA,CAAaA,EAClC,CACF,CAGA,IAAMA,EAAO+E,EAAI,KAAA,CAAM,EAAG,IAC1B,MAAO,CACL,KAAM,SACN,IAAAA,EACA,KAAA/E,EACA,OAAQ,IAAA,CAAK,KAAA,CAAM,YAAA,CAAaA,EAClC,CACF,CACF,CACF,CAEA,SAAS6I,CAAAA,CAA0C,CACjD,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,IAAA,CAAK,IAAA,CAAK5H,GACxC,GAAI4H,EAAK,CACP,IAAIzQ,EAAOyQ,CAAAA,CAAI,EAAC,CAAE,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAmB,KACxDiD,EAAmB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,YAAA,CAAa,IAAA,CAAK1T,GACtD2T,EAA0B,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,iBAAA,CAAkB,IAAA,CAAK3T,IAAS,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,eAAA,CAAgB,IAAA,CAAKA,GACvH,OAAI0T,GAAoBC,GACtB3T,CAAAA,EAAOA,EAAK,SAAA,CAAU,EAAGA,EAAK,MAAA,CAAS,EAAA,EAElC,CACL,KAAM,WACN,IAAKyQ,CAAAA,CAAI,EAAC,CACV,KAAAzQ,CACF,CACF,CACF,CAEA,GAAG6I,CAAAA,CAAoC,CACrC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,EAAA,CAAG,IAAA,CAAK5H,GACtC,GAAI4H,EACF,MAAO,CACL,KAAM,KACN,IAAKA,CAAAA,CAAI,EACX,AAAA,CAEJ,CAEA,IAAI5H,CAAAA,CAAqC,CACvC,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,GAAA,CAAI,IAAA,CAAK5H,GACvC,GAAI4H,EACF,MAAO,CACL,KAAM,MACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAMA,CAAAA,CAAI,EAAC,CACX,OAAQ,IAAA,CAAK,KAAA,CAAM,YAAA,CAAaA,CAAAA,CAAI,EAAE,CACxC,CAEJ,CAEA,SAAS5H,CAAAA,CAAsC,CAC7C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,QAAA,CAAS,IAAA,CAAK5H,GAC5C,GAAI4H,EAAK,CACP,IAAIzQ,EAAMyE,EACV,OAAIgM,AAEFhM,EAFEgM,AAAW,MAAXA,CAAAA,CAAI,EAAC,CAEA,UADPzQ,CAAAA,EAAOyQ,CAAAA,CAAI,EAAC,AAAD,EAGXzQ,EAAOyQ,CAAAA,CAAI,EAAC,CAIP,CACL,KAAM,OACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAAzQ,EACA,KAAAyE,EACA,OAAQ,CACN,CACE,KAAM,OACN,IAAKzE,EACL,KAAAA,CACF,EAEJ,AAAA,CACF,CACF,CAEA,IAAI6I,CAAAA,CAAsC,CACxC,IAAI4H,EACJ,GAAIA,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,GAAA,CAAI,IAAA,CAAK5H,GAAM,CACzC,IAAI7I,EAAMyE,EACV,GAAIgM,AAAW,MAAXA,CAAAA,CAAI,EAAC,CAEPhM,EAAO,UADPzE,CAAAA,EAAOyQ,CAAAA,CAAI,EAAC,AAAD,MAEN,CAEL,IAAImD,EACJ,GACEA,EAAcnD,CAAAA,CAAI,EAAC,CACnBA,CAAAA,CAAI,EAAC,CAAI,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,UAAA,CAAW,IAAA,CAAKA,CAAAA,CAAI,EAAE,GAAA,CAAI,EAAC,EAAK,SACpDmD,IAAgBnD,CAAAA,CAAI,EAAC,CAC9BzQ,AAAAA,EAAOyQ,CAAAA,CAAI,EAAC,CAEVhM,EADEgM,AAAW,SAAXA,CAAAA,CAAI,EAAC,CACA,UAAYA,CAAAA,CAAI,EAAC,CAEjBA,CAAAA,CAAI,EAEf,AAAA,CACA,MAAO,CACL,KAAM,OACN,IAAKA,CAAAA,CAAI,EAAC,CACV,KAAAzQ,EACA,KAAAyE,EACA,OAAQ,CACN,CACE,KAAM,OACN,IAAKzE,EACL,KAAAA,CACF,EAEJ,AAAA,CACF,CACF,CAEA,WAAW6I,CAAAA,CAAsC,CAC/C,IAAM4H,EAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,IAAA,CAAK,IAAA,CAAK5H,GACxC,GAAI4H,EAAK,CACP,IAAMlI,EAAU,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM,UAAA,CACjC,MAAO,CACL,KAAM,OACN,IAAKkI,CAAAA,CAAI,EAAC,CACV,KAAMA,CAAAA,CAAI,EAAC,CACX,QAAAlI,CACF,CACF,CACF,CACF,ECn2Ba6D,GAAN,MAAMyH,EACX,MACA,AAAA,CAAA,OACA,AAAA,CAAA,KAMQ,AAAA,CAAA,SACA,AAAA,CAAA,WAER,AAAA,aAAY3b,CAAAA,CAAuD,CAEjE,IAAA,CAAK,MAAA,CAAS,EAAC,CACf,IAAA,CAAK,MAAA,CAAO,KAAA,CAAQ,OAAO,MAAA,CAAO,MAClC,IAAA,CAAK,OAAA,CAAUA,GAAWuU,EAC1B,IAAA,CAAK,OAAA,CAAQ,SAAA,CAAY,IAAA,CAAK,OAAA,CAAQ,SAAA,EAAa,IAAID,GACvD,IAAA,CAAK,SAAA,CAAY,IAAA,CAAK,OAAA,CAAQ,SAAA,CAC9B,IAAA,CAAK,SAAA,CAAU,OAAA,CAAU,IAAA,CAAK,OAAA,CAC9B,IAAA,CAAK,SAAA,CAAU,KAAA,CAAQ,IAAA,CACvB,IAAA,CAAK,WAAA,CAAc,EAAC,CACpB,IAAA,CAAK,KAAA,CAAQ,CACX,OAAQ,CAAA,EACR,WAAY,CAAA,EACZ,IAAK,CAAA,CACP,EAEA,IAAMtH,EAAQ,CACZ,MAAAP,EACA,MAAOS,GAAM,MAAA,CACb,OAAQO,GAAO,MACjB,AAAA,CAEI,CAAA,IAAA,CAAK,OAAA,CAAQ,QAAA,CACfT,CAAAA,EAAM,KAAA,CAAQE,GAAM,QAAA,CACpBF,EAAM,MAAA,CAASS,GAAO,QAAA,AAAA,EACb,IAAA,CAAK,OAAA,CAAQ,GAAA,EACtBT,CAAAA,EAAM,KAAA,CAAQE,GAAM,GAAA,CAChB,IAAA,CAAK,OAAA,CAAQ,MAAA,CACfF,EAAM,MAAA,CAASS,GAAO,MAAA,CAEtBT,EAAM,MAAA,CAASS,GAAO,GAAA,AAAA,EAG1B,IAAA,CAAK,SAAA,CAAU,KAAA,CAAQT,CACzB,CAKA,WAAW,OAAQ,CACjB,MAAO,CACL,MAAAE,GACA,OAAAO,EACF,CACF,CAKA,OAAO,IAAoDkD,CAAAA,CAAa3Q,CAAAA,CAAuD,CAE7H,OADc,IAAI2b,EAAqC3b,GAC1C,GAAA,CAAI2Q,EACnB,CAKA,OAAO,UAA0DA,CAAAA,CAAa3Q,CAAAA,CAAuD,CAEnI,OADc,IAAI2b,EAAqC3b,GAC1C,YAAA,CAAa2Q,EAC5B,CAKA,IAAIA,CAAAA,CAAa,CACfA,EAAMA,EAAI,OAAA,CAAQlE,EAAM,cAAA,CAAgB;AAAA,CAAI,EAE5C,IAAA,CAAK,WAAA,CAAYkE,EAAK,IAAA,CAAK,MAAM,EAEjC,IAAA,IAAStO,EAAI,EAAGA,EAAI,IAAA,CAAK,WAAA,CAAY,MAAA,CAAQA,IAAK,CAChD,IAAMuZ,EAAO,IAAA,CAAK,WAAA,CAAYvZ,EAAC,CAC/B,IAAA,CAAK,YAAA,CAAauZ,EAAK,GAAA,CAAKA,EAAK,MAAM,CACzC,CACA,OAAA,IAAA,CAAK,WAAA,CAAc,EAAC,CAEb,IAAA,CAAK,MACd,AAAA,CAOA,YAAYjL,CAAAA,CAAa7D,EAAkB,EAAC,CAAG+O,EAAuB,CAAA,CAAA,CAAO,CAK3E,IAJI,IAAA,CAAK,OAAA,CAAQ,QAAA,EACflL,CAAAA,EAAMA,EAAI,OAAA,CAAQlE,EAAM,aAAA,CAAe,QAAQ,OAAA,CAAQA,EAAM,SAAA,CAAW,GAAA,EAGnEkE,GAAK,KACN6H,EAEJ,GAAI,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,OAAO,KAAMsD,AAAAA,GACpCtD,EAAAA,CAAAA,EAAQsD,EAAa,IAAA,CAAK,CAAE,MAAO,IAAK,AAAA,EAAGnL,EAAK7D,EAAAA,GAClD6D,CAAAA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACL,CAAA,CAAA,GAIT,SAIF,GAAIA,EAAQ,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM7H,GAAM,CACrCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,IAAMY,EAAYtM,EAAO,EAAA,CAAG,GACxB0L,AAAqB,CAAA,IAArBA,EAAM,GAAA,CAAI,MAAA,EAAgBY,AAAc,KAAA,IAAdA,EAG5BA,EAAU,GAAA,EAAO;AAAA,CAAA,CAEjBtM,EAAO,IAAA,CAAK0L,GAEd,QACF,CAGA,GAAIA,EAAQ,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK7H,GAAM,CACpCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,IAAMY,EAAYtM,EAAO,EAAA,CAAG,GAExBsM,CAAAA,GAAW,OAAS,aAAeA,GAAW,OAAS,OACzDA,CAAAA,EAAU,GAAA,EAAQA,AAAAA,CAAAA,EAAU,GAAA,CAAI,QAAA,CAAS;AAAA,CAAI,EAAI,GAAK;AAAA,CAAA,AAAA,EAAQZ,EAAM,GAAA,CACpEY,EAAU,IAAA,EAAQ;AAAA,CAAA,CAAOZ,EAAM,IAAA,CAC/B,IAAA,CAAK,WAAA,CAAY,EAAA,CAAG,IAAK,GAAA,CAAMY,EAAU,IAAA,AAAA,EAEzCtM,EAAO,IAAA,CAAK0L,GAEd,QACF,CAGA,GAAIA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,MAAA,CAAO7H,EAAAA,GAO9B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,OAAA,CAAQ7H,EAAAA,GAO/B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,EAAA,CAAG7H,EAAAA,GAO1B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,UAAA,CAAW7H,EAAAA,GAOlC6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK7H,EAAAA,GAO5B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK7H,EAAAA,EAnCQ,CACtCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACZ,QACF,CAsCA,GAAIA,EAAQ,IAAA,CAAK,SAAA,CAAU,GAAA,CAAI7H,GAAM,CACnCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,IAAMY,EAAYtM,EAAO,EAAA,CAAG,GACxBsM,CAAAA,GAAW,OAAS,aAAeA,GAAW,OAAS,OACzDA,CAAAA,EAAU,GAAA,EAAQA,AAAAA,CAAAA,EAAU,GAAA,CAAI,QAAA,CAAS;AAAA,CAAI,EAAI,GAAK;AAAA,CAAA,AAAA,EAAQZ,EAAM,GAAA,CACpEY,EAAU,IAAA,EAAQ;AAAA,CAAA,CAAOZ,EAAM,GAAA,CAC/B,IAAA,CAAK,WAAA,CAAY,EAAA,CAAG,IAAK,GAAA,CAAMY,EAAU,IAAA,AAAA,EAC/B,IAAA,CAAK,MAAA,CAAO,KAAA,CAAMZ,EAAM,GAAG,CAAA,EACrC,CAAA,IAAA,CAAK,MAAA,CAAO,KAAA,CAAMA,EAAM,GAAG,CAAA,CAAI,CAC7B,KAAMA,EAAM,IAAA,CACZ,MAAOA,EAAM,KACf,AAAA,EACA1L,EAAO,IAAA,CAAK0L,EAAAA,EAEd,QACF,CAGA,GAAIA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM7H,EAAAA,GAO7B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,QAAA,CAAS7H,EAAAA,EAPG,CACrCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACZ,QACF,CAWA,IAAIuD,EAASpL,EACb,GAAI,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,WAAY,CACvC,IAAIqL,EAAa,EAAA,EACXC,EAAUtL,EAAI,KAAA,CAAM,GACtBuL,CACJ,CAAA,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,UAAA,CAAW,OAAA,CAASC,AAAAA,IAC1CD,AACyB,UAArB,MADJA,CAAAA,EAAYC,EAAc,IAAA,CAAK,CAAE,MAAO,IAAK,AAAA,EAAGF,EAAAA,GACXC,GAAa,GAChDF,CAAAA,EAAa,KAAK,GAAA,CAAIA,EAAYE,EAAAA,CAEtC,GACIF,EAAa,EAAA,GAAYA,GAAc,GACzCD,CAAAA,EAASpL,EAAI,SAAA,CAAU,EAAGqL,EAAa,EAAA,CAE3C,CACA,GAAI,IAAA,CAAK,KAAA,CAAM,GAAA,EAAQxD,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,SAAA,CAAUuD,EAAAA,EAAU,CAChE,IAAM3C,EAAYtM,EAAO,EAAA,CAAG,GACxB+O,CAAAA,GAAwBzC,GAAW,OAAS,YAC9CA,CAAAA,EAAU,GAAA,EAAA,AAAQA,CAAAA,EAAU,GAAA,CAAI,QAAA,CAAS;AAAA,CAAI,EAAI,GAAK;AAAA,CAAA,AAAA,EAAQZ,EAAM,GAAA,CACpEY,EAAU,IAAA,EAAQ;AAAA,CAAA,CAAOZ,EAAM,IAAA,CAC/B,IAAA,CAAK,WAAA,CAAY,GAAA,GACjB,IAAA,CAAK,WAAA,CAAY,EAAA,CAAG,IAAK,GAAA,CAAMY,EAAU,IAAA,AAAA,EAEzCtM,EAAO,IAAA,CAAK0L,GAEdqD,EAAuBE,EAAO,MAAA,GAAWpL,EAAI,MAAA,CAC7CA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,QACF,CAGA,GAAIA,EAAQ,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK7H,GAAM,CACpCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,IAAMY,EAAYtM,EAAO,EAAA,CAAG,GACxBsM,CAAAA,GAAW,OAAS,OACtBA,CAAAA,EAAU,GAAA,EAAQA,AAAAA,CAAAA,EAAU,GAAA,CAAI,QAAA,CAAS;AAAA,CAAI,EAAI,GAAK;AAAA,CAAA,AAAA,EAAQZ,EAAM,GAAA,CACpEY,EAAU,IAAA,EAAQ;AAAA,CAAA,CAAOZ,EAAM,IAAA,CAC/B,IAAA,CAAK,WAAA,CAAY,GAAA,GACjB,IAAA,CAAK,WAAA,CAAY,EAAA,CAAG,IAAK,GAAA,CAAMY,EAAU,IAAA,AAAA,EAEzCtM,EAAO,IAAA,CAAK0L,GAEd,QACF,CAEA,GAAI7H,EAAK,CACP,IAAMyL,EAAS,0BAA4BzL,EAAI,UAAA,CAAW,GAC1D,GAAI,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAQ,CACvB,QAAQ,KAAA,CAAMyL,GACd,KACF,CACE,MAAM,AAAI,MAAMA,EAEpB,CACF,CAEA,OAAA,IAAA,CAAK,KAAA,CAAM,GAAA,CAAM,CAAA,EACVtP,CACT,CAEA,OAAO6D,CAAAA,CAAa7D,EAAkB,EAAC,CAAG,CACxC,OAAA,IAAA,CAAK,WAAA,CAAY,IAAA,CAAK,CAAE,IAAA6D,EAAK,OAAA7D,CAAO,GAC7BA,CACT,CAKA,aAAa6D,CAAAA,CAAa7D,EAAkB,EAAC,CAAY,CAEvD,IAAIiO,EAAYpK,EACZtD,EAAgC,KAGpC,GAAI,IAAA,CAAK,MAAA,CAAO,KAAA,CAAO,CACrB,IAAMkD,EAAQ,OAAO,IAAA,CAAK,IAAA,CAAK,MAAA,CAAO,KAAK,EAC3C,GAAIA,EAAM,MAAA,CAAS,EACjB,KAAQlD,AAAsE,MAAtEA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,aAAA,CAAc,IAAA,CAAK0N,EAAAA,GACzDxK,EAAM,QAAA,CAASlD,CAAAA,CAAM,EAAC,CAAE,KAAA,CAAMA,CAAAA,CAAM,EAAC,CAAE,WAAA,CAAY,KAAO,EAAG,MAC/D0N,CAAAA,EAAYA,EAAU,KAAA,CAAM,EAAG1N,EAAM,KAAK,EACtC,IAAM,IAAI,MAAA,CAAOA,CAAAA,CAAM,EAAC,CAAE,MAAA,CAAS,GAAK,IACxC0N,EAAU,KAAA,CAAM,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,aAAA,CAAc,SAAS,CAAA,CAI/E,CAGA,KAAQ1N,AAAuE,MAAvEA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,cAAA,CAAe,IAAA,CAAK0N,EAAAA,GAC9DA,EAAYA,EAAU,KAAA,CAAM,EAAG1N,EAAM,KAAK,EAAI,KAAO0N,EAAU,KAAA,CAAM,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,cAAA,CAAe,SAAS,EAI3H,KAAA,AAA0E,MAAlE1N,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,SAAA,CAAU,IAAA,CAAK0N,EAAAA,GACzDA,EAAYA,EAAU,KAAA,CAAM,EAAG1N,EAAM,KAAK,EAAI,IAAM,IAAI,MAAA,CAAOA,CAAAA,CAAM,EAAC,CAAE,MAAA,CAAS,GAAK,IAAM0N,EAAU,KAAA,CAAM,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM,MAAA,CAAO,SAAA,CAAU,SAAS,EAI7JA,EAAY,IAAA,CAAK,OAAA,CAAQ,KAAA,EAAO,cAAc,KAAK,CAAE,MAAO,IAAK,AAAA,EAAGA,IAAcA,EAElF,IAAIsB,EAAe,CAAA,EACfrB,EAAW,GACf,KAAOrK,GAAK,KAMN6H,EAGJ,GARK6D,GACHrB,CAAAA,EAAW,EAAA,EAEbqB,EAAe,CAAA,EAKX,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,QAAQ,KAAMP,AAAAA,GACrCtD,EAAAA,CAAAA,EAAQsD,EAAa,IAAA,CAAK,CAAE,MAAO,IAAK,AAAA,EAAGnL,EAAK7D,EAAAA,GAClD6D,CAAAA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACL,CAAA,CAAA,GAIT,SAIF,GAAIA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,MAAA,CAAO7H,EAAAA,GAO9B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,GAAA,CAAI7H,EAAAA,GAO3B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK7H,EAAAA,EAdQ,CACtCA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACZ,QACF,CAiBA,GAAIA,EAAQ,IAAA,CAAK,SAAA,CAAU,OAAA,CAAQ7H,EAAK,IAAA,CAAK,MAAA,CAAO,KAAK,EAAG,CAC1DA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC,IAAMY,EAAYtM,EAAO,EAAA,CAAG,GACxB0L,AAAe,CAAA,SAAfA,EAAM,IAAA,EAAmBY,GAAW,OAAS,OAC/CA,CAAAA,EAAU,GAAA,EAAOZ,EAAM,GAAA,CACvBY,EAAU,IAAA,EAAQZ,EAAM,IAAA,AAAA,EAExB1L,EAAO,IAAA,CAAK0L,GAEd,QACF,CAGA,GAAIA,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,QAAA,CAAS7H,EAAKoK,EAAWC,EAAAA,GAOhDxC,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,QAAA,CAAS7H,EAAAA,GAOhC6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,EAAA,CAAG7H,EAAAA,GAO1B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,GAAA,CAAI7H,EAAAA,GAO3B6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,QAAA,CAAS7H,EAAAA,GAOhC,CAAC,IAAA,CAAK,KAAA,CAAM,MAAA,EAAW6H,CAAAA,EAAQ,IAAA,CAAK,SAAA,CAAU,GAAA,CAAI7H,EAAAA,EAnCS,CAC7DA,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EACpC1L,EAAO,IAAA,CAAK0L,GACZ,QACF,CAuCA,IAAIuD,EAASpL,EACb,GAAI,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,YAAa,CACxC,IAAIqL,EAAa,EAAA,EACXC,EAAUtL,EAAI,KAAA,CAAM,GACtBuL,CACJ,CAAA,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,WAAA,CAAY,OAAA,CAASC,AAAAA,IAC3CD,AACyB,UAArB,MADJA,CAAAA,EAAYC,EAAc,IAAA,CAAK,CAAE,MAAO,IAAK,AAAA,EAAGF,EAAAA,GACXC,GAAa,GAChDF,CAAAA,EAAa,KAAK,GAAA,CAAIA,EAAYE,EAAAA,CAEtC,GACIF,EAAa,EAAA,GAAYA,GAAc,GACzCD,CAAAA,EAASpL,EAAI,SAAA,CAAU,EAAGqL,EAAa,EAAA,CAE3C,CACA,GAAIxD,EAAQ,IAAA,CAAK,SAAA,CAAU,UAAA,CAAWuD,GAAS,CAC7CpL,EAAMA,EAAI,SAAA,CAAU6H,EAAM,GAAA,CAAI,MAAM,EAChCA,AAAwB,MAAxBA,EAAM,GAAA,CAAI,KAAA,CAAM,KAClBwC,CAAAA,EAAWxC,EAAM,GAAA,CAAI,KAAA,CAAM,GAAA,EAE7B6D,EAAe,CAAA,EACf,IAAMjD,EAAYtM,EAAO,EAAA,CAAG,GACxBsM,CAAAA,GAAW,OAAS,OACtBA,CAAAA,EAAU,GAAA,EAAOZ,EAAM,GAAA,CACvBY,EAAU,IAAA,EAAQZ,EAAM,IAAA,AAAA,EAExB1L,EAAO,IAAA,CAAK0L,GAEd,QACF,CAEA,GAAI7H,EAAK,CACP,IAAMyL,EAAS,0BAA4BzL,EAAI,UAAA,CAAW,GAC1D,GAAI,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAQ,CACvB,QAAQ,KAAA,CAAMyL,GACd,KACF,CACE,MAAM,AAAI,MAAMA,EAEpB,CACF,CAEA,OAAOtP,CACT,CACF,EC5casH,GAAN,MACL,OACA,AAAA,CAAA,MACA,AAAA,aAAYpU,CAAAA,CAAuD,CACjE,IAAA,CAAK,OAAA,CAAUA,GAAWuU,CAC5B,CAEA,MAAMiE,CAAAA,CAAqC,CACzC,MAAO,EACT,CAEA,KAAK,CAAE,KAAA1Q,CAAAA,CAAM,KAAA0F,CAAAA,CAAM,QAAA6C,CAAQ,CAAA,CAAgC,CACzD,IAAMiM,EAAc9O,AAAAA,CAAAA,GAAQ,EAAA,EAAI,KAAA,CAAMf,EAAM,aAAa,GAAA,CAAI,EAAC,CAExDtF,EAAOW,EAAK,OAAA,CAAQ2E,EAAM,aAAA,CAAe,IAAM;AAAA,CAAA,CAErD,OAAK6P,EAME,8BACHlS,GAAOkS,GACP,KACCjM,CAAAA,EAAUlJ,EAAOiD,GAAOjD,EAAM,CAAA,EAAA,EAC/B,CAZiD;AAYjD,CAAA,CATK,cACFkJ,CAAAA,EAAUlJ,EAAOiD,GAAOjD,EAAM,CAAA,EAAA,EAC/B,CAOF;AAPE,CAQR,AAAA,CAEA,WAAW,CAAE,OAAA2F,CAAO,CAAA,CAAsC,CAExD,MAAO,CAZD;AAYC,EADM,IAAA,CAAK,MAAA,CAAO,KAAA,CAAMA,GACxB;AAAqB,CAC9B,AAAA,CAEA,KAAK,CAAE,KAAAhF,CAAK,CAAA,CAA6C,CACvD,OAAOA,CACT,CAEA,IAAI0Q,CAAAA,CAAmC,CACrC,MAAO,EACT,CAEA,QAAQ,CAAE,OAAA1L,CAAAA,CAAQ,MAAAY,CAAM,CAAA,CAAmC,CACzD,MAAO,CAAA,EAAA,EAAKA,EAAK,CAAA,EAAI,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYZ,GAAO,GAAA,EAAMY,EAZ9B;AAYmC,CACjE,AAAA,CAEA,GAAG8K,CAAAA,CAAkC,CACnC,MAAO,CAJwD;AAIxD,CACT,AAAA,CAEA,KAAKA,CAAAA,CAAoC,CACvC,IAAMpK,EAAUoK,EAAM,OAAA,CAChBnK,EAAQmK,EAAM,KAAA,CAEhB+D,EAAO,GACX,IAAA,IAASlW,EAAI,EAAGA,EAAImS,EAAM,KAAA,CAAM,MAAA,CAAQnS,IAAK,CAC3C,IAAMmU,EAAOhC,EAAM,KAAA,CAAMnS,EAAC,CAC1BkW,GAAQ,IAAA,CAAK,QAAA,CAAS/B,EACxB,CAEA,IAAM5N,EAAOwB,EAAU,KAAO,KAE9B,MAAO,IAAMxB,EADMwB,CAAAA,GAAWC,AAAU,IAAVA,EAAgB,WAAaA,EAAQ,IAAO,EAD1E,EAEgC,CAfzB;AAeyB,CAAA,CAAQkO,EAAO,KAAO3P,EAAO,CAA7B;AAA6B,CAC/D,AAAA,CAEA,SAAS4N,CAAAA,CAAuC,CAC9C,IAAIiC,EAAW,GACf,GAAIjC,EAAK,IAAA,CAAM,CACb,IAAM/I,EAAW,IAAA,CAAK,QAAA,CAAS,CAAE,QAAS,CAAC,CAAC+I,EAAK,OAAQ,AAAA,EACrDA,CAAAA,EAAK,KAAA,CACHA,EAAK,MAAA,CAAO,EAAC,EAAG,OAAS,YAC3BA,CAAAA,EAAK,MAAA,CAAO,EAAC,CAAE,IAAA,CAAO/I,EAAW,IAAM+I,EAAK,MAAA,CAAO,EAAC,CAAE,IAAA,CAClDA,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,EAAUA,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,CAAO,MAAA,CAAS,GAAKA,AAAkC,SAAlCA,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,CAAO,EAAC,CAAE,IAAA,EACxFA,CAAAA,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,CAAO,EAAC,CAAE,IAAA,CAAO/I,EAAW,IAAMrH,GAAOoQ,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,CAAO,EAAC,CAAE,IAAI,EACrFA,EAAK,MAAA,CAAO,EAAC,CAAE,MAAA,CAAO,EAAC,CAAE,OAAA,CAAU,CAAA,CAAA,CAAA,EAGrCA,EAAK,MAAA,CAAO,OAAA,CAAQ,CAClB,KAAM,OACN,IAAK/I,EAAW,IAChB,KAAMA,EAAW,IACjB,QAAS,CAAA,CACX,GAGFgL,GAAYhL,EAAW,GAE3B,CAEA,OAAAgL,GAAY,IAAA,CAAK,MAAA,CAAO,KAAA,CAAMjC,EAAK,MAAA,CAAQ,CAAC,CAACA,EAAK,KAAK,EAEhD,CAAA,IAAA,EAAOiC,EA7B+C;AA6BvC,CACxB,AAAA,CAEA,SAAS,CAAE,QAAArN,CAAQ,CAAA,CAAoC,CACrD,MAAO,UACFA,CAAAA,EAAU,cAAgB,EAAA,EAC3B,8BACN,CAEA,UAAU,CAAE,OAAAtC,CAAO,CAAA,CAAqC,CACtD,MAAO,CAAA,GAAA,EAAM,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYA,GAVf;AAUsB,CAC9C,AAAA,CAEA,MAAM0L,CAAAA,CAAqC,CACzC,IAAI9I,EAAS,GAGT+K,EAAO,GACX,IAAA,IAASpU,EAAI,EAAGA,EAAImS,EAAM,MAAA,CAAO,MAAA,CAAQnS,IACvCoU,GAAQ,IAAA,CAAK,SAAA,CAAUjC,EAAM,MAAA,CAAOnS,EAAE,EAExCqJ,GAAU,IAAA,CAAK,QAAA,CAAS,CAAE,KAAM+K,CAAqB,GAErD,IAAI8B,EAAO,GACX,IAAA,IAASlW,EAAI,EAAGA,EAAImS,EAAM,IAAA,CAAK,MAAA,CAAQnS,IAAK,CAC1C,IAAMuR,EAAMY,EAAM,IAAA,CAAKnS,EAAC,CAExBoU,EAAO,GACP,IAAA,IAAS1a,EAAI,EAAGA,EAAI6X,EAAI,MAAA,CAAQ7X,IAC9B0a,GAAQ,IAAA,CAAK,SAAA,CAAU7C,CAAAA,CAAI7X,EAAE,EAG/Bwc,GAAQ,IAAA,CAAK,QAAA,CAAS,CAAE,KAAM9B,CAAqB,EACrD,CACA,OAAI8B,GAAMA,CAAAA,EAAO,CAAA,OAAA,EAAUA,EAAI,QAAA,CAAA,AAAA,EAExB,CA1BqC;A;AA0BrC,CAAA,CAEH7M,EACA,CAHG;AAGH,CAAA,CACA6M,EACA,CAFA;AAEA,CACN,AAAA,CAEA,SAAS,CAAE,KAAAzU,CAAK,CAAA,CAAkD,CAChE,MAAO,CAJH;AAIG,EAASA,EAAT;AAAa,CACtB,AAAA,CAEA,UAAU0Q,CAAAA,CAAyC,CACjD,IAAMkE,EAAU,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYlE,EAAM,MAAM,EAC9C5L,EAAO4L,EAAM,MAAA,CAAS,KAAO,KAInC,MAHYA,AAAAA,CAAAA,EAAM,KAAA,CACd,CAAA,CAAA,EAAI5L,EAAI,QAAA,EAAW4L,EAAM,KAAK,CAAA,EAAA,CAAA,CAC9B,CAAA,CAAA,EAAI5L,EAAI,CAAA,CAAA,AAAA,EACC8P,EAAU,CAAA,EAAA,EAAK9P,EATR;AASY,CAClC,AAAA,CAKA,OAAO,CAAE,OAAAE,CAAO,CAAA,CAAkC,CAChD,MAAO,CAAA,QAAA,EAAW,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYA,GAAO,SAAA,CACnD,AAAA,CAEA,GAAG,CAAE,OAAAA,CAAO,CAAA,CAA8B,CACxC,MAAO,CAAA,IAAA,EAAO,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYA,GAAO,KAAA,CAC/C,AAAA,CAEA,SAAS,CAAE,KAAAhF,CAAK,CAAA,CAAoC,CAClD,MAAO,CAAA,MAAA,EAASsC,GAAOtC,EAAM,CAAA,GAAK,OAAA,CACpC,AAAA,CAEA,GAAG0Q,CAAAA,CAAkC,CACnC,MAAO,MACT,CAEA,IAAI,CAAE,OAAA1L,CAAO,CAAA,CAA+B,CAC1C,MAAO,CAAA,KAAA,EAAQ,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYA,GAAO,MAAA,CAChD,AAAA,CAEA,KAAK,CAAE,KAAAP,CAAAA,CAAM,MAAAC,CAAAA,CAAO,OAAAM,CAAO,CAAA,CAAgC,CACzD,IAAMhF,EAAO,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYgF,GAC/B6P,EAAYnF,GAASjL,GAC3B,GAAIoQ,AAAc,OAAdA,EACF,OAAO7U,EAGT,IAAI8U,EAAM,YADVrQ,CAAAA,EAAOoQ,CAAAA,EACwB,IAC/B,OAAInQ,GACFoQ,CAAAA,GAAO,WAAcxS,GAAOoC,GAAU,GAAA,EAExCoQ,GAAO,IAAM9U,EAAO,MAEtB,CAEA,MAAM,CAAE,KAAAyE,CAAAA,CAAM,MAAAC,CAAAA,CAAO,KAAA1E,CAAAA,CAAM,OAAAgF,CAAO,CAAA,CAAiC,CAC7DA,GACFhF,CAAAA,EAAO,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYgF,EAAQ,IAAA,CAAK,MAAA,CAAO,YAAY,CAAA,EAEjE,IAAM6P,EAAYnF,GAASjL,GAC3B,GAAIoQ,AAAc,OAAdA,EACF,OAAOvS,GAAOtC,GAEhByE,EAAOoQ,EAEP,IAAIC,EAAM,CAAA,UAAA,EAAarQ,EAAI,OAAA,EAAUzE,EAAI,CAAA,CAAA,CACzC,OAAI0E,GACFoQ,CAAAA,GAAO,CAAA,QAAA,EAAWxS,GAAOoC,GAAM,CAAA,CAAA,AAAA,EAEjCoQ,GAAO,GAET,CAEA,KAAKpE,CAAAA,CAAoD,CACvD,MAAO,WAAYA,GAASA,EAAM,MAAA,CAC9B,IAAA,CAAK,MAAA,CAAO,WAAA,CAAYA,EAAM,MAAM,EACnC,YAAaA,GAASA,EAAM,OAAA,CAAUA,EAAM,IAAA,CAAyBpO,GAAOoO,EAAM,IAAI,CAC7F,CACF,ECxNanE,GAAN,MAEL,OAAO,CAAE,KAAAvM,CAAK,CAAA,CAAkC,CAC9C,OAAOA,CACT,CAEA,GAAG,CAAE,KAAAA,CAAK,CAAA,CAA8B,CACtC,OAAOA,CACT,CAEA,SAAS,CAAE,KAAAA,CAAK,CAAA,CAAoC,CAClD,OAAOA,CACT,CAEA,IAAI,CAAE,KAAAA,CAAK,CAAA,CAA+B,CACxC,OAAOA,CACT,CAEA,KAAK,CAAE,KAAAA,CAAK,CAAA,CAA6C,CACvD,OAAOA,CACT,CAEA,KAAK,CAAE,KAAAA,CAAK,CAAA,CAA6D,CACvE,OAAOA,CACT,CAEA,KAAK,CAAE,KAAAA,CAAK,CAAA,CAAgC,CAC1C,MAAO,GAAKA,CACd,CAEA,MAAM,CAAE,KAAAA,CAAK,CAAA,CAAiC,CAC5C,MAAO,GAAKA,CACd,CAEA,IAAqB,CACnB,MAAO,EACT,CACF,EClCaqM,GAAN,MAAM0I,EACX,OACA,AAAA,CAAA,QACA,AAAA,CAAA,YACA,AAAA,aAAY7c,CAAAA,CAAuD,CACjE,IAAA,CAAK,OAAA,CAAUA,GAAWuU,EAC1B,IAAA,CAAK,OAAA,CAAQ,QAAA,CAAW,IAAA,CAAK,OAAA,CAAQ,QAAA,EAAY,IAAIH,GACrD,IAAA,CAAK,QAAA,CAAW,IAAA,CAAK,OAAA,CAAQ,QAAA,CAC7B,IAAA,CAAK,QAAA,CAAS,OAAA,CAAU,IAAA,CAAK,OAAA,CAC7B,IAAA,CAAK,QAAA,CAAS,MAAA,CAAS,IAAA,CACvB,IAAA,CAAK,YAAA,CAAe,IAAIC,EAC1B,CAKA,OAAO,MAAsDvH,CAAAA,CAAiB9M,CAAAA,CAAuD,CAEnI,OADe,IAAI6c,EAAsC7c,GAC3C,KAAA,CAAM8M,EACtB,CAKA,OAAO,YAA4DA,CAAAA,CAAiB9M,CAAAA,CAAuD,CAEzI,OADe,IAAI6c,EAAsC7c,GAC3C,WAAA,CAAY8M,EAC5B,CAKA,MAAMA,CAAAA,CAAiBgB,EAAM,CAAA,CAAA,CAAoB,CAC/C,IAAI8O,EAAM,GAEV,IAAA,IAASva,EAAI,EAAGA,EAAIyK,EAAO,MAAA,CAAQzK,IAAK,CACtC,IAAMya,EAAWhQ,CAAAA,CAAOzK,EAAC,CAGzB,GAAI,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,WAAA,CAAYya,EAAS,IAAI,CAAA,CAAG,CACvD,IACME,EAAM,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,SAAA,CAAUD,AADzBD,EACsC,IAAI,CAAA,CAAE,IAAA,CAAK,CAAE,OAAQ,IAAK,AAAA,EADhEA,GAErB,GAAIE,AAAQ,CAAA,IAARA,GAAiB,CAAC,CAAC,QAAS,KAAM,UAAW,OAAQ,QAAS,aAAc,OAAQ,OAAQ,MAAO,YAAa,OAAM,CAAE,QAAA,CAASD,AAFhHD,EAE6H,IAAI,EAAG,CACvJF,GAAOI,GAAO,GACd,QACF,CACF,CAIA,OAAQxE,AAFMsE,EAEA,IAAA,EACZ,IAAK,QACHF,GAAO,IAAA,CAAK,QAAA,CAAS,KAAA,CAJXE,GAKV,QAEF,KAAK,KACHF,GAAO,IAAA,CAAK,QAAA,CAAS,EAAA,CARXE,GASV,QAEF,KAAK,UACHF,GAAO,IAAA,CAAK,QAAA,CAAS,OAAA,CAZXE,GAaV,QAEF,KAAK,OACHF,GAAO,IAAA,CAAK,QAAA,CAAS,IAAA,CAhBXE,GAiBV,QAEF,KAAK,QACHF,GAAO,IAAA,CAAK,QAAA,CAAS,KAAA,CApBXE,GAqBV,QAEF,KAAK,aACHF,GAAO,IAAA,CAAK,QAAA,CAAS,UAAA,CAxBXE,GAyBV,QAEF,KAAK,OACHF,GAAO,IAAA,CAAK,QAAA,CAAS,IAAA,CA5BXE,GA6BV,QAEF,KAAK,OACHF,GAAO,IAAA,CAAK,QAAA,CAAS,IAAA,CAhCXE,GAiCV,QAEF,KAAK,MACHF,GAAO,IAAA,CAAK,QAAA,CAAS,GAAA,CApCXE,GAqCV,QAEF,KAAK,YACHF,GAAO,IAAA,CAAK,QAAA,CAAS,SAAA,CAxCXE,GAyCV,QAEF,KAAK,OAAQ,CACX,IAAIG,EA5CMH,EA6CNP,EAAO,IAAA,CAAK,QAAA,CAAS,IAAA,CAAKU,GAC9B,KAAO5a,EAAI,EAAIyK,EAAO,MAAA,EAAUA,AAAuB,SAAvBA,CAAAA,CAAOzK,EAAI,EAAC,CAAE,IAAA,EAC5C4a,EAAYnQ,CAAAA,CAAO,EAAEzK,EAAC,CACtBka,GAAS;AAAA,CAAA,CAAO,IAAA,CAAK,QAAA,CAAS,IAAA,CAAKU,EAEjCnP,CAAAA,EACF8O,GAAO,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,CAC7B,KAAM,YACN,IAAKL,EACL,KAAMA,EACN,OAAQ,CAAC,CAAE,KAAM,OAAQ,IAAKA,EAAM,KAAMA,EAAM,QAAS,CAAA,CAAK,EAChE,AAAA,GAEAK,GAAOL,EAET,QACF,CAEA,QAAS,CACP,IAAMH,EAAS,eAAiB5D,AAhEtBsE,EAgE4B,IAAA,CAAO,wBAC7C,GAAI,IAAA,CAAK,OAAA,CAAQ,MAAA,CACf,OAAA,QAAQ,KAAA,CAAMV,GACP,EAEP,OAAM,AAAI,MAAMA,EAEpB,CACF,CACF,CAEA,OAAOQ,CACT,CAKA,YAAY9P,CAAAA,CAAiBvL,EAAoF,IAAA,CAAK,QAAA,CAAwB,CAC5I,IAAIqb,EAAM,GAEV,IAAA,IAASva,EAAI,EAAGA,EAAIyK,EAAO,MAAA,CAAQzK,IAAK,CACtC,IAAMya,EAAWhQ,CAAAA,CAAOzK,EAAC,CAGzB,GAAI,IAAA,CAAK,OAAA,CAAQ,UAAA,EAAY,WAAA,CAAYya,EAAS,IAAI,CAAA,CAAG,CACvD,IAAME,EAAM,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,SAAA,CAAUF,EAAS,IAAI,CAAA,CAAE,IAAA,CAAK,CAAE,OAAQ,IAAK,AAAA,EAAGA,GACpF,GAAIE,AAAQ,CAAA,IAARA,GAAiB,CAAC,CAAC,SAAU,OAAQ,OAAQ,QAAS,SAAU,KAAM,WAAY,KAAM,MAAO,OAAM,CAAE,QAAA,CAASF,EAAS,IAAI,EAAG,CAClIF,GAAOI,GAAO,GACd,QACF,CACF,CAIA,OAAQxE,AAFMsE,EAEA,IAAA,EACZ,IAAK,SAoCL,IAAK,OAnCHF,GAAOrb,EAAS,IAAA,CAJNub,GAKV,KAEF,KAAK,OACHF,GAAOrb,EAAS,IAAA,CARNub,GASV,KAEF,KAAK,OACHF,GAAOrb,EAAS,IAAA,CAZNub,GAaV,KAEF,KAAK,QACHF,GAAOrb,EAAS,KAAA,CAhBNub,GAiBV,KAEF,KAAK,SACHF,GAAOrb,EAAS,MAAA,CApBNub,GAqBV,KAEF,KAAK,KACHF,GAAOrb,EAAS,EAAA,CAxBNub,GAyBV,KAEF,KAAK,WACHF,GAAOrb,EAAS,QAAA,CA5BNub,GA6BV,KAEF,KAAK,KACHF,GAAOrb,EAAS,EAAA,CAhCNub,GAiCV,KAEF,KAAK,MACHF,GAAOrb,EAAS,GAAA,CApCNub,GAqCV,KAMF,SAAS,CACP,IAAMV,EAAS,eAAiB5D,AA5CtBsE,EA4C4B,IAAA,CAAO,wBAC7C,GAAI,IAAA,CAAK,OAAA,CAAQ,MAAA,CACf,OAAA,QAAQ,KAAA,CAAMV,GACP,EAEP,OAAM,AAAI,MAAMA,EAEpB,CACF,CACF,CACA,OAAOQ,CACT,CACF,EC3Ma3I,GAAN,MACL,OACA,AAAA,CAAA,KAEA,AAAA,aAAYjU,CAAAA,CAAuD,CACjE,IAAA,CAAK,OAAA,CAAUA,GAAWuU,CAC5B,CAEA,OAAO,iBAAmB,IAAI,IAAI,CAChC,aACA,cACA,mBACA,eACD,CAED,AAAA,QAAO,6BAA+B,IAAI,IAAI,CAC5C,aACA,cACA,mBACD,CAKD,AAAA,CAAA,WAAW2I,CAAAA,CAAkB,CAC3B,OAAOA,CACT,CAKA,YAAY1V,CAAAA,CAAoB,CAC9B,OAAOA,CACT,CAKA,iBAAiBsF,CAAAA,CAA8B,CAC7C,OAAOA,CACT,CAKA,aAAa6D,CAAAA,CAAa,CACxB,OAAOA,CACT,CAKA,cAAe,CACb,OAAO,IAAA,CAAK,KAAA,CAAQuD,GAAO,GAAA,CAAMA,GAAO,SAC1C,AAAA,CAKA,eAAgB,CACd,OAAO,IAAA,CAAK,KAAA,CAAQC,GAAQ,KAAA,CAAsCA,GAAQ,WAC5E,AAAA,CACF,ECpDarV,GAAN,MACL,SAAW0V,GACX,AAAA,CAAA,QAAU,IAAA,CAAK,UAAA,AAEf,AAAA,CAAA,MAAQ,IAAA,CAAK,aAAA,CAAc,CAAA,EAC3B,AAAA,CAAA,YAAc,IAAA,CAAK,aAAA,CAAc,CAAA,EAEjC,AAAA,CAAA,OAASL,EACT,AAAA,CAAA,SAAWC,EACX,AAAA,CAAA,aAAeC,EACf,AAAA,CAAA,MAAQH,EACR,AAAA,CAAA,UAAYI,EACZ,AAAA,CAAA,MAAQL,EAER,AAAA,aAAA,GAAekJ,CAAAA,CAAuD,CACpE,IAAA,CAAK,GAAA,IAAOA,EACd,CAKA,WAAWrQ,CAAAA,CAA8BsQ,CAAAA,CAA2D,CAClG,IAAIC,EAAyB,EAAC,CAC9B,IAAA,IAAW7E,KAAS1L,EAElB,OADAuQ,EAASA,EAAO,MAAA,CAAOD,EAAS,IAAA,CAAK,IAAA,CAAM5E,IACnCA,EAAM,IAAA,EACZ,IAAK,QAEH,IAAA,IAAWiC,KAAQ6C,AADA9E,EACW,MAAA,CAC5B6E,EAASA,EAAO,MAAA,CAAO,IAAA,CAAK,UAAA,CAAW5C,EAAK,MAAA,CAAQ2C,IAEtD,IAAA,IAAWxF,KAAO0F,AAJC9E,EAIU,IAAA,CAC3B,IAAA,IAAWiC,KAAQ7C,EACjByF,EAASA,EAAO,MAAA,CAAO,IAAA,CAAK,UAAA,CAAW5C,EAAK,MAAA,CAAQ2C,IAGxD,KAEF,KAAK,OAEHC,EAASA,EAAO,MAAA,CAAO,IAAA,CAAK,UAAA,CAAWE,AADrB/E,EAC+B,KAAA,CAAO4E,IACxD,KAEF,SAAS,CACP,IAAML,EAAevE,CACjB,CAAA,IAAA,CAAK,QAAA,CAAS,UAAA,EAAY,aAAA,CAAcuE,EAAa,IAAI,CAAA,CAC3D,IAAA,CAAK,QAAA,CAAS,UAAA,CAAW,WAAA,CAAYA,EAAa,IAAI,CAAA,CAAE,OAAA,CAASnK,AAAAA,IAC/D,IAAM9F,EAASiQ,CAAAA,CAAanK,EAAW,CAAE,IAAA,CAAK,EAAA,GAC9CyK,EAASA,EAAO,MAAA,CAAO,IAAA,CAAK,UAAA,CAAWvQ,EAAQsQ,GACjD,GACSL,EAAa,MAAA,EACtBM,CAAAA,EAASA,EAAO,MAAA,CAAO,IAAA,CAAK,UAAA,CAAWN,EAAa,MAAA,CAAQK,GAAAA,CAEhE,CACF,CAEF,OAAOC,CACT,CAEA,IAAA,GAAOF,CAAAA,CAAuD,CAC5D,IAAMhc,EAAwE,IAAA,CAAK,QAAA,CAAS,UAAA,EAAc,CAAE,UAAW,CAAC,EAAG,YAAa,CAAC,CAAE,EAE3I,OAAAgc,EAAK,OAAA,CAASK,AAAAA,IAEZ,IAAMC,EAAO,CAAE,GAAGD,CAAK,AAAA,EA4DvB,GAzDAC,EAAK,KAAA,CAAQ,IAAA,CAAK,QAAA,CAAS,KAAA,EAASA,EAAK,KAAA,EAAS,CAAA,EAG9CD,EAAK,UAAA,EACPA,CAAAA,EAAK,UAAA,CAAW,OAAA,CAASE,AAAAA,IACvB,GAAI,CAACA,EAAI,IAAA,CACP,MAAM,AAAI,MAAM,2BAElB,GAAI,aAAcA,EAAK,CACrB,IAAMC,EAAexc,EAAW,SAAA,CAAUuc,EAAI,IAAI,CAAA,AAC9CC,CAAAA,EAEFxc,EAAW,SAAA,CAAUuc,EAAI,IAAI,CAAA,CAAI,SAAA,GAAYP,CAAAA,EAC3C,IAAIH,EAAMU,EAAI,QAAA,CAAS,KAAA,CAAM,IAAA,CAAMP,GACnC,MAAIH,AAAQ,CAAA,IAARA,GACFA,CAAAA,EAAMW,EAAa,KAAA,CAAM,IAAA,CAAMR,EAAAA,EAE1BH,CACT,EAEA7b,EAAW,SAAA,CAAUuc,EAAI,IAAI,CAAA,CAAIA,EAAI,QAEzC,AAAA,CACA,GAAI,cAAeA,EAAK,CACtB,GAAI,CAACA,EAAI,KAAA,EAAUA,AAAc,UAAdA,EAAI,KAAA,EAAqBA,AAAc,WAAdA,EAAI,KAAA,CAC9C,MAAM,AAAI,MAAM,+CAElB,IAAME,EAAWzc,CAAAA,CAAWuc,EAAI,KAAK,CAAA,AACjCE,CAAAA,EACFA,EAAS,OAAA,CAAQF,EAAI,SAAS,EAE9Bvc,CAAAA,CAAWuc,EAAI,KAAK,CAAA,CAAI,CAACA,EAAI,SAAS,CAAA,CAEpCA,EAAI,KAAA,EACFA,CAAAA,AAAc,UAAdA,EAAI,KAAA,CACFvc,EAAW,UAAA,CACbA,EAAW,UAAA,CAAW,IAAA,CAAKuc,EAAI,KAAK,EAEpCvc,EAAW,UAAA,CAAa,CAACuc,EAAI,KAAK,CAAA,CAE3BA,AAAc,WAAdA,EAAI,KAAA,EACTvc,CAAAA,EAAW,WAAA,CACbA,EAAW,WAAA,CAAY,IAAA,CAAKuc,EAAI,KAAK,EAErCvc,EAAW,WAAA,CAAc,CAACuc,EAAI,KAAK,CAAA,AAAA,CAAA,CAI3C,CACI,gBAAiBA,GAAOA,EAAI,WAAA,EAC9Bvc,CAAAA,EAAW,WAAA,CAAYuc,EAAI,IAAI,CAAA,CAAIA,EAAI,WAAA,AAAA,CAE3C,GACAD,EAAK,UAAA,CAAatc,CAAAA,EAIhBqc,EAAK,QAAA,CAAU,CACjB,IAAMjc,EAAW,IAAA,CAAK,QAAA,CAAS,QAAA,EAAY,IAAI6S,GAAwC,IAAA,CAAK,QAAQ,EACpG,IAAA,IAAWyJ,KAAQL,EAAK,QAAA,CAAU,CAChC,GAAI,CAAEK,CAAAA,KAAQtc,CAAAA,EACZ,MAAM,AAAI,MAAM,CAAA,UAAA,EAAasc,EAAI,gBAAA,CAAkB,EAErD,GAAI,CAAC,UAAW,SAAQ,CAAE,QAAA,CAASA,GAEjC,SAEF,IACME,EAAeP,EAAK,QAAA,CADLK,EAC0B,CACzCF,EAAepc,CAAAA,CAFAsc,EAEqB,AAE1Ctc,CAAAA,CAAAA,CAJqBsc,EAIA,CAAI,CAAA,GAAIV,KAC3B,IAAIH,EAAMe,EAAa,KAAA,CAAMxc,EAAU4b,GACvC,MAAIH,AAAQ,CAAA,IAARA,GACFA,CAAAA,EAAMW,EAAa,KAAA,CAAMpc,EAAU4b,EAAAA,EAE7BH,GAAO,EACjB,CACF,CACAS,EAAK,QAAA,CAAWlc,CAClB,CACA,GAAIic,EAAK,SAAA,CAAW,CAClB,IAAM/b,EAAY,IAAA,CAAK,QAAA,CAAS,SAAA,EAAa,IAAI6S,GAAyC,IAAA,CAAK,QAAQ,EACvG,IAAA,IAAWuJ,KAAQL,EAAK,SAAA,CAAW,CACjC,GAAI,CAAEK,CAAAA,KAAQpc,CAAAA,EACZ,MAAM,AAAI,MAAM,CAAA,WAAA,EAAcoc,EAAI,gBAAA,CAAkB,EAEtD,GAAI,CAAC,UAAW,QAAS,QAAO,CAAE,QAAA,CAASA,GAEzC,SAEF,IACMI,EAAgBT,EAAK,SAAA,CADLK,EAC4B,CAC5CK,EAAgBzc,CAAAA,CAFAoc,EAEuB,AAG7Cpc,CAAAA,CAAAA,CALsBoc,EAKC,CAAI,CAAA,GAAIV,KAC7B,IAAIH,EAAMiB,EAAc,KAAA,CAAMxc,EAAW0b,GACzC,MAAIH,AAAQ,CAAA,IAARA,GACFA,CAAAA,EAAMkB,EAAc,KAAA,CAAMzc,EAAW0b,EAAAA,EAEhCH,CACT,CACF,CACAS,EAAK,SAAA,CAAYhc,CACnB,CAGA,GAAI+b,EAAK,KAAA,CAAO,CACd,IAAMnc,EAAQ,IAAA,CAAK,QAAA,CAAS,KAAA,EAAS,IAAI4S,GACzC,IAAA,IAAW4J,KAAQL,EAAK,KAAA,CAAO,CAC7B,GAAI,CAAEK,CAAAA,KAAQxc,CAAAA,EACZ,MAAM,AAAI,MAAM,CAAA,MAAA,EAASwc,EAAI,gBAAA,CAAkB,EAEjD,GAAI,CAAC,UAAW,QAAO,CAAE,QAAA,CAASA,GAEhC,SAEF,IACMO,EAAYZ,EAAK,KAAA,CADLK,EACoB,CAChCQ,EAAWhd,CAAAA,CAFCwc,EAEc,AAC5B5J,CAAAA,GAAO,gBAAA,CAAiB,GAAA,CAAI4J,GAE9Bxc,CAAAA,CALgBwc,EAKD,CAAKS,AAAAA,IAClB,GAAI,IAAA,CAAK,QAAA,CAAS,KAAA,EAASrK,GAAO,4BAAA,CAA6B,GAAA,CAAI4J,GACjE,MAAQ,AAAA,CAAA,UACN,IAAMb,EAAM,MAAMoB,EAAU,IAAA,CAAK/c,EAAOid,GACxC,OAAOD,EAAS,IAAA,CAAKhd,EAAO2b,EAC9B,CAAA,IAGF,IAAMA,EAAMoB,EAAU,IAAA,CAAK/c,EAAOid,GAClC,OAAOD,EAAS,IAAA,CAAKhd,EAAO2b,EAC9B,EAGA3b,CAAAA,CAlBgBwc,EAkBD,CAAI,CAAA,GAAIV,KACrB,GAAI,IAAA,CAAK,QAAA,CAAS,KAAA,CAChB,MAAA,AAAQ,CAAA,UACN,IAAIH,EAAM,MAAMoB,EAAU,KAAA,CAAM/c,EAAO8b,GACvC,MAAIH,AAAQ,CAAA,IAARA,GACFA,CAAAA,EAAM,MAAMqB,EAAS,KAAA,CAAMhd,EAAO8b,EAAAA,EAE7BH,CACT,CAAA,IAGF,IAAIA,EAAMoB,EAAU,KAAA,CAAM/c,EAAO8b,GACjC,MAAIH,AAAQ,CAAA,IAARA,GACFA,CAAAA,EAAMqB,EAAS,KAAA,CAAMhd,EAAO8b,EAAAA,EAEvBH,CACT,CAEJ,CACAS,EAAK,KAAA,CAAQpc,CACf,CAGA,GAAImc,EAAK,UAAA,CAAY,CACnB,IAAM5c,EAAa,IAAA,CAAK,QAAA,CAAS,UAAA,CAC3B2d,EAAiBf,EAAK,UAAA,AAC5BC,CAAAA,EAAK,UAAA,CAAa,SAASjF,CAAAA,EACzB,IAAI6E,EAAyB,EAAC,CAC9B,OAAAA,EAAO,IAAA,CAAKkB,EAAe,IAAA,CAAK,IAAA,CAAM/F,IAClC5X,GACFyc,CAAAA,EAASA,EAAO,MAAA,CAAOzc,EAAW,IAAA,CAAK,IAAA,CAAM4X,GAAAA,EAExC6E,CACT,CACF,CAEA,IAAA,CAAK,QAAA,CAAW,CAAE,GAAG,IAAA,CAAK,QAAA,CAAU,GAAGI,CAAK,AAAA,CAC9C,GAEO,IACT,AAAA,CAEA,WAAW1I,CAAAA,CAAkD,CAC3D,OAAA,IAAA,CAAK,QAAA,CAAW,CAAE,GAAG,IAAA,CAAK,QAAA,CAAU,GAAGA,CAAI,AAAA,EACpC,IACT,AAAA,CAEA,MAAMpE,CAAAA,CAAa3Q,CAAAA,CAAuD,CACxE,OAAOkU,GAAO,GAAA,CAAIvD,EAAK3Q,GAAW,IAAA,CAAK,QAAQ,CACjD,CAEA,OAAO8M,CAAAA,CAAiB9M,CAAAA,CAAuD,CAC7E,OAAOmU,GAAQ,KAAA,CAAoCrH,EAAQ9M,GAAW,IAAA,CAAK,QAAQ,CACrF,CAEQ,cAAcwe,CAAAA,CAAoB,CAuExC,MA/D+B,CAAC7N,EAAa3Q,KAC3C,IAAMye,EAAU,CAAE,GAAGze,CAAQ,AAAA,EACvB+U,EAAM,CAAE,GAAG,IAAA,CAAK,QAAA,CAAU,GAAG0J,CAAQ,AAAA,EAErCC,EAAa,IAAA,CAAK,OAAA,CAAQ,CAAC,CAAC3J,EAAI,MAAA,CAAQ,CAAC,CAACA,EAAI,KAAK,EAGzD,GAAI,AAAwB,CAAA,IAAxB,IAAA,CAAK,QAAA,CAAS,KAAA,EAAkB0J,AAAkB,CAAA,IAAlBA,EAAQ,KAAA,CAC1C,OAAOC,EAAW,AAAI,MAAM,uIAI9B,GAAI,OAAO/N,EAAQ,KAAeA,AAAQ,OAARA,EAChC,OAAO+N,EAAW,AAAI,MAAM,mDAE9B,GAAI,AAAe,UAAf,OAAO/N,EACT,OAAO+N,EAAW,AAAI,MAAM,wCACxB,OAAO,SAAA,CAAU,QAAA,CAAS,IAAA,CAAK/N,GAAO,sBAQ5C,GALIoE,EAAI,KAAA,EACNA,CAAAA,EAAI,KAAA,CAAM,OAAA,CAAUA,EACpBA,EAAI,KAAA,CAAM,KAAA,CAAQyJ,CAAAA,EAGhBzJ,EAAI,KAAA,CACN,MAAA,AAAQ,CAAA,UACN,IAAM4J,EAAe5J,EAAI,KAAA,CAAQ,MAAMA,EAAI,KAAA,CAAM,UAAA,CAAWpE,GAAOA,EAE7D7D,EAAS,MAAA,AADDiI,CAAAA,EAAI,KAAA,CAAQ,MAAMA,EAAI,KAAA,CAAM,YAAA,GAAkByJ,EAAYtK,GAAO,GAAA,CAAMA,GAAO,SAAA,AAAA,EACjEyK,EAAc5J,GACnC6J,EAAkB7J,EAAI,KAAA,CAAQ,MAAMA,EAAI,KAAA,CAAM,gBAAA,CAAiBjI,GAAUA,CAC3EiI,CAAAA,EAAI,UAAA,EACN,MAAM,QAAQ,GAAA,CAAI,IAAA,CAAK,UAAA,CAAW6J,EAAiB7J,EAAI,UAAU,GAGnE,IAAMvN,EAAO,MAAA,AADEuN,CAAAA,EAAI,KAAA,CAAQ,MAAMA,EAAI,KAAA,CAAM,aAAA,GAAmByJ,EAAYrK,GAAQ,KAAA,CAAQA,GAAQ,WAAA,AAAA,EACxEyK,EAAiB7J,GAC3C,OAAOA,EAAI,KAAA,CAAQ,MAAMA,EAAI,KAAA,CAAM,WAAA,CAAYvN,GAAQA,CACzD,CAAA,IAAK,KAAA,CAAMkX,GAGb,GAAI,CACE3J,EAAI,KAAA,EACNpE,CAAAA,EAAMoE,EAAI,KAAA,CAAM,UAAA,CAAWpE,EAAAA,EAG7B,IAAI7D,EAAAA,AADUiI,CAAAA,EAAI,KAAA,CAAQA,EAAI,KAAA,CAAM,YAAA,GAAkByJ,EAAYtK,GAAO,GAAA,CAAMA,GAAO,SAAA,AAAA,EACnEvD,EAAKoE,EACpBA,CAAAA,EAAI,KAAA,EACNjI,CAAAA,EAASiI,EAAI,KAAA,CAAM,gBAAA,CAAiBjI,EAAAA,EAElCiI,EAAI,UAAA,EACN,IAAA,CAAK,UAAA,CAAWjI,EAAQiI,EAAI,UAAU,EAGxC,IAAIvN,EAAAA,AADWuN,CAAAA,EAAI,KAAA,CAAQA,EAAI,KAAA,CAAM,aAAA,GAAmByJ,EAAYrK,GAAQ,KAAA,CAAQA,GAAQ,WAAA,AAAA,EAC1ErH,EAAQiI,GAC1B,OAAIA,EAAI,KAAA,EACNvN,CAAAA,EAAOuN,EAAI,KAAA,CAAM,WAAA,CAAYvN,EAAAA,EAExBA,CACT,CAAA,MAAQ/I,EAAG,CACT,OAAOigB,EAAWjgB,EACpB,CACF,CAGF,CAEQ,QAAQ+C,CAAAA,CAAiBP,CAAAA,CAAgB,CAC/C,OAAQxC,AAAAA,IAGN,GAFAA,EAAE,OAAA,EAAW;AAAA,yDAAA,CAAA,CAET+C,EAAQ,CACV,IAAMqd,EAAM,iCACRzU,GAAO3L,EAAE,OAAA,CAAU,GAAI,CAAA,GACvB,SACJ,OAAIwC,EACK,QAAQ,OAAA,CAAQ4d,GAElBA,CACT,CAEA,GAAI5d,EACF,OAAO,QAAQ,MAAA,CAAOxC,EAExB,OAAMA,CACR,CACF,CACF,EVhWMqgB,GAAiB,IAAIhgB,GAqBpB,SAASgB,GAAO6Q,CAAAA,CAAaoE,CAAAA,EAClC,OAAO+J,GAAe,KAAA,CAAMnO,EAAKoE,EACnC,CAOAjV,GAAO,OAAA,CACPA,GAAO,UAAA,CAAa,SAASE,CAAAA,EAC3B,OAAA8e,GAAe,UAAA,CAAW9e,GAC1BF,GAAO,QAAA,CAAWgf,GAAe,QAAA,CC1BjCvK,ED2BezU,GAAO,QAAQ,CACvBA,EACT,EAKAA,GAAO,WAAA,CAAc0U,EAErB1U,GAAO,QAAA,CAAWyU,EAMlBzU,GAAO,GAAA,CAAM,SAAA,GAAYqd,CAAAA,EACvB,OAAA2B,GAAe,GAAA,IAAO3B,GACtBrd,GAAO,QAAA,CAAWgf,GAAe,QAAA,CC5CjCvK,ED6CezU,GAAO,QAAQ,CACvBA,EACT,EAMAA,GAAO,UAAA,CAAa,SAASgN,CAAAA,CAA8BsQ,CAAAA,EACzD,OAAO0B,GAAe,UAAA,CAAWhS,EAAQsQ,EAC3C,EASAtd,GAAO,WAAA,CAAcgf,GAAe,WAAA,CAKpChf,GAAO,MAAA,CAASqU,GAChBrU,GAAO,MAAA,CAASqU,GAAQ,KAAA,CACxBrU,GAAO,QAAA,CAAWsU,GAClBtU,GAAO,YAAA,CAAeuU,GACtBvU,GAAO,KAAA,CAAQoU,GACfpU,GAAO,KAAA,CAAQoU,GAAO,GAAA,CACtBpU,GAAO,SAAA,CAAYwU,GACnBxU,GAAO,KAAA,CAAQmU,GACfnU,GAAO,KAAA,CAAQA,GAER,IAAME,GAAUF,GAAO,OAAA,CACjBU,GAAaV,GAAO,UAAA,CACpBY,GAAMZ,GAAO,GAAA,CACbc,GAAad,GAAO,UAAA,CACpBM,GAAcN,GAAO,WAAA,CACrBI,GAAQJ,GACRQ,GAAS6T,GAAQ,KAAA,CACjBvU,GAAQsU,GAAO,GUiPT,C,O,E,O,A,IZ5VnB,IAAI,EAAO,CAAC;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,AACD,CAAA,SAAS,cAAc,CAAC,cAAc,SAAS,CAC3C,AAAA,EAAA,MAAK,CAAE,KAAK,CAAC","sources":["<anon>","src/scripts/cv.js","node_modules/marked/lib/marked.umd.js","node_modules/marked/src/marked.ts","node_modules/marked/src/defaults.ts","node_modules/marked/src/rules.ts","node_modules/marked/src/helpers.ts","node_modules/marked/src/Tokenizer.ts","node_modules/marked/src/Lexer.ts","node_modules/marked/src/Renderer.ts","node_modules/marked/src/TextRenderer.ts","node_modules/marked/src/Parser.ts","node_modules/marked/src/Hooks.ts","node_modules/marked/src/Instance.ts"],"sourcesContent":["var $d55025bea272cdc1$exports = {};\n/**\n * marked v16.4.1 - a markdown parser\n * Copyright (c) 2011-2025, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */ /**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */ (function(g, f) {\n    $d55025bea272cdc1$exports = f();\n})(typeof globalThis < \"u\" ? globalThis : typeof self < \"u\" ? self : $d55025bea272cdc1$exports, function() {\n    var exports = {};\n    var __exports = exports;\n    var module1 = {\n        exports: exports\n    };\n    \"use strict\";\n    var G = Object.defineProperty;\n    var Re = Object.getOwnPropertyDescriptor;\n    var Te = Object.getOwnPropertyNames;\n    var Oe = Object.prototype.hasOwnProperty;\n    var we = (l, e)=>{\n        for(var t in e)G(l, t, {\n            get: e[t],\n            enumerable: !0\n        });\n    }, ye = (l, e, t, n)=>{\n        if (e && typeof e == \"object\" || typeof e == \"function\") for (let r of Te(e))!Oe.call(l, r) && r !== t && G(l, r, {\n            get: ()=>e[r],\n            enumerable: !(n = Re(e, r)) || n.enumerable\n        });\n        return l;\n    };\n    var Pe = (l)=>ye(G({}, \"__esModule\", {\n            value: !0\n        }), l);\n    var kt = {};\n    we(kt, {\n        Hooks: ()=>S,\n        Lexer: ()=>x,\n        Marked: ()=>A,\n        Parser: ()=>b,\n        Renderer: ()=>P,\n        TextRenderer: ()=>$,\n        Tokenizer: ()=>y,\n        defaults: ()=>T,\n        getDefaults: ()=>_,\n        lexer: ()=>dt,\n        marked: ()=>k,\n        options: ()=>ot,\n        parse: ()=>ct,\n        parseInline: ()=>pt,\n        parser: ()=>ht,\n        setOptions: ()=>at,\n        use: ()=>lt,\n        walkTokens: ()=>ut\n    });\n    module1.exports = Pe(kt);\n    function _() {\n        return {\n            async: !1,\n            breaks: !1,\n            extensions: null,\n            gfm: !0,\n            hooks: null,\n            pedantic: !1,\n            renderer: null,\n            silent: !1,\n            tokenizer: null,\n            walkTokens: null\n        };\n    }\n    var T = _();\n    function N(l) {\n        T = l;\n    }\n    var E = {\n        exec: ()=>null\n    };\n    function h(l, e = \"\") {\n        let t = typeof l == \"string\" ? l : l.source, n = {\n            replace: (r, i)=>{\n                let s = typeof i == \"string\" ? i : i.source;\n                return s = s.replace(m.caret, \"$1\"), t = t.replace(r, s), n;\n            },\n            getRegex: ()=>new RegExp(t, e)\n        };\n        return n;\n    }\n    var m = {\n        codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n        outputLinkReplace: /\\\\([\\[\\]])/g,\n        indentCodeCompensation: /^(\\s+)(?:```)/,\n        beginningSpace: /^\\s+/,\n        endingHash: /#$/,\n        startingSpaceChar: /^ /,\n        endingSpaceChar: / $/,\n        nonSpaceChar: /[^ ]/,\n        newLineCharGlobal: /\\n/g,\n        tabCharGlobal: /\\t/g,\n        multipleSpaceGlobal: /\\s+/g,\n        blankLine: /^[ \\t]*$/,\n        doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n        blockquoteStart: /^ {0,3}>/,\n        blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n        blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n        listReplaceTabs: /^\\t+/,\n        listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n        listIsTask: /^\\[[ xX]\\] /,\n        listReplaceTask: /^\\[[ xX]\\] +/,\n        anyLine: /\\n.*\\n/,\n        hrefBrackets: /^<(.*)>$/,\n        tableDelimiter: /[:|]/,\n        tableAlignChars: /^\\||\\| *$/g,\n        tableRowBlankLine: /\\n[ \\t]*$/,\n        tableAlignRight: /^ *-+: *$/,\n        tableAlignCenter: /^ *:-+: *$/,\n        tableAlignLeft: /^ *:-+ *$/,\n        startATag: /^<a /i,\n        endATag: /^<\\/a>/i,\n        startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n        endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n        startAngleBracket: /^</,\n        endAngleBracket: />$/,\n        pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n        unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n        escapeTest: /[&<>\"']/,\n        escapeReplace: /[&<>\"']/g,\n        escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n        escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n        unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n        caret: /(^|[^\\[])\\^/g,\n        percentDecode: /%25/g,\n        findPipe: /\\|/g,\n        splitPipe: / \\|/,\n        slashPipe: /\\\\\\|/g,\n        carriageReturn: /\\r\\n|\\r/g,\n        spaceLine: /^ +$/gm,\n        notSpaceStart: /^\\S*/,\n        endingNewline: /\\n$/,\n        listItemRegex: (l)=>new RegExp(`^( {0,3}${l})((?:[\t ][^\\\\n]*)?(?:\\\\n|$))`),\n        nextBulletRegex: (l)=>new RegExp(`^ {0,${Math.min(3, l - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \t][^\\\\n]*)?(?:\\\\n|$))`),\n        hrRegex: (l)=>new RegExp(`^ {0,${Math.min(3, l - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n        fencesBeginRegex: (l)=>new RegExp(`^ {0,${Math.min(3, l - 1)}}(?:\\`\\`\\`|~~~)`),\n        headingBeginRegex: (l)=>new RegExp(`^ {0,${Math.min(3, l - 1)}}#`),\n        htmlBeginRegex: (l)=>new RegExp(`^ {0,${Math.min(3, l - 1)}}<(?:[a-z].*>|!--)`, \"i\")\n    }, Se = /^(?:[ \\t]*(?:\\n|$))+/, $e = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/, _e = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/, C = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/, Le = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/, j = /(?:[*+-]|\\d{1,9}[.)])/, oe = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/, ae = h(oe).replace(/bull/g, j).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/\\|table/g, \"\").getRegex(), Me = h(oe).replace(/bull/g, j).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/).getRegex(), Q = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/, ze = /^[^\\n]+/, U = /(?!\\s*\\])(?:\\\\[\\s\\S]|[^\\[\\]\\\\])+/, Ae = h(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/).replace(\"label\", U).replace(\"title\", /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/).getRegex(), Ie = h(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/).replace(/bull/g, j).getRegex(), v = \"address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul\", K = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/, Ee = h(\"^ {0,3}(?:<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)|comment[^\\\\n]*(\\\\n+|$)|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$))\", \"i\").replace(\"comment\", K).replace(\"tag\", v).replace(\"attribute\", / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/).getRegex(), le = h(Q).replace(\"hr\", C).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", v).getRegex(), Ce = h(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/).replace(\"paragraph\", le).getRegex(), W = {\n        blockquote: Ce,\n        code: $e,\n        def: Ae,\n        fences: _e,\n        heading: Le,\n        hr: C,\n        html: Ee,\n        lheading: ae,\n        list: Ie,\n        newline: Se,\n        paragraph: le,\n        table: E,\n        text: ze\n    }, se = h(\"^ *([^\\\\n ].*)\\\\n {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\").replace(\"hr\", C).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"blockquote\", \" {0,3}>\").replace(\"code\", \"(?: {4}| {0,3}\t)[^\\\\n]\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", v).getRegex(), Be = {\n        ...W,\n        lheading: Me,\n        table: se,\n        paragraph: h(Q).replace(\"hr\", C).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"table\", se).replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", v).getRegex()\n    }, qe = {\n        ...W,\n        html: h(`^ *(?:comment *(?:\\\\n|\\\\s*$)|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\\\s[^'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))`).replace(\"comment\", K).replace(/tag/g, \"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\").getRegex(),\n        def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n        heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n        fences: E,\n        lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n        paragraph: h(Q).replace(\"hr\", C).replace(\"heading\", ` *#{1,6} *[^\n]`).replace(\"lheading\", ae).replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"|fences\", \"\").replace(\"|list\", \"\").replace(\"|html\", \"\").replace(\"|tag\", \"\").getRegex()\n    }, ve = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/, De = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/, ue = /^( {2,}|\\\\)\\n(?!\\s*$)/, He = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/, D = /[\\p{P}\\p{S}]/u, X = /[\\s\\p{P}\\p{S}]/u, pe = /[^\\s\\p{P}\\p{S}]/u, Ze = h(/^((?![*_])punctSpace)/, \"u\").replace(/punctSpace/g, X).getRegex(), ce = /(?!~)[\\p{P}\\p{S}]/u, Ge = /(?!~)[\\s\\p{P}\\p{S}]/u, Ne = /(?:[^\\s\\p{P}\\p{S}]|~)/u, Fe = h(/link|code|html/, \"g\").replace(\"link\", /\\[(?:[^\\[\\]`]|(?<!`)(?<a>`+)[^`]+\\k<a>(?!`))*?\\]\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)]|\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)])*\\))*\\)/).replace(\"code\", /(?<!`)(?<b>`+)[^`]+\\k<b>(?!`)/).replace(\"html\", /<(?! )[^<>]*?>/).getRegex(), he = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/, je = h(he, \"u\").replace(/punct/g, D).getRegex(), Qe = h(he, \"u\").replace(/punct/g, ce).getRegex(), de = \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)|[^*]+(?=[^*])|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)|notPunctSpace(\\\\*+)(?=notPunctSpace)\", Ue = h(de, \"gu\").replace(/notPunctSpace/g, pe).replace(/punctSpace/g, X).replace(/punct/g, D).getRegex(), Ke = h(de, \"gu\").replace(/notPunctSpace/g, Ne).replace(/punctSpace/g, Ge).replace(/punct/g, ce).getRegex(), We = h(\"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)|[^_]+(?=[^_])|(?!_)punct(_+)(?=[\\\\s]|$)|notPunctSpace(_+)(?!_)(?=punctSpace|$)|(?!_)punctSpace(_+)(?=notPunctSpace)|[\\\\s](_+)(?!_)(?=punct)|(?!_)punct(_+)(?!_)(?=punct)\", \"gu\").replace(/notPunctSpace/g, pe).replace(/punctSpace/g, X).replace(/punct/g, D).getRegex(), Xe = h(/\\\\(punct)/, \"gu\").replace(/punct/g, D).getRegex(), Je = h(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/).replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/).replace(\"email\", /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/).getRegex(), Ve = h(K).replace(\"(?:-->|$)\", \"-->\").getRegex(), Ye = h(\"^comment|^</[a-zA-Z][\\\\w:-]*\\\\s*>|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>|^<\\\\?[\\\\s\\\\S]*?\\\\?>|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\").replace(\"comment\", Ve).replace(\"attribute\", /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/).getRegex(), q = /(?:\\[(?:\\\\[\\s\\S]|[^\\[\\]\\\\])*\\]|\\\\[\\s\\S]|`+[^`]*?`+(?!`)|[^\\[\\]\\\\`])*?/, et = h(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/).replace(\"label\", q).replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/).replace(\"title\", /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/).getRegex(), ke = h(/^!?\\[(label)\\]\\[(ref)\\]/).replace(\"label\", q).replace(\"ref\", U).getRegex(), ge = h(/^!?\\[(ref)\\](?:\\[\\])?/).replace(\"ref\", U).getRegex(), tt = h(\"reflink|nolink(?!\\\\()\", \"g\").replace(\"reflink\", ke).replace(\"nolink\", ge).getRegex(), ie = /[hH][tT][tT][pP][sS]?|[fF][tT][pP]/, J = {\n        _backpedal: E,\n        anyPunctuation: Xe,\n        autolink: Je,\n        blockSkip: Fe,\n        br: ue,\n        code: De,\n        del: E,\n        emStrongLDelim: je,\n        emStrongRDelimAst: Ue,\n        emStrongRDelimUnd: We,\n        escape: ve,\n        link: et,\n        nolink: ge,\n        punctuation: Ze,\n        reflink: ke,\n        reflinkSearch: tt,\n        tag: Ye,\n        text: He,\n        url: E\n    }, nt = {\n        ...J,\n        link: h(/^!?\\[(label)\\]\\((.*?)\\)/).replace(\"label\", q).getRegex(),\n        reflink: h(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/).replace(\"label\", q).getRegex()\n    }, F = {\n        ...J,\n        emStrongRDelimAst: Ke,\n        emStrongLDelim: Qe,\n        url: h(/^((?:protocol):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/).replace(\"protocol\", ie).replace(\"email\", /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/).getRegex(),\n        _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n        del: /^(~~?)(?=[^\\s~])((?:\\\\[\\s\\S]|[^\\\\])*?(?:\\\\[\\s\\S]|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n        text: h(/^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|protocol:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/).replace(\"protocol\", ie).getRegex()\n    }, rt = {\n        ...F,\n        br: h(ue).replace(\"{2,}\", \"*\").getRegex(),\n        text: h(F.text).replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\").replace(/\\{2,\\}/g, \"*\").getRegex()\n    }, B = {\n        normal: W,\n        gfm: Be,\n        pedantic: qe\n    }, M = {\n        normal: J,\n        gfm: F,\n        breaks: rt,\n        pedantic: nt\n    };\n    var st = {\n        \"&\": \"&amp;\",\n        \"<\": \"&lt;\",\n        \">\": \"&gt;\",\n        '\"': \"&quot;\",\n        \"'\": \"&#39;\"\n    }, fe = (l)=>st[l];\n    function w(l, e) {\n        if (e) {\n            if (m.escapeTest.test(l)) return l.replace(m.escapeReplace, fe);\n        } else if (m.escapeTestNoEncode.test(l)) return l.replace(m.escapeReplaceNoEncode, fe);\n        return l;\n    }\n    function V(l) {\n        try {\n            l = encodeURI(l).replace(m.percentDecode, \"%\");\n        } catch  {\n            return null;\n        }\n        return l;\n    }\n    function Y(l, e) {\n        let t = l.replace(m.findPipe, (i, s, o)=>{\n            let a = !1, u = s;\n            for(; --u >= 0 && o[u] === \"\\\\\";)a = !a;\n            return a ? \"|\" : \" |\";\n        }), n = t.split(m.splitPipe), r = 0;\n        if (n[0].trim() || n.shift(), n.length > 0 && !n.at(-1)?.trim() && n.pop(), e) {\n            if (n.length > e) n.splice(e);\n            else for(; n.length < e;)n.push(\"\");\n        }\n        for(; r < n.length; r++)n[r] = n[r].trim().replace(m.slashPipe, \"|\");\n        return n;\n    }\n    function z(l, e, t) {\n        let n = l.length;\n        if (n === 0) return \"\";\n        let r = 0;\n        for(; r < n;){\n            let i = l.charAt(n - r - 1);\n            if (i === e && !t) r++;\n            else if (i !== e && t) r++;\n            else break;\n        }\n        return l.slice(0, n - r);\n    }\n    function me(l, e) {\n        if (l.indexOf(e[1]) === -1) return -1;\n        let t = 0;\n        for(let n = 0; n < l.length; n++)if (l[n] === \"\\\\\") n++;\n        else if (l[n] === e[0]) t++;\n        else if (l[n] === e[1] && (t--, t < 0)) return n;\n        return t > 0 ? -2 : -1;\n    }\n    function xe(l, e, t, n, r) {\n        let i = e.href, s = e.title || null, o = l[1].replace(r.other.outputLinkReplace, \"$1\");\n        n.state.inLink = !0;\n        let a = {\n            type: l[0].charAt(0) === \"!\" ? \"image\" : \"link\",\n            raw: t,\n            href: i,\n            title: s,\n            text: o,\n            tokens: n.inlineTokens(o)\n        };\n        return n.state.inLink = !1, a;\n    }\n    function it(l, e, t) {\n        let n = l.match(t.other.indentCodeCompensation);\n        if (n === null) return e;\n        let r = n[1];\n        return e.split(`\n`).map((i)=>{\n            let s = i.match(t.other.beginningSpace);\n            if (s === null) return i;\n            let [o] = s;\n            return o.length >= r.length ? i.slice(r.length) : i;\n        }).join(`\n`);\n    }\n    var y = class {\n        options;\n        rules;\n        lexer;\n        constructor(e){\n            this.options = e || T;\n        }\n        space(e) {\n            let t = this.rules.block.newline.exec(e);\n            if (t && t[0].length > 0) return {\n                type: \"space\",\n                raw: t[0]\n            };\n        }\n        code(e) {\n            let t = this.rules.block.code.exec(e);\n            if (t) {\n                let n = t[0].replace(this.rules.other.codeRemoveIndent, \"\");\n                return {\n                    type: \"code\",\n                    raw: t[0],\n                    codeBlockStyle: \"indented\",\n                    text: this.options.pedantic ? n : z(n, `\n`)\n                };\n            }\n        }\n        fences(e) {\n            let t = this.rules.block.fences.exec(e);\n            if (t) {\n                let n = t[0], r = it(n, t[3] || \"\", this.rules);\n                return {\n                    type: \"code\",\n                    raw: n,\n                    lang: t[2] ? t[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\") : t[2],\n                    text: r\n                };\n            }\n        }\n        heading(e) {\n            let t = this.rules.block.heading.exec(e);\n            if (t) {\n                let n = t[2].trim();\n                if (this.rules.other.endingHash.test(n)) {\n                    let r = z(n, \"#\");\n                    (this.options.pedantic || !r || this.rules.other.endingSpaceChar.test(r)) && (n = r.trim());\n                }\n                return {\n                    type: \"heading\",\n                    raw: t[0],\n                    depth: t[1].length,\n                    text: n,\n                    tokens: this.lexer.inline(n)\n                };\n            }\n        }\n        hr(e) {\n            let t = this.rules.block.hr.exec(e);\n            if (t) return {\n                type: \"hr\",\n                raw: z(t[0], `\n`)\n            };\n        }\n        blockquote(e) {\n            let t = this.rules.block.blockquote.exec(e);\n            if (t) {\n                let n = z(t[0], `\n`).split(`\n`), r = \"\", i = \"\", s = [];\n                for(; n.length > 0;){\n                    let o = !1, a = [], u;\n                    for(u = 0; u < n.length; u++)if (this.rules.other.blockquoteStart.test(n[u])) a.push(n[u]), o = !0;\n                    else if (!o) a.push(n[u]);\n                    else break;\n                    n = n.slice(u);\n                    let c = a.join(`\n`), p = c.replace(this.rules.other.blockquoteSetextReplace, `\n    $1`).replace(this.rules.other.blockquoteSetextReplace2, \"\");\n                    r = r ? `${r}\n${c}` : c, i = i ? `${i}\n${p}` : p;\n                    let g = this.lexer.state.top;\n                    if (this.lexer.state.top = !0, this.lexer.blockTokens(p, s, !0), this.lexer.state.top = g, n.length === 0) break;\n                    let d = s.at(-1);\n                    if (d?.type === \"code\") break;\n                    if (d?.type === \"blockquote\") {\n                        let R = d, f = R.raw + `\n` + n.join(`\n`), O = this.blockquote(f);\n                        s[s.length - 1] = O, r = r.substring(0, r.length - R.raw.length) + O.raw, i = i.substring(0, i.length - R.text.length) + O.text;\n                        break;\n                    } else if (d?.type === \"list\") {\n                        let R = d, f = R.raw + `\n` + n.join(`\n`), O = this.list(f);\n                        s[s.length - 1] = O, r = r.substring(0, r.length - d.raw.length) + O.raw, i = i.substring(0, i.length - R.raw.length) + O.raw, n = f.substring(s.at(-1).raw.length).split(`\n`);\n                        continue;\n                    }\n                }\n                return {\n                    type: \"blockquote\",\n                    raw: r,\n                    tokens: s,\n                    text: i\n                };\n            }\n        }\n        list(e) {\n            let t = this.rules.block.list.exec(e);\n            if (t) {\n                let n = t[1].trim(), r = n.length > 1, i = {\n                    type: \"list\",\n                    raw: \"\",\n                    ordered: r,\n                    start: r ? +n.slice(0, -1) : \"\",\n                    loose: !1,\n                    items: []\n                };\n                n = r ? `\\\\d{1,9}\\\\${n.slice(-1)}` : `\\\\${n}`, this.options.pedantic && (n = r ? n : \"[*+-]\");\n                let s = this.rules.other.listItemRegex(n), o = !1;\n                for(; e;){\n                    let u = !1, c = \"\", p = \"\";\n                    if (!(t = s.exec(e)) || this.rules.block.hr.test(e)) break;\n                    c = t[0], e = e.substring(c.length);\n                    let g = t[2].split(`\n`, 1)[0].replace(this.rules.other.listReplaceTabs, (H)=>\" \".repeat(3 * H.length)), d = e.split(`\n`, 1)[0], R = !g.trim(), f = 0;\n                    if (this.options.pedantic ? (f = 2, p = g.trimStart()) : R ? f = t[1].length + 1 : (f = t[2].search(this.rules.other.nonSpaceChar), f = f > 4 ? 1 : f, p = g.slice(f), f += t[1].length), R && this.rules.other.blankLine.test(d) && (c += d + `\n`, e = e.substring(d.length + 1), u = !0), !u) {\n                        let H = this.rules.other.nextBulletRegex(f), te = this.rules.other.hrRegex(f), ne = this.rules.other.fencesBeginRegex(f), re = this.rules.other.headingBeginRegex(f), be = this.rules.other.htmlBeginRegex(f);\n                        for(; e;){\n                            let Z = e.split(`\n`, 1)[0], I;\n                            if (d = Z, this.options.pedantic ? (d = d.replace(this.rules.other.listReplaceNesting, \"  \"), I = d) : I = d.replace(this.rules.other.tabCharGlobal, \"    \"), ne.test(d) || re.test(d) || be.test(d) || H.test(d) || te.test(d)) break;\n                            if (I.search(this.rules.other.nonSpaceChar) >= f || !d.trim()) p += `\n` + I.slice(f);\n                            else {\n                                if (R || g.replace(this.rules.other.tabCharGlobal, \"    \").search(this.rules.other.nonSpaceChar) >= 4 || ne.test(g) || re.test(g) || te.test(g)) break;\n                                p += `\n` + d;\n                            }\n                            !R && !d.trim() && (R = !0), c += Z + `\n`, e = e.substring(Z.length + 1), g = I.slice(f);\n                        }\n                    }\n                    i.loose || (o ? i.loose = !0 : this.rules.other.doubleBlankLine.test(c) && (o = !0));\n                    let O = null, ee;\n                    this.options.gfm && (O = this.rules.other.listIsTask.exec(p), O && (ee = O[0] !== \"[ ] \", p = p.replace(this.rules.other.listReplaceTask, \"\"))), i.items.push({\n                        type: \"list_item\",\n                        raw: c,\n                        task: !!O,\n                        checked: ee,\n                        loose: !1,\n                        text: p,\n                        tokens: []\n                    }), i.raw += c;\n                }\n                let a = i.items.at(-1);\n                if (a) a.raw = a.raw.trimEnd(), a.text = a.text.trimEnd();\n                else return;\n                i.raw = i.raw.trimEnd();\n                for(let u = 0; u < i.items.length; u++)if (this.lexer.state.top = !1, i.items[u].tokens = this.lexer.blockTokens(i.items[u].text, []), !i.loose) {\n                    let c = i.items[u].tokens.filter((g)=>g.type === \"space\"), p = c.length > 0 && c.some((g)=>this.rules.other.anyLine.test(g.raw));\n                    i.loose = p;\n                }\n                if (i.loose) for(let u = 0; u < i.items.length; u++)i.items[u].loose = !0;\n                return i;\n            }\n        }\n        html(e) {\n            let t = this.rules.block.html.exec(e);\n            if (t) return {\n                type: \"html\",\n                block: !0,\n                raw: t[0],\n                pre: t[1] === \"pre\" || t[1] === \"script\" || t[1] === \"style\",\n                text: t[0]\n            };\n        }\n        def(e) {\n            let t = this.rules.block.def.exec(e);\n            if (t) {\n                let n = t[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, \" \"), r = t[2] ? t[2].replace(this.rules.other.hrefBrackets, \"$1\").replace(this.rules.inline.anyPunctuation, \"$1\") : \"\", i = t[3] ? t[3].substring(1, t[3].length - 1).replace(this.rules.inline.anyPunctuation, \"$1\") : t[3];\n                return {\n                    type: \"def\",\n                    tag: n,\n                    raw: t[0],\n                    href: r,\n                    title: i\n                };\n            }\n        }\n        table(e) {\n            let t = this.rules.block.table.exec(e);\n            if (!t || !this.rules.other.tableDelimiter.test(t[2])) return;\n            let n = Y(t[1]), r = t[2].replace(this.rules.other.tableAlignChars, \"\").split(\"|\"), i = t[3]?.trim() ? t[3].replace(this.rules.other.tableRowBlankLine, \"\").split(`\n`) : [], s = {\n                type: \"table\",\n                raw: t[0],\n                header: [],\n                align: [],\n                rows: []\n            };\n            if (n.length === r.length) {\n                for (let o of r)this.rules.other.tableAlignRight.test(o) ? s.align.push(\"right\") : this.rules.other.tableAlignCenter.test(o) ? s.align.push(\"center\") : this.rules.other.tableAlignLeft.test(o) ? s.align.push(\"left\") : s.align.push(null);\n                for(let o = 0; o < n.length; o++)s.header.push({\n                    text: n[o],\n                    tokens: this.lexer.inline(n[o]),\n                    header: !0,\n                    align: s.align[o]\n                });\n                for (let o of i)s.rows.push(Y(o, s.header.length).map((a, u)=>({\n                        text: a,\n                        tokens: this.lexer.inline(a),\n                        header: !1,\n                        align: s.align[u]\n                    })));\n                return s;\n            }\n        }\n        lheading(e) {\n            let t = this.rules.block.lheading.exec(e);\n            if (t) return {\n                type: \"heading\",\n                raw: t[0],\n                depth: t[2].charAt(0) === \"=\" ? 1 : 2,\n                text: t[1],\n                tokens: this.lexer.inline(t[1])\n            };\n        }\n        paragraph(e) {\n            let t = this.rules.block.paragraph.exec(e);\n            if (t) {\n                let n = t[1].charAt(t[1].length - 1) === `\n` ? t[1].slice(0, -1) : t[1];\n                return {\n                    type: \"paragraph\",\n                    raw: t[0],\n                    text: n,\n                    tokens: this.lexer.inline(n)\n                };\n            }\n        }\n        text(e) {\n            let t = this.rules.block.text.exec(e);\n            if (t) return {\n                type: \"text\",\n                raw: t[0],\n                text: t[0],\n                tokens: this.lexer.inline(t[0])\n            };\n        }\n        escape(e) {\n            let t = this.rules.inline.escape.exec(e);\n            if (t) return {\n                type: \"escape\",\n                raw: t[0],\n                text: t[1]\n            };\n        }\n        tag(e) {\n            let t = this.rules.inline.tag.exec(e);\n            if (t) return !this.lexer.state.inLink && this.rules.other.startATag.test(t[0]) ? this.lexer.state.inLink = !0 : this.lexer.state.inLink && this.rules.other.endATag.test(t[0]) && (this.lexer.state.inLink = !1), !this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(t[0]) ? this.lexer.state.inRawBlock = !0 : this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(t[0]) && (this.lexer.state.inRawBlock = !1), {\n                type: \"html\",\n                raw: t[0],\n                inLink: this.lexer.state.inLink,\n                inRawBlock: this.lexer.state.inRawBlock,\n                block: !1,\n                text: t[0]\n            };\n        }\n        link(e) {\n            let t = this.rules.inline.link.exec(e);\n            if (t) {\n                let n = t[2].trim();\n                if (!this.options.pedantic && this.rules.other.startAngleBracket.test(n)) {\n                    if (!this.rules.other.endAngleBracket.test(n)) return;\n                    let s = z(n.slice(0, -1), \"\\\\\");\n                    if ((n.length - s.length) % 2 === 0) return;\n                } else {\n                    let s = me(t[2], \"()\");\n                    if (s === -2) return;\n                    if (s > -1) {\n                        let a = (t[0].indexOf(\"!\") === 0 ? 5 : 4) + t[1].length + s;\n                        t[2] = t[2].substring(0, s), t[0] = t[0].substring(0, a).trim(), t[3] = \"\";\n                    }\n                }\n                let r = t[2], i = \"\";\n                if (this.options.pedantic) {\n                    let s = this.rules.other.pedanticHrefTitle.exec(r);\n                    s && (r = s[1], i = s[3]);\n                } else i = t[3] ? t[3].slice(1, -1) : \"\";\n                return r = r.trim(), this.rules.other.startAngleBracket.test(r) && (this.options.pedantic && !this.rules.other.endAngleBracket.test(n) ? r = r.slice(1) : r = r.slice(1, -1)), xe(t, {\n                    href: r && r.replace(this.rules.inline.anyPunctuation, \"$1\"),\n                    title: i && i.replace(this.rules.inline.anyPunctuation, \"$1\")\n                }, t[0], this.lexer, this.rules);\n            }\n        }\n        reflink(e, t) {\n            let n;\n            if ((n = this.rules.inline.reflink.exec(e)) || (n = this.rules.inline.nolink.exec(e))) {\n                let r = (n[2] || n[1]).replace(this.rules.other.multipleSpaceGlobal, \" \"), i = t[r.toLowerCase()];\n                if (!i) {\n                    let s = n[0].charAt(0);\n                    return {\n                        type: \"text\",\n                        raw: s,\n                        text: s\n                    };\n                }\n                return xe(n, i, n[0], this.lexer, this.rules);\n            }\n        }\n        emStrong(e, t, n = \"\") {\n            let r = this.rules.inline.emStrongLDelim.exec(e);\n            if (!r || r[3] && n.match(this.rules.other.unicodeAlphaNumeric)) return;\n            if (!(r[1] || r[2] || \"\") || !n || this.rules.inline.punctuation.exec(n)) {\n                let s = [\n                    ...r[0]\n                ].length - 1, o, a, u = s, c = 0, p = r[0][0] === \"*\" ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n                for(p.lastIndex = 0, t = t.slice(-1 * e.length + s); (r = p.exec(t)) != null;){\n                    if (o = r[1] || r[2] || r[3] || r[4] || r[5] || r[6], !o) continue;\n                    if (a = [\n                        ...o\n                    ].length, r[3] || r[4]) {\n                        u += a;\n                        continue;\n                    } else if ((r[5] || r[6]) && s % 3 && !((s + a) % 3)) {\n                        c += a;\n                        continue;\n                    }\n                    if (u -= a, u > 0) continue;\n                    a = Math.min(a, a + u + c);\n                    let g = [\n                        ...r[0]\n                    ][0].length, d = e.slice(0, s + r.index + g + a);\n                    if (Math.min(s, a) % 2) {\n                        let f = d.slice(1, -1);\n                        return {\n                            type: \"em\",\n                            raw: d,\n                            text: f,\n                            tokens: this.lexer.inlineTokens(f)\n                        };\n                    }\n                    let R = d.slice(2, -2);\n                    return {\n                        type: \"strong\",\n                        raw: d,\n                        text: R,\n                        tokens: this.lexer.inlineTokens(R)\n                    };\n                }\n            }\n        }\n        codespan(e) {\n            let t = this.rules.inline.code.exec(e);\n            if (t) {\n                let n = t[2].replace(this.rules.other.newLineCharGlobal, \" \"), r = this.rules.other.nonSpaceChar.test(n), i = this.rules.other.startingSpaceChar.test(n) && this.rules.other.endingSpaceChar.test(n);\n                return r && i && (n = n.substring(1, n.length - 1)), {\n                    type: \"codespan\",\n                    raw: t[0],\n                    text: n\n                };\n            }\n        }\n        br(e) {\n            let t = this.rules.inline.br.exec(e);\n            if (t) return {\n                type: \"br\",\n                raw: t[0]\n            };\n        }\n        del(e) {\n            let t = this.rules.inline.del.exec(e);\n            if (t) return {\n                type: \"del\",\n                raw: t[0],\n                text: t[2],\n                tokens: this.lexer.inlineTokens(t[2])\n            };\n        }\n        autolink(e) {\n            let t = this.rules.inline.autolink.exec(e);\n            if (t) {\n                let n, r;\n                return t[2] === \"@\" ? (n = t[1], r = \"mailto:\" + n) : (n = t[1], r = n), {\n                    type: \"link\",\n                    raw: t[0],\n                    text: n,\n                    href: r,\n                    tokens: [\n                        {\n                            type: \"text\",\n                            raw: n,\n                            text: n\n                        }\n                    ]\n                };\n            }\n        }\n        url(e) {\n            let t;\n            if (t = this.rules.inline.url.exec(e)) {\n                let n, r;\n                if (t[2] === \"@\") n = t[0], r = \"mailto:\" + n;\n                else {\n                    let i;\n                    do i = t[0], t[0] = this.rules.inline._backpedal.exec(t[0])?.[0] ?? \"\";\n                    while (i !== t[0]);\n                    n = t[0], t[1] === \"www.\" ? r = \"http://\" + t[0] : r = t[0];\n                }\n                return {\n                    type: \"link\",\n                    raw: t[0],\n                    text: n,\n                    href: r,\n                    tokens: [\n                        {\n                            type: \"text\",\n                            raw: n,\n                            text: n\n                        }\n                    ]\n                };\n            }\n        }\n        inlineText(e) {\n            let t = this.rules.inline.text.exec(e);\n            if (t) {\n                let n = this.lexer.state.inRawBlock;\n                return {\n                    type: \"text\",\n                    raw: t[0],\n                    text: t[0],\n                    escaped: n\n                };\n            }\n        }\n    };\n    var x = class l {\n        tokens;\n        options;\n        state;\n        tokenizer;\n        inlineQueue;\n        constructor(e){\n            this.tokens = [], this.tokens.links = Object.create(null), this.options = e || T, this.options.tokenizer = this.options.tokenizer || new y, this.tokenizer = this.options.tokenizer, this.tokenizer.options = this.options, this.tokenizer.lexer = this, this.inlineQueue = [], this.state = {\n                inLink: !1,\n                inRawBlock: !1,\n                top: !0\n            };\n            let t = {\n                other: m,\n                block: B.normal,\n                inline: M.normal\n            };\n            this.options.pedantic ? (t.block = B.pedantic, t.inline = M.pedantic) : this.options.gfm && (t.block = B.gfm, this.options.breaks ? t.inline = M.breaks : t.inline = M.gfm), this.tokenizer.rules = t;\n        }\n        static get rules() {\n            return {\n                block: B,\n                inline: M\n            };\n        }\n        static lex(e, t) {\n            return new l(t).lex(e);\n        }\n        static lexInline(e, t) {\n            return new l(t).inlineTokens(e);\n        }\n        lex(e) {\n            e = e.replace(m.carriageReturn, `\n`), this.blockTokens(e, this.tokens);\n            for(let t = 0; t < this.inlineQueue.length; t++){\n                let n = this.inlineQueue[t];\n                this.inlineTokens(n.src, n.tokens);\n            }\n            return this.inlineQueue = [], this.tokens;\n        }\n        blockTokens(e, t = [], n = !1) {\n            for(this.options.pedantic && (e = e.replace(m.tabCharGlobal, \"    \").replace(m.spaceLine, \"\")); e;){\n                let r;\n                if (this.options.extensions?.block?.some((s)=>(r = s.call({\n                        lexer: this\n                    }, e, t)) ? (e = e.substring(r.raw.length), t.push(r), !0) : !1)) continue;\n                if (r = this.tokenizer.space(e)) {\n                    e = e.substring(r.raw.length);\n                    let s = t.at(-1);\n                    r.raw.length === 1 && s !== void 0 ? s.raw += `\n` : t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.code(e)) {\n                    e = e.substring(r.raw.length);\n                    let s = t.at(-1);\n                    s?.type === \"paragraph\" || s?.type === \"text\" ? (s.raw += (s.raw.endsWith(`\n`) ? \"\" : `\n`) + r.raw, s.text += `\n` + r.text, this.inlineQueue.at(-1).src = s.text) : t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.fences(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.heading(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.hr(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.blockquote(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.list(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.html(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.def(e)) {\n                    e = e.substring(r.raw.length);\n                    let s = t.at(-1);\n                    s?.type === \"paragraph\" || s?.type === \"text\" ? (s.raw += (s.raw.endsWith(`\n`) ? \"\" : `\n`) + r.raw, s.text += `\n` + r.raw, this.inlineQueue.at(-1).src = s.text) : this.tokens.links[r.tag] || (this.tokens.links[r.tag] = {\n                        href: r.href,\n                        title: r.title\n                    }, t.push(r));\n                    continue;\n                }\n                if (r = this.tokenizer.table(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                if (r = this.tokenizer.lheading(e)) {\n                    e = e.substring(r.raw.length), t.push(r);\n                    continue;\n                }\n                let i = e;\n                if (this.options.extensions?.startBlock) {\n                    let s = 1 / 0, o = e.slice(1), a;\n                    this.options.extensions.startBlock.forEach((u)=>{\n                        a = u.call({\n                            lexer: this\n                        }, o), typeof a == \"number\" && a >= 0 && (s = Math.min(s, a));\n                    }), s < 1 / 0 && s >= 0 && (i = e.substring(0, s + 1));\n                }\n                if (this.state.top && (r = this.tokenizer.paragraph(i))) {\n                    let s = t.at(-1);\n                    n && s?.type === \"paragraph\" ? (s.raw += (s.raw.endsWith(`\n`) ? \"\" : `\n`) + r.raw, s.text += `\n` + r.text, this.inlineQueue.pop(), this.inlineQueue.at(-1).src = s.text) : t.push(r), n = i.length !== e.length, e = e.substring(r.raw.length);\n                    continue;\n                }\n                if (r = this.tokenizer.text(e)) {\n                    e = e.substring(r.raw.length);\n                    let s = t.at(-1);\n                    s?.type === \"text\" ? (s.raw += (s.raw.endsWith(`\n`) ? \"\" : `\n`) + r.raw, s.text += `\n` + r.text, this.inlineQueue.pop(), this.inlineQueue.at(-1).src = s.text) : t.push(r);\n                    continue;\n                }\n                if (e) {\n                    let s = \"Infinite loop on byte: \" + e.charCodeAt(0);\n                    if (this.options.silent) {\n                        console.error(s);\n                        break;\n                    } else throw new Error(s);\n                }\n            }\n            return this.state.top = !0, t;\n        }\n        inline(e, t = []) {\n            return this.inlineQueue.push({\n                src: e,\n                tokens: t\n            }), t;\n        }\n        inlineTokens(e, t = []) {\n            let n = e, r = null;\n            if (this.tokens.links) {\n                let o = Object.keys(this.tokens.links);\n                if (o.length > 0) for(; (r = this.tokenizer.rules.inline.reflinkSearch.exec(n)) != null;)o.includes(r[0].slice(r[0].lastIndexOf(\"[\") + 1, -1)) && (n = n.slice(0, r.index) + \"[\" + \"a\".repeat(r[0].length - 2) + \"]\" + n.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex));\n            }\n            for(; (r = this.tokenizer.rules.inline.anyPunctuation.exec(n)) != null;)n = n.slice(0, r.index) + \"++\" + n.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n            for(; (r = this.tokenizer.rules.inline.blockSkip.exec(n)) != null;)n = n.slice(0, r.index) + \"[\" + \"a\".repeat(r[0].length - 2) + \"]\" + n.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n            n = this.options.hooks?.emStrongMask?.call({\n                lexer: this\n            }, n) ?? n;\n            let i = !1, s = \"\";\n            for(; e;){\n                i || (s = \"\"), i = !1;\n                let o;\n                if (this.options.extensions?.inline?.some((u)=>(o = u.call({\n                        lexer: this\n                    }, e, t)) ? (e = e.substring(o.raw.length), t.push(o), !0) : !1)) continue;\n                if (o = this.tokenizer.escape(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.tag(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.link(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.reflink(e, this.tokens.links)) {\n                    e = e.substring(o.raw.length);\n                    let u = t.at(-1);\n                    o.type === \"text\" && u?.type === \"text\" ? (u.raw += o.raw, u.text += o.text) : t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.emStrong(e, n, s)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.codespan(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.br(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.del(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (o = this.tokenizer.autolink(e)) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                if (!this.state.inLink && (o = this.tokenizer.url(e))) {\n                    e = e.substring(o.raw.length), t.push(o);\n                    continue;\n                }\n                let a = e;\n                if (this.options.extensions?.startInline) {\n                    let u = 1 / 0, c = e.slice(1), p;\n                    this.options.extensions.startInline.forEach((g)=>{\n                        p = g.call({\n                            lexer: this\n                        }, c), typeof p == \"number\" && p >= 0 && (u = Math.min(u, p));\n                    }), u < 1 / 0 && u >= 0 && (a = e.substring(0, u + 1));\n                }\n                if (o = this.tokenizer.inlineText(a)) {\n                    e = e.substring(o.raw.length), o.raw.slice(-1) !== \"_\" && (s = o.raw.slice(-1)), i = !0;\n                    let u = t.at(-1);\n                    u?.type === \"text\" ? (u.raw += o.raw, u.text += o.text) : t.push(o);\n                    continue;\n                }\n                if (e) {\n                    let u = \"Infinite loop on byte: \" + e.charCodeAt(0);\n                    if (this.options.silent) {\n                        console.error(u);\n                        break;\n                    } else throw new Error(u);\n                }\n            }\n            return t;\n        }\n    };\n    var P = class {\n        options;\n        parser;\n        constructor(e){\n            this.options = e || T;\n        }\n        space(e) {\n            return \"\";\n        }\n        code({ text: e, lang: t, escaped: n }) {\n            let r = (t || \"\").match(m.notSpaceStart)?.[0], i = e.replace(m.endingNewline, \"\") + `\n`;\n            return r ? '<pre><code class=\"language-' + w(r) + '\">' + (n ? i : w(i, !0)) + `</code></pre>\n` : \"<pre><code>\" + (n ? i : w(i, !0)) + `</code></pre>\n`;\n        }\n        blockquote({ tokens: e }) {\n            return `<blockquote>\n${this.parser.parse(e)}</blockquote>\n`;\n        }\n        html({ text: e }) {\n            return e;\n        }\n        def(e) {\n            return \"\";\n        }\n        heading({ tokens: e, depth: t }) {\n            return `<h${t}>${this.parser.parseInline(e)}</h${t}>\n`;\n        }\n        hr(e) {\n            return `<hr>\n`;\n        }\n        list(e) {\n            let t = e.ordered, n = e.start, r = \"\";\n            for(let o = 0; o < e.items.length; o++){\n                let a = e.items[o];\n                r += this.listitem(a);\n            }\n            let i = t ? \"ol\" : \"ul\", s = t && n !== 1 ? ' start=\"' + n + '\"' : \"\";\n            return \"<\" + i + s + `>\n` + r + \"</\" + i + `>\n`;\n        }\n        listitem(e) {\n            let t = \"\";\n            if (e.task) {\n                let n = this.checkbox({\n                    checked: !!e.checked\n                });\n                e.loose ? e.tokens[0]?.type === \"paragraph\" ? (e.tokens[0].text = n + \" \" + e.tokens[0].text, e.tokens[0].tokens && e.tokens[0].tokens.length > 0 && e.tokens[0].tokens[0].type === \"text\" && (e.tokens[0].tokens[0].text = n + \" \" + w(e.tokens[0].tokens[0].text), e.tokens[0].tokens[0].escaped = !0)) : e.tokens.unshift({\n                    type: \"text\",\n                    raw: n + \" \",\n                    text: n + \" \",\n                    escaped: !0\n                }) : t += n + \" \";\n            }\n            return t += this.parser.parse(e.tokens, !!e.loose), `<li>${t}</li>\n`;\n        }\n        checkbox({ checked: e }) {\n            return \"<input \" + (e ? 'checked=\"\" ' : \"\") + 'disabled=\"\" type=\"checkbox\">';\n        }\n        paragraph({ tokens: e }) {\n            return `<p>${this.parser.parseInline(e)}</p>\n`;\n        }\n        table(e) {\n            let t = \"\", n = \"\";\n            for(let i = 0; i < e.header.length; i++)n += this.tablecell(e.header[i]);\n            t += this.tablerow({\n                text: n\n            });\n            let r = \"\";\n            for(let i = 0; i < e.rows.length; i++){\n                let s = e.rows[i];\n                n = \"\";\n                for(let o = 0; o < s.length; o++)n += this.tablecell(s[o]);\n                r += this.tablerow({\n                    text: n\n                });\n            }\n            return r && (r = `<tbody>${r}</tbody>`), `<table>\n<thead>\n` + t + `</thead>\n` + r + `</table>\n`;\n        }\n        tablerow({ text: e }) {\n            return `<tr>\n${e}</tr>\n`;\n        }\n        tablecell(e) {\n            let t = this.parser.parseInline(e.tokens), n = e.header ? \"th\" : \"td\";\n            return (e.align ? `<${n} align=\"${e.align}\">` : `<${n}>`) + t + `</${n}>\n`;\n        }\n        strong({ tokens: e }) {\n            return `<strong>${this.parser.parseInline(e)}</strong>`;\n        }\n        em({ tokens: e }) {\n            return `<em>${this.parser.parseInline(e)}</em>`;\n        }\n        codespan({ text: e }) {\n            return `<code>${w(e, !0)}</code>`;\n        }\n        br(e) {\n            return \"<br>\";\n        }\n        del({ tokens: e }) {\n            return `<del>${this.parser.parseInline(e)}</del>`;\n        }\n        link({ href: e, title: t, tokens: n }) {\n            let r = this.parser.parseInline(n), i = V(e);\n            if (i === null) return r;\n            e = i;\n            let s = '<a href=\"' + e + '\"';\n            return t && (s += ' title=\"' + w(t) + '\"'), s += \">\" + r + \"</a>\", s;\n        }\n        image({ href: e, title: t, text: n, tokens: r }) {\n            r && (n = this.parser.parseInline(r, this.parser.textRenderer));\n            let i = V(e);\n            if (i === null) return w(n);\n            e = i;\n            let s = `<img src=\"${e}\" alt=\"${n}\"`;\n            return t && (s += ` title=\"${w(t)}\"`), s += \">\", s;\n        }\n        text(e) {\n            return \"tokens\" in e && e.tokens ? this.parser.parseInline(e.tokens) : \"escaped\" in e && e.escaped ? e.text : w(e.text);\n        }\n    };\n    var $ = class {\n        strong({ text: e }) {\n            return e;\n        }\n        em({ text: e }) {\n            return e;\n        }\n        codespan({ text: e }) {\n            return e;\n        }\n        del({ text: e }) {\n            return e;\n        }\n        html({ text: e }) {\n            return e;\n        }\n        text({ text: e }) {\n            return e;\n        }\n        link({ text: e }) {\n            return \"\" + e;\n        }\n        image({ text: e }) {\n            return \"\" + e;\n        }\n        br() {\n            return \"\";\n        }\n    };\n    var b = class l {\n        options;\n        renderer;\n        textRenderer;\n        constructor(e){\n            this.options = e || T, this.options.renderer = this.options.renderer || new P, this.renderer = this.options.renderer, this.renderer.options = this.options, this.renderer.parser = this, this.textRenderer = new $;\n        }\n        static parse(e, t) {\n            return new l(t).parse(e);\n        }\n        static parseInline(e, t) {\n            return new l(t).parseInline(e);\n        }\n        parse(e, t = !0) {\n            let n = \"\";\n            for(let r = 0; r < e.length; r++){\n                let i = e[r];\n                if (this.options.extensions?.renderers?.[i.type]) {\n                    let o = i, a = this.options.extensions.renderers[o.type].call({\n                        parser: this\n                    }, o);\n                    if (a !== !1 || ![\n                        \"space\",\n                        \"hr\",\n                        \"heading\",\n                        \"code\",\n                        \"table\",\n                        \"blockquote\",\n                        \"list\",\n                        \"html\",\n                        \"def\",\n                        \"paragraph\",\n                        \"text\"\n                    ].includes(o.type)) {\n                        n += a || \"\";\n                        continue;\n                    }\n                }\n                let s = i;\n                switch(s.type){\n                    case \"space\":\n                        n += this.renderer.space(s);\n                        continue;\n                    case \"hr\":\n                        n += this.renderer.hr(s);\n                        continue;\n                    case \"heading\":\n                        n += this.renderer.heading(s);\n                        continue;\n                    case \"code\":\n                        n += this.renderer.code(s);\n                        continue;\n                    case \"table\":\n                        n += this.renderer.table(s);\n                        continue;\n                    case \"blockquote\":\n                        n += this.renderer.blockquote(s);\n                        continue;\n                    case \"list\":\n                        n += this.renderer.list(s);\n                        continue;\n                    case \"html\":\n                        n += this.renderer.html(s);\n                        continue;\n                    case \"def\":\n                        n += this.renderer.def(s);\n                        continue;\n                    case \"paragraph\":\n                        n += this.renderer.paragraph(s);\n                        continue;\n                    case \"text\":\n                        {\n                            let o = s, a = this.renderer.text(o);\n                            for(; r + 1 < e.length && e[r + 1].type === \"text\";)o = e[++r], a += `\n` + this.renderer.text(o);\n                            t ? n += this.renderer.paragraph({\n                                type: \"paragraph\",\n                                raw: a,\n                                text: a,\n                                tokens: [\n                                    {\n                                        type: \"text\",\n                                        raw: a,\n                                        text: a,\n                                        escaped: !0\n                                    }\n                                ]\n                            }) : n += a;\n                            continue;\n                        }\n                    default:\n                        {\n                            let o = 'Token with \"' + s.type + '\" type was not found.';\n                            if (this.options.silent) return console.error(o), \"\";\n                            throw new Error(o);\n                        }\n                }\n            }\n            return n;\n        }\n        parseInline(e, t = this.renderer) {\n            let n = \"\";\n            for(let r = 0; r < e.length; r++){\n                let i = e[r];\n                if (this.options.extensions?.renderers?.[i.type]) {\n                    let o = this.options.extensions.renderers[i.type].call({\n                        parser: this\n                    }, i);\n                    if (o !== !1 || ![\n                        \"escape\",\n                        \"html\",\n                        \"link\",\n                        \"image\",\n                        \"strong\",\n                        \"em\",\n                        \"codespan\",\n                        \"br\",\n                        \"del\",\n                        \"text\"\n                    ].includes(i.type)) {\n                        n += o || \"\";\n                        continue;\n                    }\n                }\n                let s = i;\n                switch(s.type){\n                    case \"escape\":\n                        n += t.text(s);\n                        break;\n                    case \"html\":\n                        n += t.html(s);\n                        break;\n                    case \"link\":\n                        n += t.link(s);\n                        break;\n                    case \"image\":\n                        n += t.image(s);\n                        break;\n                    case \"strong\":\n                        n += t.strong(s);\n                        break;\n                    case \"em\":\n                        n += t.em(s);\n                        break;\n                    case \"codespan\":\n                        n += t.codespan(s);\n                        break;\n                    case \"br\":\n                        n += t.br(s);\n                        break;\n                    case \"del\":\n                        n += t.del(s);\n                        break;\n                    case \"text\":\n                        n += t.text(s);\n                        break;\n                    default:\n                        {\n                            let o = 'Token with \"' + s.type + '\" type was not found.';\n                            if (this.options.silent) return console.error(o), \"\";\n                            throw new Error(o);\n                        }\n                }\n            }\n            return n;\n        }\n    };\n    var S = class {\n        options;\n        block;\n        constructor(e){\n            this.options = e || T;\n        }\n        static passThroughHooks = new Set([\n            \"preprocess\",\n            \"postprocess\",\n            \"processAllTokens\",\n            \"emStrongMask\"\n        ]);\n        static passThroughHooksRespectAsync = new Set([\n            \"preprocess\",\n            \"postprocess\",\n            \"processAllTokens\"\n        ]);\n        preprocess(e) {\n            return e;\n        }\n        postprocess(e) {\n            return e;\n        }\n        processAllTokens(e) {\n            return e;\n        }\n        emStrongMask(e) {\n            return e;\n        }\n        provideLexer() {\n            return this.block ? x.lex : x.lexInline;\n        }\n        provideParser() {\n            return this.block ? b.parse : b.parseInline;\n        }\n    };\n    var A = class {\n        defaults = _();\n        options = this.setOptions;\n        parse = this.parseMarkdown(!0);\n        parseInline = this.parseMarkdown(!1);\n        Parser = b;\n        Renderer = P;\n        TextRenderer = $;\n        Lexer = x;\n        Tokenizer = y;\n        Hooks = S;\n        constructor(...e){\n            this.use(...e);\n        }\n        walkTokens(e, t) {\n            let n = [];\n            for (let r of e)switch(n = n.concat(t.call(this, r)), r.type){\n                case \"table\":\n                    {\n                        let i = r;\n                        for (let s of i.header)n = n.concat(this.walkTokens(s.tokens, t));\n                        for (let s of i.rows)for (let o of s)n = n.concat(this.walkTokens(o.tokens, t));\n                        break;\n                    }\n                case \"list\":\n                    {\n                        let i = r;\n                        n = n.concat(this.walkTokens(i.items, t));\n                        break;\n                    }\n                default:\n                    {\n                        let i = r;\n                        this.defaults.extensions?.childTokens?.[i.type] ? this.defaults.extensions.childTokens[i.type].forEach((s)=>{\n                            let o = i[s].flat(1 / 0);\n                            n = n.concat(this.walkTokens(o, t));\n                        }) : i.tokens && (n = n.concat(this.walkTokens(i.tokens, t)));\n                    }\n            }\n            return n;\n        }\n        use(...e) {\n            let t = this.defaults.extensions || {\n                renderers: {},\n                childTokens: {}\n            };\n            return e.forEach((n)=>{\n                let r = {\n                    ...n\n                };\n                if (r.async = this.defaults.async || r.async || !1, n.extensions && (n.extensions.forEach((i)=>{\n                    if (!i.name) throw new Error(\"extension name required\");\n                    if (\"renderer\" in i) {\n                        let s = t.renderers[i.name];\n                        s ? t.renderers[i.name] = function(...o) {\n                            let a = i.renderer.apply(this, o);\n                            return a === !1 && (a = s.apply(this, o)), a;\n                        } : t.renderers[i.name] = i.renderer;\n                    }\n                    if (\"tokenizer\" in i) {\n                        if (!i.level || i.level !== \"block\" && i.level !== \"inline\") throw new Error(\"extension level must be 'block' or 'inline'\");\n                        let s = t[i.level];\n                        s ? s.unshift(i.tokenizer) : t[i.level] = [\n                            i.tokenizer\n                        ], i.start && (i.level === \"block\" ? t.startBlock ? t.startBlock.push(i.start) : t.startBlock = [\n                            i.start\n                        ] : i.level === \"inline\" && (t.startInline ? t.startInline.push(i.start) : t.startInline = [\n                            i.start\n                        ]));\n                    }\n                    \"childTokens\" in i && i.childTokens && (t.childTokens[i.name] = i.childTokens);\n                }), r.extensions = t), n.renderer) {\n                    let i = this.defaults.renderer || new P(this.defaults);\n                    for(let s in n.renderer){\n                        if (!(s in i)) throw new Error(`renderer '${s}' does not exist`);\n                        if ([\n                            \"options\",\n                            \"parser\"\n                        ].includes(s)) continue;\n                        let o = s, a = n.renderer[o], u = i[o];\n                        i[o] = (...c)=>{\n                            let p = a.apply(i, c);\n                            return p === !1 && (p = u.apply(i, c)), p || \"\";\n                        };\n                    }\n                    r.renderer = i;\n                }\n                if (n.tokenizer) {\n                    let i = this.defaults.tokenizer || new y(this.defaults);\n                    for(let s in n.tokenizer){\n                        if (!(s in i)) throw new Error(`tokenizer '${s}' does not exist`);\n                        if ([\n                            \"options\",\n                            \"rules\",\n                            \"lexer\"\n                        ].includes(s)) continue;\n                        let o = s, a = n.tokenizer[o], u = i[o];\n                        i[o] = (...c)=>{\n                            let p = a.apply(i, c);\n                            return p === !1 && (p = u.apply(i, c)), p;\n                        };\n                    }\n                    r.tokenizer = i;\n                }\n                if (n.hooks) {\n                    let i = this.defaults.hooks || new S;\n                    for(let s in n.hooks){\n                        if (!(s in i)) throw new Error(`hook '${s}' does not exist`);\n                        if ([\n                            \"options\",\n                            \"block\"\n                        ].includes(s)) continue;\n                        let o = s, a = n.hooks[o], u = i[o];\n                        S.passThroughHooks.has(s) ? i[o] = (c)=>{\n                            if (this.defaults.async && S.passThroughHooksRespectAsync.has(s)) return (async ()=>{\n                                let g = await a.call(i, c);\n                                return u.call(i, g);\n                            })();\n                            let p = a.call(i, c);\n                            return u.call(i, p);\n                        } : i[o] = (...c)=>{\n                            if (this.defaults.async) return (async ()=>{\n                                let g = await a.apply(i, c);\n                                return g === !1 && (g = await u.apply(i, c)), g;\n                            })();\n                            let p = a.apply(i, c);\n                            return p === !1 && (p = u.apply(i, c)), p;\n                        };\n                    }\n                    r.hooks = i;\n                }\n                if (n.walkTokens) {\n                    let i = this.defaults.walkTokens, s = n.walkTokens;\n                    r.walkTokens = function(o) {\n                        let a = [];\n                        return a.push(s.call(this, o)), i && (a = a.concat(i.call(this, o))), a;\n                    };\n                }\n                this.defaults = {\n                    ...this.defaults,\n                    ...r\n                };\n            }), this;\n        }\n        setOptions(e) {\n            return this.defaults = {\n                ...this.defaults,\n                ...e\n            }, this;\n        }\n        lexer(e, t) {\n            return x.lex(e, t ?? this.defaults);\n        }\n        parser(e, t) {\n            return b.parse(e, t ?? this.defaults);\n        }\n        parseMarkdown(e) {\n            return (n, r)=>{\n                let i = {\n                    ...r\n                }, s = {\n                    ...this.defaults,\n                    ...i\n                }, o = this.onError(!!s.silent, !!s.async);\n                if (this.defaults.async === !0 && i.async === !1) return o(new Error(\"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"));\n                if (typeof n > \"u\" || n === null) return o(new Error(\"marked(): input parameter is undefined or null\"));\n                if (typeof n != \"string\") return o(new Error(\"marked(): input parameter is of type \" + Object.prototype.toString.call(n) + \", string expected\"));\n                if (s.hooks && (s.hooks.options = s, s.hooks.block = e), s.async) return (async ()=>{\n                    let a = s.hooks ? await s.hooks.preprocess(n) : n, c = await (s.hooks ? await s.hooks.provideLexer() : e ? x.lex : x.lexInline)(a, s), p = s.hooks ? await s.hooks.processAllTokens(c) : c;\n                    s.walkTokens && await Promise.all(this.walkTokens(p, s.walkTokens));\n                    let d = await (s.hooks ? await s.hooks.provideParser() : e ? b.parse : b.parseInline)(p, s);\n                    return s.hooks ? await s.hooks.postprocess(d) : d;\n                })().catch(o);\n                try {\n                    s.hooks && (n = s.hooks.preprocess(n));\n                    let u = (s.hooks ? s.hooks.provideLexer() : e ? x.lex : x.lexInline)(n, s);\n                    s.hooks && (u = s.hooks.processAllTokens(u)), s.walkTokens && this.walkTokens(u, s.walkTokens);\n                    let p = (s.hooks ? s.hooks.provideParser() : e ? b.parse : b.parseInline)(u, s);\n                    return s.hooks && (p = s.hooks.postprocess(p)), p;\n                } catch (a) {\n                    return o(a);\n                }\n            };\n        }\n        onError(e, t) {\n            return (n)=>{\n                if (n.message += `\nPlease report this to https://github.com/markedjs/marked.`, e) {\n                    let r = \"<p>An error occurred:</p><pre>\" + w(n.message + \"\", !0) + \"</pre>\";\n                    return t ? Promise.resolve(r) : r;\n                }\n                if (t) return Promise.reject(n);\n                throw n;\n            };\n        }\n    };\n    var L = new A;\n    function k(l, e) {\n        return L.parse(l, e);\n    }\n    k.options = k.setOptions = function(l) {\n        return L.setOptions(l), k.defaults = L.defaults, N(k.defaults), k;\n    };\n    k.getDefaults = _;\n    k.defaults = T;\n    k.use = function(...l) {\n        return L.use(...l), k.defaults = L.defaults, N(k.defaults), k;\n    };\n    k.walkTokens = function(l, e) {\n        return L.walkTokens(l, e);\n    };\n    k.parseInline = L.parseInline;\n    k.Parser = b;\n    k.parser = b.parse;\n    k.Renderer = P;\n    k.TextRenderer = $;\n    k.Lexer = x;\n    k.lexer = x.lex;\n    k.Tokenizer = y;\n    k.Hooks = S;\n    k.parse = k;\n    var ot = k.options, at = k.setOptions, lt = k.use, ut = k.walkTokens, pt = k.parseInline, ct = k, ht = b.parse, dt = x.lex;\n    if (__exports != exports) module1.exports = exports;\n    return module1.exports;\n});\n\n\nlet $63a51ab81e297f22$var$cvMd = `# Antonino Cilione\n**Big Data Engineer**\nReggio Calabria, Italy | (+39) 347-252-7757\nantoninocilione96@gmail.com | linkedin.com/in/antonino-cilione-1258291a6 | github.com/acilione | acilione.github.io\n\n### Professional Summary\nBig Data Engineer with extensive experience in designing scalable ETL pipelines and microservices. Proven track record in migrating legacy frameworks to modern cloud architectures and optimizing database performance. Specializes in the ingestion and processing of critical energy grid data, utilizing the Hadoop ecosystem (Spark, Kafka) and Cloud technologies.\n\n---\n\n### Work History\n\n**Big Data Engineer** | **Enel** | *Jul 2022 \\u{2013} Present*\n* **Primary Responsibility:** Engineered and maintained high-throughput data pipelines specifically for the **ingestion of medium and low voltage measurements**, ensuring data accuracy and real-time availability for grid analysis.\n* **Framework Migration:** Led the complex framework migration from Cloudera Distribution Hadoop (CDH) to **Cloudera Data Platform (CDP)**, modernizing the data infrastructure.\n* **ETL Development:** Developed and maintained high-performance ETL pipelines using **Apache Spark** and **Kafka**.\n* **R&D & Optimization:** Researched and benchmarked **Apache Iceberg** functionalities using Spark and Flink; successfully implemented a custom \"equality delete files\" commit feature on Apache Spark.\n* **Data Ingestion:** Designed and implemented robust data ingestion flows using **Apache NiFi**.\n* **Database Management:** Optimized **MongoDB Atlas** clusters by tuning indexes, memory, and configuring auto-scaling to balance cost and performance.\n* **Microservices:** Developed **Java/Kotlin microservices** (Spring Boot) to expose NoSQL data stored on MongoDB to downstream applications.\n* **Automation:** Authored **Python scripts** for advanced S3 Parquet file operations (merge, deduplicate, backup, restore) and **Bash scripts** for automated Kafka/S3 status checks.\n* **Performance Tuning:** Integrated **Redis cache** (Redisson) within Spark jobs to reduce latency.\n* **Codebase Evolution:** Developed complex SQL procedures for data analysis and executed significant codebase refactoring.\n* **Desktop Tooling:** Developed a user-friendly desktop application in **Go** using the **Fyne** framework for task automation involving Excel manipulation, data filtering pipelines, and automated report generation.\n* *Tech Stack:* Kubernetes, Docker, Git, Dremio.\n\n**Android Developer** | **Iriscube Reply** | *Feb 2022 \\u{2013} Jul 2022*\n* Developed and maintained a corporate Android banking application.\n* Migrated the codebase from **Java** to **Kotlin**.\n* Implemented new user-facing features and performed critical bug fixing to ensure app stability.\n\n---\n\n### Education\n\n**B.Eng. in Software Engineering** | **University of Catania** | *Oct 2018 \\u{2013} Mar 2022*\n* **Thesis:** *Implementation of learning algorithms on microcontrollers.* Developed a Human Activity Recognition (HAR) model on an STM microcontroller using **TFLite**.\n\n---\n\n### Skills\n\n* **Data Technologies:** Apache Spark, Kafka, MongoDB Atlas, Apache NiFi, Redis, Dremio.\n* **Programming:** Java, Go, Kotlin, Python, Scala, C, SQL, Bash, TypeScript, C#.\n* **Frontend & Graphics:** React, Three.js, Unity.\n* **Frameworks and Libraries:** Spring Boot, React, TensorFlow Lite (TFLite).\n* **Cloud & DevOps:** Kubernetes, Docker, AWS (S3), Git.\n* **Languages:** English (Proficient), Italian (Native).\n\n---\n\n### Side Projects\n\n**Physics Simulations**\n* Implemented complex physics papers using **Three.js** to create realistic browser-based visualizations.\n* **Simulations developed:**\n    * *Heron's Fountain:* A fluid dynamics simulation demonstrating pneumatic and hydraulic pressure.\n    * *Unblowing bubbles: Understanding the physics of bubble deflation through a straw:* A simulation modeling surface tension and air pressure dynamics.\n    * *Boyle's Perpetual Movement Flask:* (In Progress) A simulation of the classic hydrostatic paradox.\n\n**Videogames & Interactive Media**\n* **Quantum Dungeon Crawler:** Designed a dungeon crawler where real quantum computing algorithms (Grover, Shor, Bernstein-Vazirani, VQE, QAOA) become core gameplay mechanics. Features an in-game circuit composer, temperature-driven decoherence system, and progressive level design teaching quantum concepts. (In Progress)\n* **Kamisado:** A full-featured real-time multiplayer Kamisado board game with sumo push mechanics, chess-style timers, and spectator mode. Built with **TypeScript**, **Node.js**, **Express**, and **Socket.IO**.\n* **Greta's Adventures:** Developed a full platform video game using **Unity** and **C#** (Awarded First Prize at University of Catania's Game Jam).\n* **Interactive Physics Lab:** Developing a fully interactive virtual physics laboratory using **React**, **TypeScript**, and **Three.js** (In Progress).\n\n**Other Engineering Projects**\n* **Computer Vision App:** Created an Android application enabling 3D model manipulation via computer vision using hand gestures.\n* **C Standard Library:** Re-implemented portions of the C Standard Library to deepen understanding of low-level memory management.\n\n---\n\n### Competitions\n\n* **MALLORN Astronomical Classification Challenge** (Kaggle): Classified astronomical transients to detect Tidal Disruption Events (stars torn apart by black holes). Ranked **58th out of 894** participants.\n\n---\n\n### Certifications\n\n* **Coursera:** The Data Scientist\\u{2019}s Toolbox - Johns Hopkins University\n* **Coursera:** Algorithm Toolbox - UC San Diego\n* **Coursera:** Improving Deep Neural Networks - DeepLearning.AI\n* **Coursera:** Getting and Cleaning Data - Johns Hopkins University\n* **Cambridge English:** First (FCE)\n`;\ndocument.getElementById(\"cv-content\").innerHTML = (0, $d55025bea272cdc1$exports.marked).parse($63a51ab81e297f22$var$cvMd);\n\n\n//# sourceMappingURL=cv.6514e68f.js.map\n","import { marked } from \"marked\";\n\nlet cvMd = `# Antonino Cilione\n**Big Data Engineer**\nReggio Calabria, Italy | (+39) 347-252-7757\nantoninocilione96@gmail.com | linkedin.com/in/antonino-cilione-1258291a6 | github.com/acilione | acilione.github.io\n\n### Professional Summary\nBig Data Engineer with extensive experience in designing scalable ETL pipelines and microservices. Proven track record in migrating legacy frameworks to modern cloud architectures and optimizing database performance. Specializes in the ingestion and processing of critical energy grid data, utilizing the Hadoop ecosystem (Spark, Kafka) and Cloud technologies.\n\n---\n\n### Work History\n\n**Big Data Engineer** | **Enel** | *Jul 2022  Present*\n* **Primary Responsibility:** Engineered and maintained high-throughput data pipelines specifically for the **ingestion of medium and low voltage measurements**, ensuring data accuracy and real-time availability for grid analysis.\n* **Framework Migration:** Led the complex framework migration from Cloudera Distribution Hadoop (CDH) to **Cloudera Data Platform (CDP)**, modernizing the data infrastructure.\n* **ETL Development:** Developed and maintained high-performance ETL pipelines using **Apache Spark** and **Kafka**.\n* **R&D & Optimization:** Researched and benchmarked **Apache Iceberg** functionalities using Spark and Flink; successfully implemented a custom \"equality delete files\" commit feature on Apache Spark.\n* **Data Ingestion:** Designed and implemented robust data ingestion flows using **Apache NiFi**.\n* **Database Management:** Optimized **MongoDB Atlas** clusters by tuning indexes, memory, and configuring auto-scaling to balance cost and performance.\n* **Microservices:** Developed **Java/Kotlin microservices** (Spring Boot) to expose NoSQL data stored on MongoDB to downstream applications.\n* **Automation:** Authored **Python scripts** for advanced S3 Parquet file operations (merge, deduplicate, backup, restore) and **Bash scripts** for automated Kafka/S3 status checks.\n* **Performance Tuning:** Integrated **Redis cache** (Redisson) within Spark jobs to reduce latency.\n* **Codebase Evolution:** Developed complex SQL procedures for data analysis and executed significant codebase refactoring.\n* **Desktop Tooling:** Developed a user-friendly desktop application in **Go** using the **Fyne** framework for task automation involving Excel manipulation, data filtering pipelines, and automated report generation.\n* *Tech Stack:* Kubernetes, Docker, Git, Dremio.\n\n**Android Developer** | **Iriscube Reply** | *Feb 2022  Jul 2022*\n* Developed and maintained a corporate Android banking application.\n* Migrated the codebase from **Java** to **Kotlin**.\n* Implemented new user-facing features and performed critical bug fixing to ensure app stability.\n\n---\n\n### Education\n\n**B.Eng. in Software Engineering** | **University of Catania** | *Oct 2018  Mar 2022*\n* **Thesis:** *Implementation of learning algorithms on microcontrollers.* Developed a Human Activity Recognition (HAR) model on an STM microcontroller using **TFLite**.\n\n---\n\n### Skills\n\n* **Data Technologies:** Apache Spark, Kafka, MongoDB Atlas, Apache NiFi, Redis, Dremio.\n* **Programming:** Java, Go, Kotlin, Python, Scala, C, SQL, Bash, TypeScript, C#.\n* **Frontend & Graphics:** React, Three.js, Unity.\n* **Frameworks and Libraries:** Spring Boot, React, TensorFlow Lite (TFLite).\n* **Cloud & DevOps:** Kubernetes, Docker, AWS (S3), Git.\n* **Languages:** English (Proficient), Italian (Native).\n\n---\n\n### Side Projects\n\n**Physics Simulations**\n* Implemented complex physics papers using **Three.js** to create realistic browser-based visualizations.\n* **Simulations developed:**\n    * *Heron's Fountain:* A fluid dynamics simulation demonstrating pneumatic and hydraulic pressure.\n    * *Unblowing bubbles: Understanding the physics of bubble deflation through a straw:* A simulation modeling surface tension and air pressure dynamics.\n    * *Boyle's Perpetual Movement Flask:* (In Progress) A simulation of the classic hydrostatic paradox.\n\n**Videogames & Interactive Media**\n* **Quantum Dungeon Crawler:** Designed a dungeon crawler where real quantum computing algorithms (Grover, Shor, Bernstein-Vazirani, VQE, QAOA) become core gameplay mechanics. Features an in-game circuit composer, temperature-driven decoherence system, and progressive level design teaching quantum concepts. (In Progress)\n* **Kamisado:** A full-featured real-time multiplayer Kamisado board game with sumo push mechanics, chess-style timers, and spectator mode. Built with **TypeScript**, **Node.js**, **Express**, and **Socket.IO**.\n* **Greta's Adventures:** Developed a full platform video game using **Unity** and **C#** (Awarded First Prize at University of Catania's Game Jam).\n* **Interactive Physics Lab:** Developing a fully interactive virtual physics laboratory using **React**, **TypeScript**, and **Three.js** (In Progress).\n\n**Other Engineering Projects**\n* **Computer Vision App:** Created an Android application enabling 3D model manipulation via computer vision using hand gestures.\n* **C Standard Library:** Re-implemented portions of the C Standard Library to deepen understanding of low-level memory management.\n\n---\n\n### Competitions\n\n* **MALLORN Astronomical Classification Challenge** (Kaggle): Classified astronomical transients to detect Tidal Disruption Events (stars torn apart by black holes). Ranked **58th out of 894** participants.\n\n---\n\n### Certifications\n\n* **Coursera:** The Data Scientists Toolbox - Johns Hopkins University\n* **Coursera:** Algorithm Toolbox - UC San Diego\n* **Coursera:** Improving Deep Neural Networks - DeepLearning.AI\n* **Coursera:** Getting and Cleaning Data - Johns Hopkins University\n* **Cambridge English:** First (FCE)\n`\ndocument.getElementById(\"cv-content\").innerHTML =\n    marked.parse(cvMd)","/**\n * marked v16.4.1 - a markdown parser\n * Copyright (c) 2011-2025, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n(function(g,f){if(typeof exports==\"object\"&&typeof module<\"u\"){module.exports=f()}else if(\"function\"==typeof define && define.amd){define(\"marked\",f)}else {g[\"marked\"]=f()}}(typeof globalThis < \"u\" ? globalThis : typeof self < \"u\" ? self : this,function(){var exports={};var __exports=exports;var module={exports};\n\"use strict\";var G=Object.defineProperty;var Re=Object.getOwnPropertyDescriptor;var Te=Object.getOwnPropertyNames;var Oe=Object.prototype.hasOwnProperty;var we=(l,e)=>{for(var t in e)G(l,t,{get:e[t],enumerable:!0})},ye=(l,e,t,n)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of Te(e))!Oe.call(l,r)&&r!==t&&G(l,r,{get:()=>e[r],enumerable:!(n=Re(e,r))||n.enumerable});return l};var Pe=l=>ye(G({},\"__esModule\",{value:!0}),l);var kt={};we(kt,{Hooks:()=>S,Lexer:()=>x,Marked:()=>A,Parser:()=>b,Renderer:()=>P,TextRenderer:()=>$,Tokenizer:()=>y,defaults:()=>T,getDefaults:()=>_,lexer:()=>dt,marked:()=>k,options:()=>ot,parse:()=>ct,parseInline:()=>pt,parser:()=>ht,setOptions:()=>at,use:()=>lt,walkTokens:()=>ut});module.exports=Pe(kt);function _(){return{async:!1,breaks:!1,extensions:null,gfm:!0,hooks:null,pedantic:!1,renderer:null,silent:!1,tokenizer:null,walkTokens:null}}var T=_();function N(l){T=l}var E={exec:()=>null};function h(l,e=\"\"){let t=typeof l==\"string\"?l:l.source,n={replace:(r,i)=>{let s=typeof i==\"string\"?i:i.source;return s=s.replace(m.caret,\"$1\"),t=t.replace(r,s),n},getRegex:()=>new RegExp(t,e)};return n}var m={codeRemoveIndent:/^(?: {1,4}| {0,3}\\t)/gm,outputLinkReplace:/\\\\([\\[\\]])/g,indentCodeCompensation:/^(\\s+)(?:```)/,beginningSpace:/^\\s+/,endingHash:/#$/,startingSpaceChar:/^ /,endingSpaceChar:/ $/,nonSpaceChar:/[^ ]/,newLineCharGlobal:/\\n/g,tabCharGlobal:/\\t/g,multipleSpaceGlobal:/\\s+/g,blankLine:/^[ \\t]*$/,doubleBlankLine:/\\n[ \\t]*\\n[ \\t]*$/,blockquoteStart:/^ {0,3}>/,blockquoteSetextReplace:/\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,blockquoteSetextReplace2:/^ {0,3}>[ \\t]?/gm,listReplaceTabs:/^\\t+/,listReplaceNesting:/^ {1,4}(?=( {4})*[^ ])/g,listIsTask:/^\\[[ xX]\\] /,listReplaceTask:/^\\[[ xX]\\] +/,anyLine:/\\n.*\\n/,hrefBrackets:/^<(.*)>$/,tableDelimiter:/[:|]/,tableAlignChars:/^\\||\\| *$/g,tableRowBlankLine:/\\n[ \\t]*$/,tableAlignRight:/^ *-+: *$/,tableAlignCenter:/^ *:-+: *$/,tableAlignLeft:/^ *:-+ *$/,startATag:/^<a /i,endATag:/^<\\/a>/i,startPreScriptTag:/^<(pre|code|kbd|script)(\\s|>)/i,endPreScriptTag:/^<\\/(pre|code|kbd|script)(\\s|>)/i,startAngleBracket:/^</,endAngleBracket:/>$/,pedanticHrefTitle:/^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,unicodeAlphaNumeric:/[\\p{L}\\p{N}]/u,escapeTest:/[&<>\"']/,escapeReplace:/[&<>\"']/g,escapeTestNoEncode:/[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,escapeReplaceNoEncode:/[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,unescapeTest:/&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,caret:/(^|[^\\[])\\^/g,percentDecode:/%25/g,findPipe:/\\|/g,splitPipe:/ \\|/,slashPipe:/\\\\\\|/g,carriageReturn:/\\r\\n|\\r/g,spaceLine:/^ +$/gm,notSpaceStart:/^\\S*/,endingNewline:/\\n$/,listItemRegex:l=>new RegExp(`^( {0,3}${l})((?:[\t ][^\\\\n]*)?(?:\\\\n|$))`),nextBulletRegex:l=>new RegExp(`^ {0,${Math.min(3,l-1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \t][^\\\\n]*)?(?:\\\\n|$))`),hrRegex:l=>new RegExp(`^ {0,${Math.min(3,l-1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),fencesBeginRegex:l=>new RegExp(`^ {0,${Math.min(3,l-1)}}(?:\\`\\`\\`|~~~)`),headingBeginRegex:l=>new RegExp(`^ {0,${Math.min(3,l-1)}}#`),htmlBeginRegex:l=>new RegExp(`^ {0,${Math.min(3,l-1)}}<(?:[a-z].*>|!--)`,\"i\")},Se=/^(?:[ \\t]*(?:\\n|$))+/,$e=/^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/,_e=/^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/,C=/^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/,Le=/^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/,j=/(?:[*+-]|\\d{1,9}[.)])/,oe=/^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,ae=h(oe).replace(/bull/g,j).replace(/blockCode/g,/(?: {4}| {0,3}\\t)/).replace(/fences/g,/ {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g,/ {0,3}>/).replace(/heading/g,/ {0,3}#{1,6}/).replace(/html/g,/ {0,3}<[^\\n>]+>\\n/).replace(/\\|table/g,\"\").getRegex(),Me=h(oe).replace(/bull/g,j).replace(/blockCode/g,/(?: {4}| {0,3}\\t)/).replace(/fences/g,/ {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g,/ {0,3}>/).replace(/heading/g,/ {0,3}#{1,6}/).replace(/html/g,/ {0,3}<[^\\n>]+>\\n/).replace(/table/g,/ {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/).getRegex(),Q=/^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/,ze=/^[^\\n]+/,U=/(?!\\s*\\])(?:\\\\[\\s\\S]|[^\\[\\]\\\\])+/,Ae=h(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/).replace(\"label\",U).replace(\"title\",/(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/).getRegex(),Ie=h(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/).replace(/bull/g,j).getRegex(),v=\"address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul\",K=/<!--(?:-?>|[\\s\\S]*?(?:-->|$))/,Ee=h(\"^ {0,3}(?:<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)|comment[^\\\\n]*(\\\\n+|$)|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$))\",\"i\").replace(\"comment\",K).replace(\"tag\",v).replace(\"attribute\",/ +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/).getRegex(),le=h(Q).replace(\"hr\",C).replace(\"heading\",\" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\",\"\").replace(\"|table\",\"\").replace(\"blockquote\",\" {0,3}>\").replace(\"fences\",\" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\",\" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\",\"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\",v).getRegex(),Ce=h(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/).replace(\"paragraph\",le).getRegex(),W={blockquote:Ce,code:$e,def:Ae,fences:_e,heading:Le,hr:C,html:Ee,lheading:ae,list:Ie,newline:Se,paragraph:le,table:E,text:ze},se=h(\"^ *([^\\\\n ].*)\\\\n {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\").replace(\"hr\",C).replace(\"heading\",\" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"blockquote\",\" {0,3}>\").replace(\"code\",\"(?: {4}| {0,3}\t)[^\\\\n]\").replace(\"fences\",\" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\",\" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\",\"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\",v).getRegex(),Be={...W,lheading:Me,table:se,paragraph:h(Q).replace(\"hr\",C).replace(\"heading\",\" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\",\"\").replace(\"table\",se).replace(\"blockquote\",\" {0,3}>\").replace(\"fences\",\" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\",\" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\",\"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\",v).getRegex()},qe={...W,html:h(`^ *(?:comment *(?:\\\\n|\\\\s*$)|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\\\s[^'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))`).replace(\"comment\",K).replace(/tag/g,\"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\").getRegex(),def:/^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,heading:/^(#{1,6})(.*)(?:\\n+|$)/,fences:E,lheading:/^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,paragraph:h(Q).replace(\"hr\",C).replace(\"heading\",` *#{1,6} *[^\n]`).replace(\"lheading\",ae).replace(\"|table\",\"\").replace(\"blockquote\",\" {0,3}>\").replace(\"|fences\",\"\").replace(\"|list\",\"\").replace(\"|html\",\"\").replace(\"|tag\",\"\").getRegex()},ve=/^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/,De=/^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/,ue=/^( {2,}|\\\\)\\n(?!\\s*$)/,He=/^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/,D=/[\\p{P}\\p{S}]/u,X=/[\\s\\p{P}\\p{S}]/u,pe=/[^\\s\\p{P}\\p{S}]/u,Ze=h(/^((?![*_])punctSpace)/,\"u\").replace(/punctSpace/g,X).getRegex(),ce=/(?!~)[\\p{P}\\p{S}]/u,Ge=/(?!~)[\\s\\p{P}\\p{S}]/u,Ne=/(?:[^\\s\\p{P}\\p{S}]|~)/u,Fe=h(/link|code|html/,\"g\").replace(\"link\",/\\[(?:[^\\[\\]`]|(?<!`)(?<a>`+)[^`]+\\k<a>(?!`))*?\\]\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)]|\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)])*\\))*\\)/).replace(\"code\",/(?<!`)(?<b>`+)[^`]+\\k<b>(?!`)/).replace(\"html\",/<(?! )[^<>]*?>/).getRegex(),he=/^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/,je=h(he,\"u\").replace(/punct/g,D).getRegex(),Qe=h(he,\"u\").replace(/punct/g,ce).getRegex(),de=\"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)|[^*]+(?=[^*])|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)|notPunctSpace(\\\\*+)(?=notPunctSpace)\",Ue=h(de,\"gu\").replace(/notPunctSpace/g,pe).replace(/punctSpace/g,X).replace(/punct/g,D).getRegex(),Ke=h(de,\"gu\").replace(/notPunctSpace/g,Ne).replace(/punctSpace/g,Ge).replace(/punct/g,ce).getRegex(),We=h(\"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)|[^_]+(?=[^_])|(?!_)punct(_+)(?=[\\\\s]|$)|notPunctSpace(_+)(?!_)(?=punctSpace|$)|(?!_)punctSpace(_+)(?=notPunctSpace)|[\\\\s](_+)(?!_)(?=punct)|(?!_)punct(_+)(?!_)(?=punct)\",\"gu\").replace(/notPunctSpace/g,pe).replace(/punctSpace/g,X).replace(/punct/g,D).getRegex(),Xe=h(/\\\\(punct)/,\"gu\").replace(/punct/g,D).getRegex(),Je=h(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/).replace(\"scheme\",/[a-zA-Z][a-zA-Z0-9+.-]{1,31}/).replace(\"email\",/[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/).getRegex(),Ve=h(K).replace(\"(?:-->|$)\",\"-->\").getRegex(),Ye=h(\"^comment|^</[a-zA-Z][\\\\w:-]*\\\\s*>|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>|^<\\\\?[\\\\s\\\\S]*?\\\\?>|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\").replace(\"comment\",Ve).replace(\"attribute\",/\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/).getRegex(),q=/(?:\\[(?:\\\\[\\s\\S]|[^\\[\\]\\\\])*\\]|\\\\[\\s\\S]|`+[^`]*?`+(?!`)|[^\\[\\]\\\\`])*?/,et=h(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/).replace(\"label\",q).replace(\"href\",/<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/).replace(\"title\",/\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/).getRegex(),ke=h(/^!?\\[(label)\\]\\[(ref)\\]/).replace(\"label\",q).replace(\"ref\",U).getRegex(),ge=h(/^!?\\[(ref)\\](?:\\[\\])?/).replace(\"ref\",U).getRegex(),tt=h(\"reflink|nolink(?!\\\\()\",\"g\").replace(\"reflink\",ke).replace(\"nolink\",ge).getRegex(),ie=/[hH][tT][tT][pP][sS]?|[fF][tT][pP]/,J={_backpedal:E,anyPunctuation:Xe,autolink:Je,blockSkip:Fe,br:ue,code:De,del:E,emStrongLDelim:je,emStrongRDelimAst:Ue,emStrongRDelimUnd:We,escape:ve,link:et,nolink:ge,punctuation:Ze,reflink:ke,reflinkSearch:tt,tag:Ye,text:He,url:E},nt={...J,link:h(/^!?\\[(label)\\]\\((.*?)\\)/).replace(\"label\",q).getRegex(),reflink:h(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/).replace(\"label\",q).getRegex()},F={...J,emStrongRDelimAst:Ke,emStrongLDelim:Qe,url:h(/^((?:protocol):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/).replace(\"protocol\",ie).replace(\"email\",/[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/).getRegex(),_backpedal:/(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,del:/^(~~?)(?=[^\\s~])((?:\\\\[\\s\\S]|[^\\\\])*?(?:\\\\[\\s\\S]|[^\\s~\\\\]))\\1(?=[^~]|$)/,text:h(/^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|protocol:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/).replace(\"protocol\",ie).getRegex()},rt={...F,br:h(ue).replace(\"{2,}\",\"*\").getRegex(),text:h(F.text).replace(\"\\\\b_\",\"\\\\b_| {2,}\\\\n\").replace(/\\{2,\\}/g,\"*\").getRegex()},B={normal:W,gfm:Be,pedantic:qe},M={normal:J,gfm:F,breaks:rt,pedantic:nt};var st={\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"},fe=l=>st[l];function w(l,e){if(e){if(m.escapeTest.test(l))return l.replace(m.escapeReplace,fe)}else if(m.escapeTestNoEncode.test(l))return l.replace(m.escapeReplaceNoEncode,fe);return l}function V(l){try{l=encodeURI(l).replace(m.percentDecode,\"%\")}catch{return null}return l}function Y(l,e){let t=l.replace(m.findPipe,(i,s,o)=>{let a=!1,u=s;for(;--u>=0&&o[u]===\"\\\\\";)a=!a;return a?\"|\":\" |\"}),n=t.split(m.splitPipe),r=0;if(n[0].trim()||n.shift(),n.length>0&&!n.at(-1)?.trim()&&n.pop(),e)if(n.length>e)n.splice(e);else for(;n.length<e;)n.push(\"\");for(;r<n.length;r++)n[r]=n[r].trim().replace(m.slashPipe,\"|\");return n}function z(l,e,t){let n=l.length;if(n===0)return\"\";let r=0;for(;r<n;){let i=l.charAt(n-r-1);if(i===e&&!t)r++;else if(i!==e&&t)r++;else break}return l.slice(0,n-r)}function me(l,e){if(l.indexOf(e[1])===-1)return-1;let t=0;for(let n=0;n<l.length;n++)if(l[n]===\"\\\\\")n++;else if(l[n]===e[0])t++;else if(l[n]===e[1]&&(t--,t<0))return n;return t>0?-2:-1}function xe(l,e,t,n,r){let i=e.href,s=e.title||null,o=l[1].replace(r.other.outputLinkReplace,\"$1\");n.state.inLink=!0;let a={type:l[0].charAt(0)===\"!\"?\"image\":\"link\",raw:t,href:i,title:s,text:o,tokens:n.inlineTokens(o)};return n.state.inLink=!1,a}function it(l,e,t){let n=l.match(t.other.indentCodeCompensation);if(n===null)return e;let r=n[1];return e.split(`\n`).map(i=>{let s=i.match(t.other.beginningSpace);if(s===null)return i;let[o]=s;return o.length>=r.length?i.slice(r.length):i}).join(`\n`)}var y=class{options;rules;lexer;constructor(e){this.options=e||T}space(e){let t=this.rules.block.newline.exec(e);if(t&&t[0].length>0)return{type:\"space\",raw:t[0]}}code(e){let t=this.rules.block.code.exec(e);if(t){let n=t[0].replace(this.rules.other.codeRemoveIndent,\"\");return{type:\"code\",raw:t[0],codeBlockStyle:\"indented\",text:this.options.pedantic?n:z(n,`\n`)}}}fences(e){let t=this.rules.block.fences.exec(e);if(t){let n=t[0],r=it(n,t[3]||\"\",this.rules);return{type:\"code\",raw:n,lang:t[2]?t[2].trim().replace(this.rules.inline.anyPunctuation,\"$1\"):t[2],text:r}}}heading(e){let t=this.rules.block.heading.exec(e);if(t){let n=t[2].trim();if(this.rules.other.endingHash.test(n)){let r=z(n,\"#\");(this.options.pedantic||!r||this.rules.other.endingSpaceChar.test(r))&&(n=r.trim())}return{type:\"heading\",raw:t[0],depth:t[1].length,text:n,tokens:this.lexer.inline(n)}}}hr(e){let t=this.rules.block.hr.exec(e);if(t)return{type:\"hr\",raw:z(t[0],`\n`)}}blockquote(e){let t=this.rules.block.blockquote.exec(e);if(t){let n=z(t[0],`\n`).split(`\n`),r=\"\",i=\"\",s=[];for(;n.length>0;){let o=!1,a=[],u;for(u=0;u<n.length;u++)if(this.rules.other.blockquoteStart.test(n[u]))a.push(n[u]),o=!0;else if(!o)a.push(n[u]);else break;n=n.slice(u);let c=a.join(`\n`),p=c.replace(this.rules.other.blockquoteSetextReplace,`\n    $1`).replace(this.rules.other.blockquoteSetextReplace2,\"\");r=r?`${r}\n${c}`:c,i=i?`${i}\n${p}`:p;let g=this.lexer.state.top;if(this.lexer.state.top=!0,this.lexer.blockTokens(p,s,!0),this.lexer.state.top=g,n.length===0)break;let d=s.at(-1);if(d?.type===\"code\")break;if(d?.type===\"blockquote\"){let R=d,f=R.raw+`\n`+n.join(`\n`),O=this.blockquote(f);s[s.length-1]=O,r=r.substring(0,r.length-R.raw.length)+O.raw,i=i.substring(0,i.length-R.text.length)+O.text;break}else if(d?.type===\"list\"){let R=d,f=R.raw+`\n`+n.join(`\n`),O=this.list(f);s[s.length-1]=O,r=r.substring(0,r.length-d.raw.length)+O.raw,i=i.substring(0,i.length-R.raw.length)+O.raw,n=f.substring(s.at(-1).raw.length).split(`\n`);continue}}return{type:\"blockquote\",raw:r,tokens:s,text:i}}}list(e){let t=this.rules.block.list.exec(e);if(t){let n=t[1].trim(),r=n.length>1,i={type:\"list\",raw:\"\",ordered:r,start:r?+n.slice(0,-1):\"\",loose:!1,items:[]};n=r?`\\\\d{1,9}\\\\${n.slice(-1)}`:`\\\\${n}`,this.options.pedantic&&(n=r?n:\"[*+-]\");let s=this.rules.other.listItemRegex(n),o=!1;for(;e;){let u=!1,c=\"\",p=\"\";if(!(t=s.exec(e))||this.rules.block.hr.test(e))break;c=t[0],e=e.substring(c.length);let g=t[2].split(`\n`,1)[0].replace(this.rules.other.listReplaceTabs,H=>\" \".repeat(3*H.length)),d=e.split(`\n`,1)[0],R=!g.trim(),f=0;if(this.options.pedantic?(f=2,p=g.trimStart()):R?f=t[1].length+1:(f=t[2].search(this.rules.other.nonSpaceChar),f=f>4?1:f,p=g.slice(f),f+=t[1].length),R&&this.rules.other.blankLine.test(d)&&(c+=d+`\n`,e=e.substring(d.length+1),u=!0),!u){let H=this.rules.other.nextBulletRegex(f),te=this.rules.other.hrRegex(f),ne=this.rules.other.fencesBeginRegex(f),re=this.rules.other.headingBeginRegex(f),be=this.rules.other.htmlBeginRegex(f);for(;e;){let Z=e.split(`\n`,1)[0],I;if(d=Z,this.options.pedantic?(d=d.replace(this.rules.other.listReplaceNesting,\"  \"),I=d):I=d.replace(this.rules.other.tabCharGlobal,\"    \"),ne.test(d)||re.test(d)||be.test(d)||H.test(d)||te.test(d))break;if(I.search(this.rules.other.nonSpaceChar)>=f||!d.trim())p+=`\n`+I.slice(f);else{if(R||g.replace(this.rules.other.tabCharGlobal,\"    \").search(this.rules.other.nonSpaceChar)>=4||ne.test(g)||re.test(g)||te.test(g))break;p+=`\n`+d}!R&&!d.trim()&&(R=!0),c+=Z+`\n`,e=e.substring(Z.length+1),g=I.slice(f)}}i.loose||(o?i.loose=!0:this.rules.other.doubleBlankLine.test(c)&&(o=!0));let O=null,ee;this.options.gfm&&(O=this.rules.other.listIsTask.exec(p),O&&(ee=O[0]!==\"[ ] \",p=p.replace(this.rules.other.listReplaceTask,\"\"))),i.items.push({type:\"list_item\",raw:c,task:!!O,checked:ee,loose:!1,text:p,tokens:[]}),i.raw+=c}let a=i.items.at(-1);if(a)a.raw=a.raw.trimEnd(),a.text=a.text.trimEnd();else return;i.raw=i.raw.trimEnd();for(let u=0;u<i.items.length;u++)if(this.lexer.state.top=!1,i.items[u].tokens=this.lexer.blockTokens(i.items[u].text,[]),!i.loose){let c=i.items[u].tokens.filter(g=>g.type===\"space\"),p=c.length>0&&c.some(g=>this.rules.other.anyLine.test(g.raw));i.loose=p}if(i.loose)for(let u=0;u<i.items.length;u++)i.items[u].loose=!0;return i}}html(e){let t=this.rules.block.html.exec(e);if(t)return{type:\"html\",block:!0,raw:t[0],pre:t[1]===\"pre\"||t[1]===\"script\"||t[1]===\"style\",text:t[0]}}def(e){let t=this.rules.block.def.exec(e);if(t){let n=t[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal,\" \"),r=t[2]?t[2].replace(this.rules.other.hrefBrackets,\"$1\").replace(this.rules.inline.anyPunctuation,\"$1\"):\"\",i=t[3]?t[3].substring(1,t[3].length-1).replace(this.rules.inline.anyPunctuation,\"$1\"):t[3];return{type:\"def\",tag:n,raw:t[0],href:r,title:i}}}table(e){let t=this.rules.block.table.exec(e);if(!t||!this.rules.other.tableDelimiter.test(t[2]))return;let n=Y(t[1]),r=t[2].replace(this.rules.other.tableAlignChars,\"\").split(\"|\"),i=t[3]?.trim()?t[3].replace(this.rules.other.tableRowBlankLine,\"\").split(`\n`):[],s={type:\"table\",raw:t[0],header:[],align:[],rows:[]};if(n.length===r.length){for(let o of r)this.rules.other.tableAlignRight.test(o)?s.align.push(\"right\"):this.rules.other.tableAlignCenter.test(o)?s.align.push(\"center\"):this.rules.other.tableAlignLeft.test(o)?s.align.push(\"left\"):s.align.push(null);for(let o=0;o<n.length;o++)s.header.push({text:n[o],tokens:this.lexer.inline(n[o]),header:!0,align:s.align[o]});for(let o of i)s.rows.push(Y(o,s.header.length).map((a,u)=>({text:a,tokens:this.lexer.inline(a),header:!1,align:s.align[u]})));return s}}lheading(e){let t=this.rules.block.lheading.exec(e);if(t)return{type:\"heading\",raw:t[0],depth:t[2].charAt(0)===\"=\"?1:2,text:t[1],tokens:this.lexer.inline(t[1])}}paragraph(e){let t=this.rules.block.paragraph.exec(e);if(t){let n=t[1].charAt(t[1].length-1)===`\n`?t[1].slice(0,-1):t[1];return{type:\"paragraph\",raw:t[0],text:n,tokens:this.lexer.inline(n)}}}text(e){let t=this.rules.block.text.exec(e);if(t)return{type:\"text\",raw:t[0],text:t[0],tokens:this.lexer.inline(t[0])}}escape(e){let t=this.rules.inline.escape.exec(e);if(t)return{type:\"escape\",raw:t[0],text:t[1]}}tag(e){let t=this.rules.inline.tag.exec(e);if(t)return!this.lexer.state.inLink&&this.rules.other.startATag.test(t[0])?this.lexer.state.inLink=!0:this.lexer.state.inLink&&this.rules.other.endATag.test(t[0])&&(this.lexer.state.inLink=!1),!this.lexer.state.inRawBlock&&this.rules.other.startPreScriptTag.test(t[0])?this.lexer.state.inRawBlock=!0:this.lexer.state.inRawBlock&&this.rules.other.endPreScriptTag.test(t[0])&&(this.lexer.state.inRawBlock=!1),{type:\"html\",raw:t[0],inLink:this.lexer.state.inLink,inRawBlock:this.lexer.state.inRawBlock,block:!1,text:t[0]}}link(e){let t=this.rules.inline.link.exec(e);if(t){let n=t[2].trim();if(!this.options.pedantic&&this.rules.other.startAngleBracket.test(n)){if(!this.rules.other.endAngleBracket.test(n))return;let s=z(n.slice(0,-1),\"\\\\\");if((n.length-s.length)%2===0)return}else{let s=me(t[2],\"()\");if(s===-2)return;if(s>-1){let a=(t[0].indexOf(\"!\")===0?5:4)+t[1].length+s;t[2]=t[2].substring(0,s),t[0]=t[0].substring(0,a).trim(),t[3]=\"\"}}let r=t[2],i=\"\";if(this.options.pedantic){let s=this.rules.other.pedanticHrefTitle.exec(r);s&&(r=s[1],i=s[3])}else i=t[3]?t[3].slice(1,-1):\"\";return r=r.trim(),this.rules.other.startAngleBracket.test(r)&&(this.options.pedantic&&!this.rules.other.endAngleBracket.test(n)?r=r.slice(1):r=r.slice(1,-1)),xe(t,{href:r&&r.replace(this.rules.inline.anyPunctuation,\"$1\"),title:i&&i.replace(this.rules.inline.anyPunctuation,\"$1\")},t[0],this.lexer,this.rules)}}reflink(e,t){let n;if((n=this.rules.inline.reflink.exec(e))||(n=this.rules.inline.nolink.exec(e))){let r=(n[2]||n[1]).replace(this.rules.other.multipleSpaceGlobal,\" \"),i=t[r.toLowerCase()];if(!i){let s=n[0].charAt(0);return{type:\"text\",raw:s,text:s}}return xe(n,i,n[0],this.lexer,this.rules)}}emStrong(e,t,n=\"\"){let r=this.rules.inline.emStrongLDelim.exec(e);if(!r||r[3]&&n.match(this.rules.other.unicodeAlphaNumeric))return;if(!(r[1]||r[2]||\"\")||!n||this.rules.inline.punctuation.exec(n)){let s=[...r[0]].length-1,o,a,u=s,c=0,p=r[0][0]===\"*\"?this.rules.inline.emStrongRDelimAst:this.rules.inline.emStrongRDelimUnd;for(p.lastIndex=0,t=t.slice(-1*e.length+s);(r=p.exec(t))!=null;){if(o=r[1]||r[2]||r[3]||r[4]||r[5]||r[6],!o)continue;if(a=[...o].length,r[3]||r[4]){u+=a;continue}else if((r[5]||r[6])&&s%3&&!((s+a)%3)){c+=a;continue}if(u-=a,u>0)continue;a=Math.min(a,a+u+c);let g=[...r[0]][0].length,d=e.slice(0,s+r.index+g+a);if(Math.min(s,a)%2){let f=d.slice(1,-1);return{type:\"em\",raw:d,text:f,tokens:this.lexer.inlineTokens(f)}}let R=d.slice(2,-2);return{type:\"strong\",raw:d,text:R,tokens:this.lexer.inlineTokens(R)}}}}codespan(e){let t=this.rules.inline.code.exec(e);if(t){let n=t[2].replace(this.rules.other.newLineCharGlobal,\" \"),r=this.rules.other.nonSpaceChar.test(n),i=this.rules.other.startingSpaceChar.test(n)&&this.rules.other.endingSpaceChar.test(n);return r&&i&&(n=n.substring(1,n.length-1)),{type:\"codespan\",raw:t[0],text:n}}}br(e){let t=this.rules.inline.br.exec(e);if(t)return{type:\"br\",raw:t[0]}}del(e){let t=this.rules.inline.del.exec(e);if(t)return{type:\"del\",raw:t[0],text:t[2],tokens:this.lexer.inlineTokens(t[2])}}autolink(e){let t=this.rules.inline.autolink.exec(e);if(t){let n,r;return t[2]===\"@\"?(n=t[1],r=\"mailto:\"+n):(n=t[1],r=n),{type:\"link\",raw:t[0],text:n,href:r,tokens:[{type:\"text\",raw:n,text:n}]}}}url(e){let t;if(t=this.rules.inline.url.exec(e)){let n,r;if(t[2]===\"@\")n=t[0],r=\"mailto:\"+n;else{let i;do i=t[0],t[0]=this.rules.inline._backpedal.exec(t[0])?.[0]??\"\";while(i!==t[0]);n=t[0],t[1]===\"www.\"?r=\"http://\"+t[0]:r=t[0]}return{type:\"link\",raw:t[0],text:n,href:r,tokens:[{type:\"text\",raw:n,text:n}]}}}inlineText(e){let t=this.rules.inline.text.exec(e);if(t){let n=this.lexer.state.inRawBlock;return{type:\"text\",raw:t[0],text:t[0],escaped:n}}}};var x=class l{tokens;options;state;tokenizer;inlineQueue;constructor(e){this.tokens=[],this.tokens.links=Object.create(null),this.options=e||T,this.options.tokenizer=this.options.tokenizer||new y,this.tokenizer=this.options.tokenizer,this.tokenizer.options=this.options,this.tokenizer.lexer=this,this.inlineQueue=[],this.state={inLink:!1,inRawBlock:!1,top:!0};let t={other:m,block:B.normal,inline:M.normal};this.options.pedantic?(t.block=B.pedantic,t.inline=M.pedantic):this.options.gfm&&(t.block=B.gfm,this.options.breaks?t.inline=M.breaks:t.inline=M.gfm),this.tokenizer.rules=t}static get rules(){return{block:B,inline:M}}static lex(e,t){return new l(t).lex(e)}static lexInline(e,t){return new l(t).inlineTokens(e)}lex(e){e=e.replace(m.carriageReturn,`\n`),this.blockTokens(e,this.tokens);for(let t=0;t<this.inlineQueue.length;t++){let n=this.inlineQueue[t];this.inlineTokens(n.src,n.tokens)}return this.inlineQueue=[],this.tokens}blockTokens(e,t=[],n=!1){for(this.options.pedantic&&(e=e.replace(m.tabCharGlobal,\"    \").replace(m.spaceLine,\"\"));e;){let r;if(this.options.extensions?.block?.some(s=>(r=s.call({lexer:this},e,t))?(e=e.substring(r.raw.length),t.push(r),!0):!1))continue;if(r=this.tokenizer.space(e)){e=e.substring(r.raw.length);let s=t.at(-1);r.raw.length===1&&s!==void 0?s.raw+=`\n`:t.push(r);continue}if(r=this.tokenizer.code(e)){e=e.substring(r.raw.length);let s=t.at(-1);s?.type===\"paragraph\"||s?.type===\"text\"?(s.raw+=(s.raw.endsWith(`\n`)?\"\":`\n`)+r.raw,s.text+=`\n`+r.text,this.inlineQueue.at(-1).src=s.text):t.push(r);continue}if(r=this.tokenizer.fences(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.heading(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.hr(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.blockquote(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.list(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.html(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.def(e)){e=e.substring(r.raw.length);let s=t.at(-1);s?.type===\"paragraph\"||s?.type===\"text\"?(s.raw+=(s.raw.endsWith(`\n`)?\"\":`\n`)+r.raw,s.text+=`\n`+r.raw,this.inlineQueue.at(-1).src=s.text):this.tokens.links[r.tag]||(this.tokens.links[r.tag]={href:r.href,title:r.title},t.push(r));continue}if(r=this.tokenizer.table(e)){e=e.substring(r.raw.length),t.push(r);continue}if(r=this.tokenizer.lheading(e)){e=e.substring(r.raw.length),t.push(r);continue}let i=e;if(this.options.extensions?.startBlock){let s=1/0,o=e.slice(1),a;this.options.extensions.startBlock.forEach(u=>{a=u.call({lexer:this},o),typeof a==\"number\"&&a>=0&&(s=Math.min(s,a))}),s<1/0&&s>=0&&(i=e.substring(0,s+1))}if(this.state.top&&(r=this.tokenizer.paragraph(i))){let s=t.at(-1);n&&s?.type===\"paragraph\"?(s.raw+=(s.raw.endsWith(`\n`)?\"\":`\n`)+r.raw,s.text+=`\n`+r.text,this.inlineQueue.pop(),this.inlineQueue.at(-1).src=s.text):t.push(r),n=i.length!==e.length,e=e.substring(r.raw.length);continue}if(r=this.tokenizer.text(e)){e=e.substring(r.raw.length);let s=t.at(-1);s?.type===\"text\"?(s.raw+=(s.raw.endsWith(`\n`)?\"\":`\n`)+r.raw,s.text+=`\n`+r.text,this.inlineQueue.pop(),this.inlineQueue.at(-1).src=s.text):t.push(r);continue}if(e){let s=\"Infinite loop on byte: \"+e.charCodeAt(0);if(this.options.silent){console.error(s);break}else throw new Error(s)}}return this.state.top=!0,t}inline(e,t=[]){return this.inlineQueue.push({src:e,tokens:t}),t}inlineTokens(e,t=[]){let n=e,r=null;if(this.tokens.links){let o=Object.keys(this.tokens.links);if(o.length>0)for(;(r=this.tokenizer.rules.inline.reflinkSearch.exec(n))!=null;)o.includes(r[0].slice(r[0].lastIndexOf(\"[\")+1,-1))&&(n=n.slice(0,r.index)+\"[\"+\"a\".repeat(r[0].length-2)+\"]\"+n.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex))}for(;(r=this.tokenizer.rules.inline.anyPunctuation.exec(n))!=null;)n=n.slice(0,r.index)+\"++\"+n.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);for(;(r=this.tokenizer.rules.inline.blockSkip.exec(n))!=null;)n=n.slice(0,r.index)+\"[\"+\"a\".repeat(r[0].length-2)+\"]\"+n.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);n=this.options.hooks?.emStrongMask?.call({lexer:this},n)??n;let i=!1,s=\"\";for(;e;){i||(s=\"\"),i=!1;let o;if(this.options.extensions?.inline?.some(u=>(o=u.call({lexer:this},e,t))?(e=e.substring(o.raw.length),t.push(o),!0):!1))continue;if(o=this.tokenizer.escape(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.tag(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.link(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.reflink(e,this.tokens.links)){e=e.substring(o.raw.length);let u=t.at(-1);o.type===\"text\"&&u?.type===\"text\"?(u.raw+=o.raw,u.text+=o.text):t.push(o);continue}if(o=this.tokenizer.emStrong(e,n,s)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.codespan(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.br(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.del(e)){e=e.substring(o.raw.length),t.push(o);continue}if(o=this.tokenizer.autolink(e)){e=e.substring(o.raw.length),t.push(o);continue}if(!this.state.inLink&&(o=this.tokenizer.url(e))){e=e.substring(o.raw.length),t.push(o);continue}let a=e;if(this.options.extensions?.startInline){let u=1/0,c=e.slice(1),p;this.options.extensions.startInline.forEach(g=>{p=g.call({lexer:this},c),typeof p==\"number\"&&p>=0&&(u=Math.min(u,p))}),u<1/0&&u>=0&&(a=e.substring(0,u+1))}if(o=this.tokenizer.inlineText(a)){e=e.substring(o.raw.length),o.raw.slice(-1)!==\"_\"&&(s=o.raw.slice(-1)),i=!0;let u=t.at(-1);u?.type===\"text\"?(u.raw+=o.raw,u.text+=o.text):t.push(o);continue}if(e){let u=\"Infinite loop on byte: \"+e.charCodeAt(0);if(this.options.silent){console.error(u);break}else throw new Error(u)}}return t}};var P=class{options;parser;constructor(e){this.options=e||T}space(e){return\"\"}code({text:e,lang:t,escaped:n}){let r=(t||\"\").match(m.notSpaceStart)?.[0],i=e.replace(m.endingNewline,\"\")+`\n`;return r?'<pre><code class=\"language-'+w(r)+'\">'+(n?i:w(i,!0))+`</code></pre>\n`:\"<pre><code>\"+(n?i:w(i,!0))+`</code></pre>\n`}blockquote({tokens:e}){return`<blockquote>\n${this.parser.parse(e)}</blockquote>\n`}html({text:e}){return e}def(e){return\"\"}heading({tokens:e,depth:t}){return`<h${t}>${this.parser.parseInline(e)}</h${t}>\n`}hr(e){return`<hr>\n`}list(e){let t=e.ordered,n=e.start,r=\"\";for(let o=0;o<e.items.length;o++){let a=e.items[o];r+=this.listitem(a)}let i=t?\"ol\":\"ul\",s=t&&n!==1?' start=\"'+n+'\"':\"\";return\"<\"+i+s+`>\n`+r+\"</\"+i+`>\n`}listitem(e){let t=\"\";if(e.task){let n=this.checkbox({checked:!!e.checked});e.loose?e.tokens[0]?.type===\"paragraph\"?(e.tokens[0].text=n+\" \"+e.tokens[0].text,e.tokens[0].tokens&&e.tokens[0].tokens.length>0&&e.tokens[0].tokens[0].type===\"text\"&&(e.tokens[0].tokens[0].text=n+\" \"+w(e.tokens[0].tokens[0].text),e.tokens[0].tokens[0].escaped=!0)):e.tokens.unshift({type:\"text\",raw:n+\" \",text:n+\" \",escaped:!0}):t+=n+\" \"}return t+=this.parser.parse(e.tokens,!!e.loose),`<li>${t}</li>\n`}checkbox({checked:e}){return\"<input \"+(e?'checked=\"\" ':\"\")+'disabled=\"\" type=\"checkbox\">'}paragraph({tokens:e}){return`<p>${this.parser.parseInline(e)}</p>\n`}table(e){let t=\"\",n=\"\";for(let i=0;i<e.header.length;i++)n+=this.tablecell(e.header[i]);t+=this.tablerow({text:n});let r=\"\";for(let i=0;i<e.rows.length;i++){let s=e.rows[i];n=\"\";for(let o=0;o<s.length;o++)n+=this.tablecell(s[o]);r+=this.tablerow({text:n})}return r&&(r=`<tbody>${r}</tbody>`),`<table>\n<thead>\n`+t+`</thead>\n`+r+`</table>\n`}tablerow({text:e}){return`<tr>\n${e}</tr>\n`}tablecell(e){let t=this.parser.parseInline(e.tokens),n=e.header?\"th\":\"td\";return(e.align?`<${n} align=\"${e.align}\">`:`<${n}>`)+t+`</${n}>\n`}strong({tokens:e}){return`<strong>${this.parser.parseInline(e)}</strong>`}em({tokens:e}){return`<em>${this.parser.parseInline(e)}</em>`}codespan({text:e}){return`<code>${w(e,!0)}</code>`}br(e){return\"<br>\"}del({tokens:e}){return`<del>${this.parser.parseInline(e)}</del>`}link({href:e,title:t,tokens:n}){let r=this.parser.parseInline(n),i=V(e);if(i===null)return r;e=i;let s='<a href=\"'+e+'\"';return t&&(s+=' title=\"'+w(t)+'\"'),s+=\">\"+r+\"</a>\",s}image({href:e,title:t,text:n,tokens:r}){r&&(n=this.parser.parseInline(r,this.parser.textRenderer));let i=V(e);if(i===null)return w(n);e=i;let s=`<img src=\"${e}\" alt=\"${n}\"`;return t&&(s+=` title=\"${w(t)}\"`),s+=\">\",s}text(e){return\"tokens\"in e&&e.tokens?this.parser.parseInline(e.tokens):\"escaped\"in e&&e.escaped?e.text:w(e.text)}};var $=class{strong({text:e}){return e}em({text:e}){return e}codespan({text:e}){return e}del({text:e}){return e}html({text:e}){return e}text({text:e}){return e}link({text:e}){return\"\"+e}image({text:e}){return\"\"+e}br(){return\"\"}};var b=class l{options;renderer;textRenderer;constructor(e){this.options=e||T,this.options.renderer=this.options.renderer||new P,this.renderer=this.options.renderer,this.renderer.options=this.options,this.renderer.parser=this,this.textRenderer=new $}static parse(e,t){return new l(t).parse(e)}static parseInline(e,t){return new l(t).parseInline(e)}parse(e,t=!0){let n=\"\";for(let r=0;r<e.length;r++){let i=e[r];if(this.options.extensions?.renderers?.[i.type]){let o=i,a=this.options.extensions.renderers[o.type].call({parser:this},o);if(a!==!1||![\"space\",\"hr\",\"heading\",\"code\",\"table\",\"blockquote\",\"list\",\"html\",\"def\",\"paragraph\",\"text\"].includes(o.type)){n+=a||\"\";continue}}let s=i;switch(s.type){case\"space\":{n+=this.renderer.space(s);continue}case\"hr\":{n+=this.renderer.hr(s);continue}case\"heading\":{n+=this.renderer.heading(s);continue}case\"code\":{n+=this.renderer.code(s);continue}case\"table\":{n+=this.renderer.table(s);continue}case\"blockquote\":{n+=this.renderer.blockquote(s);continue}case\"list\":{n+=this.renderer.list(s);continue}case\"html\":{n+=this.renderer.html(s);continue}case\"def\":{n+=this.renderer.def(s);continue}case\"paragraph\":{n+=this.renderer.paragraph(s);continue}case\"text\":{let o=s,a=this.renderer.text(o);for(;r+1<e.length&&e[r+1].type===\"text\";)o=e[++r],a+=`\n`+this.renderer.text(o);t?n+=this.renderer.paragraph({type:\"paragraph\",raw:a,text:a,tokens:[{type:\"text\",raw:a,text:a,escaped:!0}]}):n+=a;continue}default:{let o='Token with \"'+s.type+'\" type was not found.';if(this.options.silent)return console.error(o),\"\";throw new Error(o)}}}return n}parseInline(e,t=this.renderer){let n=\"\";for(let r=0;r<e.length;r++){let i=e[r];if(this.options.extensions?.renderers?.[i.type]){let o=this.options.extensions.renderers[i.type].call({parser:this},i);if(o!==!1||![\"escape\",\"html\",\"link\",\"image\",\"strong\",\"em\",\"codespan\",\"br\",\"del\",\"text\"].includes(i.type)){n+=o||\"\";continue}}let s=i;switch(s.type){case\"escape\":{n+=t.text(s);break}case\"html\":{n+=t.html(s);break}case\"link\":{n+=t.link(s);break}case\"image\":{n+=t.image(s);break}case\"strong\":{n+=t.strong(s);break}case\"em\":{n+=t.em(s);break}case\"codespan\":{n+=t.codespan(s);break}case\"br\":{n+=t.br(s);break}case\"del\":{n+=t.del(s);break}case\"text\":{n+=t.text(s);break}default:{let o='Token with \"'+s.type+'\" type was not found.';if(this.options.silent)return console.error(o),\"\";throw new Error(o)}}}return n}};var S=class{options;block;constructor(e){this.options=e||T}static passThroughHooks=new Set([\"preprocess\",\"postprocess\",\"processAllTokens\",\"emStrongMask\"]);static passThroughHooksRespectAsync=new Set([\"preprocess\",\"postprocess\",\"processAllTokens\"]);preprocess(e){return e}postprocess(e){return e}processAllTokens(e){return e}emStrongMask(e){return e}provideLexer(){return this.block?x.lex:x.lexInline}provideParser(){return this.block?b.parse:b.parseInline}};var A=class{defaults=_();options=this.setOptions;parse=this.parseMarkdown(!0);parseInline=this.parseMarkdown(!1);Parser=b;Renderer=P;TextRenderer=$;Lexer=x;Tokenizer=y;Hooks=S;constructor(...e){this.use(...e)}walkTokens(e,t){let n=[];for(let r of e)switch(n=n.concat(t.call(this,r)),r.type){case\"table\":{let i=r;for(let s of i.header)n=n.concat(this.walkTokens(s.tokens,t));for(let s of i.rows)for(let o of s)n=n.concat(this.walkTokens(o.tokens,t));break}case\"list\":{let i=r;n=n.concat(this.walkTokens(i.items,t));break}default:{let i=r;this.defaults.extensions?.childTokens?.[i.type]?this.defaults.extensions.childTokens[i.type].forEach(s=>{let o=i[s].flat(1/0);n=n.concat(this.walkTokens(o,t))}):i.tokens&&(n=n.concat(this.walkTokens(i.tokens,t)))}}return n}use(...e){let t=this.defaults.extensions||{renderers:{},childTokens:{}};return e.forEach(n=>{let r={...n};if(r.async=this.defaults.async||r.async||!1,n.extensions&&(n.extensions.forEach(i=>{if(!i.name)throw new Error(\"extension name required\");if(\"renderer\"in i){let s=t.renderers[i.name];s?t.renderers[i.name]=function(...o){let a=i.renderer.apply(this,o);return a===!1&&(a=s.apply(this,o)),a}:t.renderers[i.name]=i.renderer}if(\"tokenizer\"in i){if(!i.level||i.level!==\"block\"&&i.level!==\"inline\")throw new Error(\"extension level must be 'block' or 'inline'\");let s=t[i.level];s?s.unshift(i.tokenizer):t[i.level]=[i.tokenizer],i.start&&(i.level===\"block\"?t.startBlock?t.startBlock.push(i.start):t.startBlock=[i.start]:i.level===\"inline\"&&(t.startInline?t.startInline.push(i.start):t.startInline=[i.start]))}\"childTokens\"in i&&i.childTokens&&(t.childTokens[i.name]=i.childTokens)}),r.extensions=t),n.renderer){let i=this.defaults.renderer||new P(this.defaults);for(let s in n.renderer){if(!(s in i))throw new Error(`renderer '${s}' does not exist`);if([\"options\",\"parser\"].includes(s))continue;let o=s,a=n.renderer[o],u=i[o];i[o]=(...c)=>{let p=a.apply(i,c);return p===!1&&(p=u.apply(i,c)),p||\"\"}}r.renderer=i}if(n.tokenizer){let i=this.defaults.tokenizer||new y(this.defaults);for(let s in n.tokenizer){if(!(s in i))throw new Error(`tokenizer '${s}' does not exist`);if([\"options\",\"rules\",\"lexer\"].includes(s))continue;let o=s,a=n.tokenizer[o],u=i[o];i[o]=(...c)=>{let p=a.apply(i,c);return p===!1&&(p=u.apply(i,c)),p}}r.tokenizer=i}if(n.hooks){let i=this.defaults.hooks||new S;for(let s in n.hooks){if(!(s in i))throw new Error(`hook '${s}' does not exist`);if([\"options\",\"block\"].includes(s))continue;let o=s,a=n.hooks[o],u=i[o];S.passThroughHooks.has(s)?i[o]=c=>{if(this.defaults.async&&S.passThroughHooksRespectAsync.has(s))return(async()=>{let g=await a.call(i,c);return u.call(i,g)})();let p=a.call(i,c);return u.call(i,p)}:i[o]=(...c)=>{if(this.defaults.async)return(async()=>{let g=await a.apply(i,c);return g===!1&&(g=await u.apply(i,c)),g})();let p=a.apply(i,c);return p===!1&&(p=u.apply(i,c)),p}}r.hooks=i}if(n.walkTokens){let i=this.defaults.walkTokens,s=n.walkTokens;r.walkTokens=function(o){let a=[];return a.push(s.call(this,o)),i&&(a=a.concat(i.call(this,o))),a}}this.defaults={...this.defaults,...r}}),this}setOptions(e){return this.defaults={...this.defaults,...e},this}lexer(e,t){return x.lex(e,t??this.defaults)}parser(e,t){return b.parse(e,t??this.defaults)}parseMarkdown(e){return(n,r)=>{let i={...r},s={...this.defaults,...i},o=this.onError(!!s.silent,!!s.async);if(this.defaults.async===!0&&i.async===!1)return o(new Error(\"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"));if(typeof n>\"u\"||n===null)return o(new Error(\"marked(): input parameter is undefined or null\"));if(typeof n!=\"string\")return o(new Error(\"marked(): input parameter is of type \"+Object.prototype.toString.call(n)+\", string expected\"));if(s.hooks&&(s.hooks.options=s,s.hooks.block=e),s.async)return(async()=>{let a=s.hooks?await s.hooks.preprocess(n):n,c=await(s.hooks?await s.hooks.provideLexer():e?x.lex:x.lexInline)(a,s),p=s.hooks?await s.hooks.processAllTokens(c):c;s.walkTokens&&await Promise.all(this.walkTokens(p,s.walkTokens));let d=await(s.hooks?await s.hooks.provideParser():e?b.parse:b.parseInline)(p,s);return s.hooks?await s.hooks.postprocess(d):d})().catch(o);try{s.hooks&&(n=s.hooks.preprocess(n));let u=(s.hooks?s.hooks.provideLexer():e?x.lex:x.lexInline)(n,s);s.hooks&&(u=s.hooks.processAllTokens(u)),s.walkTokens&&this.walkTokens(u,s.walkTokens);let p=(s.hooks?s.hooks.provideParser():e?b.parse:b.parseInline)(u,s);return s.hooks&&(p=s.hooks.postprocess(p)),p}catch(a){return o(a)}}}onError(e,t){return n=>{if(n.message+=`\nPlease report this to https://github.com/markedjs/marked.`,e){let r=\"<p>An error occurred:</p><pre>\"+w(n.message+\"\",!0)+\"</pre>\";return t?Promise.resolve(r):r}if(t)return Promise.reject(n);throw n}}};var L=new A;function k(l,e){return L.parse(l,e)}k.options=k.setOptions=function(l){return L.setOptions(l),k.defaults=L.defaults,N(k.defaults),k};k.getDefaults=_;k.defaults=T;k.use=function(...l){return L.use(...l),k.defaults=L.defaults,N(k.defaults),k};k.walkTokens=function(l,e){return L.walkTokens(l,e)};k.parseInline=L.parseInline;k.Parser=b;k.parser=b.parse;k.Renderer=P;k.TextRenderer=$;k.Lexer=x;k.lexer=x.lex;k.Tokenizer=y;k.Hooks=S;k.parse=k;var ot=k.options,at=k.setOptions,lt=k.use,ut=k.walkTokens,pt=k.parseInline,ct=k,ht=b.parse,dt=x.lex;\n\nif(__exports != exports)module.exports = exports;return module.exports}));\n//# sourceMappingURL=marked.umd.js.map\n","import { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { Marked } from './Instance.ts';\nimport {\n  _getDefaults,\n  changeDefaults,\n  _defaults,\n} from './defaults.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\nimport type { MaybePromise } from './Instance.ts';\n\nconst markedInstance = new Marked();\n\n/**\n * Compiles markdown to HTML asynchronously.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options, having async: true\n * @return Promise of string of compiled HTML\n */\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\n\n/**\n * Compiles markdown to HTML.\n *\n * @param src String of markdown source to be compiled\n * @param options Optional hash of options\n * @return String of compiled HTML. Will be a Promise of string if async is set to true by any extensions.\n */\nexport function marked(src: string, options: MarkedOptions & { async: false }): string;\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\nexport function marked(src: string, options?: MarkedOptions | null): string | Promise<string>;\nexport function marked(src: string, opt?: MarkedOptions | null): string | Promise<string> {\n  return markedInstance.parse(src, opt);\n}\n\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options =\nmarked.setOptions = function(options: MarkedOptions) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\n\nmarked.defaults = _defaults;\n\n/**\n * Use Extension\n */\n\nmarked.use = function(...args: MarkedExtension[]) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Run callback for every token\n */\n\nmarked.walkTokens = function(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\n\nexport const options = marked.options;\nexport const setOptions = marked.setOptions;\nexport const use = marked.use;\nexport const walkTokens = marked.walkTokens;\nexport const parseInline = marked.parseInline;\nexport const parse = marked;\nexport const parser = _Parser.parse;\nexport const lexer = _Lexer.lex;\nexport { _defaults as defaults, _getDefaults as getDefaults } from './defaults.ts';\nexport { _Lexer as Lexer } from './Lexer.ts';\nexport { _Parser as Parser } from './Parser.ts';\nexport { _Tokenizer as Tokenizer } from './Tokenizer.ts';\nexport { _Renderer as Renderer } from './Renderer.ts';\nexport { _TextRenderer as TextRenderer } from './TextRenderer.ts';\nexport { _Hooks as Hooks } from './Hooks.ts';\nexport { Marked } from './Instance.ts';\nexport type * from './MarkedOptions.ts';\nexport type * from './Tokens.ts';\n","import type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Gets the original marked default options.\n */\nexport function _getDefaults<ParserOutput = string, RendererOutput = string>(): MarkedOptions<ParserOutput, RendererOutput> {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport let _defaults: MarkedOptions<any, any> = _getDefaults();\n\nexport function changeDefaults<ParserOutput = string, RendererOutput = string>(newDefaults: MarkedOptions<ParserOutput, RendererOutput>) {\n  _defaults = newDefaults;\n}\n","const noopTest = { exec: () => null } as unknown as RegExp;\n\nfunction edit(regex: string | RegExp, opt = '') {\n  let source = typeof regex === 'string' ? regex : regex.source;\n  const obj = {\n    replace: (name: string | RegExp, val: string | RegExp) => {\n      let valSource = typeof val === 'string' ? val : val.source;\n      valSource = valSource.replace(other.caret, '$1');\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\n\nexport const other = {\n  codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n  outputLinkReplace: /\\\\([\\[\\]])/g,\n  indentCodeCompensation: /^(\\s+)(?:```)/,\n  beginningSpace: /^\\s+/,\n  endingHash: /#$/,\n  startingSpaceChar: /^ /,\n  endingSpaceChar: / $/,\n  nonSpaceChar: /[^ ]/,\n  newLineCharGlobal: /\\n/g,\n  tabCharGlobal: /\\t/g,\n  multipleSpaceGlobal: /\\s+/g,\n  blankLine: /^[ \\t]*$/,\n  doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n  blockquoteStart: /^ {0,3}>/,\n  blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n  blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n  listReplaceTabs: /^\\t+/,\n  listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n  listIsTask: /^\\[[ xX]\\] /,\n  listReplaceTask: /^\\[[ xX]\\] +/,\n  anyLine: /\\n.*\\n/,\n  hrefBrackets: /^<(.*)>$/,\n  tableDelimiter: /[:|]/,\n  tableAlignChars: /^\\||\\| *$/g,\n  tableRowBlankLine: /\\n[ \\t]*$/,\n  tableAlignRight: /^ *-+: *$/,\n  tableAlignCenter: /^ *:-+: *$/,\n  tableAlignLeft: /^ *:-+ *$/,\n  startATag: /^<a /i,\n  endATag: /^<\\/a>/i,\n  startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n  endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n  startAngleBracket: /^</,\n  endAngleBracket: />$/,\n  pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n  unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n  escapeTest: /[&<>\"']/,\n  escapeReplace: /[&<>\"']/g,\n  escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n  escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n  unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n  caret: /(^|[^\\[])\\^/g,\n  percentDecode: /%25/g,\n  findPipe: /\\|/g,\n  splitPipe: / \\|/,\n  slashPipe: /\\\\\\|/g,\n  carriageReturn: /\\r\\n|\\r/g,\n  spaceLine: /^ +$/gm,\n  notSpaceStart: /^\\S*/,\n  endingNewline: /\\n$/,\n  listItemRegex: (bull: string) => new RegExp(`^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`),\n  nextBulletRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`),\n  hrRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n  fencesBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n  headingBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n  htmlBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, 'i'),\n};\n\n/**\n * Block-Level Grammar\n */\n\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nconst lheading = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/\\|table/g, '') // table not in commonmark\n  .getRegex();\nconst lheadingGfm = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/) // table can interrupt\n  .getRegex();\nconst _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\[\\s\\S]|[^\\[\\]\\\\])+/;\nconst def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/)\n  .replace('label', _blockLabel)\n  .replace('title', /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/)\n  .getRegex();\n\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\n\nconst _tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n  + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n  + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n  + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n  + '|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title'\n  + '|tr|track|ul';\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  '^ {0,3}(?:' // optional indentation\n+ '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n+ '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n+ '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n+ '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n+ '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n+ '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (6)\n+ '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) open tag\n+ '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) closing tag\n+ ')', 'i')\n  .replace('comment', _comment)\n  .replace('tag', _tag)\n  .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst paragraph = edit(_paragraph)\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n  .replace('|table', '')\n  .replace('blockquote', ' {0,3}>')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace('paragraph', paragraph)\n  .getRegex();\n\n/**\n * Normal Block Grammar\n */\n\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n\ntype BlockKeys = keyof typeof blockNormal;\n\n/**\n * GFM Block Grammar\n */\n\nconst gfmTable = edit(\n  '^ *([^\\\\n ].*)\\\\n' // Header\n+ ' {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)' // Align\n+ '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)') // Cells\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('blockquote', ' {0,3}>')\n  .replace('code', '(?: {4}| {0,3}\\t)[^\\\\n]')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockGfm: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  lheading: lheadingGfm,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n    .replace('table', gfmTable) // interrupt paragraphs with table\n    .replace('blockquote', ' {0,3}>')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\n\nconst blockPedantic: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  html: edit(\n    '^ *(?:comment *(?:\\\\n|\\\\s*$)'\n    + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n    + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n    .replace('comment', _comment)\n    .replace(/tag/g, '(?!(?:'\n      + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n      + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n      + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' *#{1,6} *[^\\n]')\n    .replace('lheading', lheading)\n    .replace('|table', '')\n    .replace('blockquote', ' {0,3}>')\n    .replace('|fences', '')\n    .replace('|list', '')\n    .replace('|html', '')\n    .replace('|tag', '')\n    .getRegex(),\n};\n\n/**\n * Inline-Level Grammar\n */\n\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = /[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nconst punctuation = edit(/^((?![*_])punctSpace)/, 'u')\n  .replace(/punctSpace/g, _punctuationOrSpace).getRegex();\n\n// GFM allows ~ inside strong and em for strikethrough\nconst _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\n\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip = edit(/link|code|html/, 'g')\n  .replace('link', /\\[(?:[^\\[\\]`]|(?<!`)(?<a>`+)[^`]+\\k<a>(?!`))*?\\]\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)]|\\((?:\\\\[\\s\\S]|[^\\\\\\(\\)])*\\))*\\)/)\n  .replace('code', /(?<!`)(?<b>`+)[^`]+\\k<b>(?!`)/)\n  .replace('html', /<(?! )[^<>]*?>/)\n  .getRegex();\n\nconst emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\n\nconst emStrongLDelim = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongLDelimGfm = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\nconst emStrongRDelimAstCore =\n  '^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)' // Skip orphan inside strong\n+ '|[^*]+(?=[^*])' // Consume to delim\n+ '|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)' // (1) #*** can only be a Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)' // (2) a***#, a*** can only be a Right Delimiter\n+ '|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)' // (3) #***a, ***a can only be Left Delimiter\n+ '|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)' // (4) ***# can only be Left Delimiter\n+ '|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)' // (5) #***# can be either Left or Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?=notPunctSpace)'; // (6) a***a can be either Left or Right Delimiter\n\nconst emStrongRDelimAst = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm)\n  .replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm)\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  '^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)' // Skip orphan inside strong\n+ '|[^_]+(?=[^_])' // Consume to delim\n+ '|(?!_)punct(_+)(?=[\\\\s]|$)' // (1) #___ can only be a Right Delimiter\n+ '|notPunctSpace(_+)(?!_)(?=punctSpace|$)' // (2) a___#, a___ can only be a Right Delimiter\n+ '|(?!_)punctSpace(_+)(?=notPunctSpace)' // (3) #___a, ___a can only be Left Delimiter\n+ '|[\\\\s](_+)(?!_)(?=punct)' // (4) ___# can only be Left Delimiter\n+ '|(?!_)punct(_+)(?!_)(?=punct)', 'gu') // (5) #___# can be either Left or Right Delimiter\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst anyPunctuation = edit(/\\\\(punct)/, 'gu')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace('scheme', /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace('email', /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/)\n  .getRegex();\n\nconst _inlineComment = edit(_comment).replace('(?:-->|$)', '-->').getRegex();\nconst tag = edit(\n  '^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>') // CDATA section\n  .replace('comment', _inlineComment)\n  .replace('attribute', /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst _inlineLabel = /(?:\\[(?:\\\\[\\s\\S]|[^\\[\\]\\\\])*\\]|\\\\[\\s\\S]|`+[^`]*?`+(?!`)|[^\\[\\]\\\\`])*?/;\n\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/)\n  .replace('label', _inlineLabel)\n  .replace('href', /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/)\n  .replace('title', /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/)\n  .getRegex();\n\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace('label', _inlineLabel)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst reflinkSearch = edit('reflink|nolink(?!\\\\()', 'g')\n  .replace('reflink', reflink)\n  .replace('nolink', nolink)\n  .getRegex();\n\nconst _caseInsensitiveProtocol = /[hH][tT][tT][pP][sS]?|[fF][tT][pP]/;\n\n/**\n * Normal Inline Grammar\n */\n\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n\ntype InlineKeys = keyof typeof inlineNormal;\n\n/**\n * Pedantic Inline Grammar\n */\n\nconst inlinePedantic: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n};\n\n/**\n * GFM Inline Grammar\n */\n\nconst inlineGfm: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  emStrongRDelimAst: emStrongRDelimAstGfm,\n  emStrongLDelim: emStrongLDelimGfm,\n  url: edit(/^((?:protocol):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/)\n    .replace('protocol', _caseInsensitiveProtocol)\n    .replace('email', /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/)\n    .getRegex(),\n  _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])((?:\\\\[\\s\\S]|[^\\\\])*?(?:\\\\[\\s\\S]|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n  text: edit(/^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|protocol:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/)\n    .replace('protocol', _caseInsensitiveProtocol)\n    .getRegex(),\n};\n\n/**\n * GFM + Line Breaks Inline Grammar\n */\n\nconst inlineBreaks: Record<InlineKeys, RegExp> = {\n  ...inlineGfm,\n  br: edit(br).replace('{2,}', '*').getRegex(),\n  text: edit(inlineGfm.text)\n    .replace('\\\\b_', '\\\\b_| {2,}\\\\n')\n    .replace(/\\{2,\\}/g, '*')\n    .getRegex(),\n};\n\n/**\n * exports\n */\n\nexport const block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\n\nexport const inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\nexport interface Rules {\n  other: typeof other\n  block: Record<BlockKeys, RegExp>\n  inline: Record<InlineKeys, RegExp>\n}\n","import { other } from './rules.ts';\n\n/**\n * Helpers\n */\nconst escapeReplacements: { [index: string]: string } = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;',\n};\nconst getEscapeReplacement = (ch: string) => escapeReplacements[ch];\n\nexport function escape(html: string, encode?: boolean) {\n  if (encode) {\n    if (other.escapeTest.test(html)) {\n      return html.replace(other.escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (other.escapeTestNoEncode.test(html)) {\n      return html.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n\n  return html;\n}\n\nexport function unescape(html: string) {\n  // explicitly match decimal, hex, and named HTML entities\n  return html.replace(other.unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n === 'colon') return ':';\n    if (n.charAt(0) === '#') {\n      return n.charAt(1) === 'x'\n        ? String.fromCharCode(parseInt(n.substring(2), 16))\n        : String.fromCharCode(+n.substring(1));\n    }\n    return '';\n  });\n}\n\nexport function cleanUrl(href: string) {\n  try {\n    href = encodeURI(href).replace(other.percentDecode, '%');\n  } catch {\n    return null;\n  }\n  return href;\n}\n\nexport function splitCells(tableRow: string, count?: number) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === '\\\\') escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return '|';\n      } else {\n        // add space before unescaped |\n        return ' |';\n      }\n    }),\n    cells = row.split(other.splitPipe);\n  let i = 0;\n\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells.at(-1)?.trim()) {\n    cells.pop();\n  }\n\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push('');\n    }\n  }\n\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(other.slashPipe, '|');\n  }\n  return cells;\n}\n\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nexport function rtrim(str: string, c: string, invert?: boolean) {\n  const l = str.length;\n  if (l === 0) {\n    return '';\n  }\n\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n\n  return str.slice(0, l - suffLen);\n}\n\nexport function findClosingBracket(str: string, b: string) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === '\\\\') {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  if (level > 0) {\n    return -2;\n  }\n\n  return -1;\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  rtrim,\n  splitCells,\n  findClosingBracket,\n} from './helpers.ts';\nimport type { Rules } from './rules.ts';\nimport type { _Lexer } from './Lexer.ts';\nimport type { Links, Tokens, Token } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\nfunction outputLink(cap: string[], link: Pick<Tokens.Link, 'href' | 'title'>, raw: string, lexer: _Lexer, rules: Rules): Tokens.Link | Tokens.Image {\n  const href = link.href;\n  const title = link.title || null;\n  const text = cap[1].replace(rules.other.outputLinkReplace, '$1');\n\n  lexer.state.inLink = true;\n  const token: Tokens.Link | Tokens.Image = {\n    type: cap[0].charAt(0) === '!' ? 'image' : 'link',\n    raw,\n    href,\n    title,\n    text,\n    tokens: lexer.inlineTokens(text),\n  };\n  lexer.state.inLink = false;\n  return token;\n}\n\nfunction indentCodeCompensation(raw: string, text: string, rules: Rules) {\n  const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n\n  if (matchIndentToCode === null) {\n    return text;\n  }\n\n  const indentToCode = matchIndentToCode[1];\n\n  return text\n    .split('\\n')\n    .map(node => {\n      const matchIndentInNode = node.match(rules.other.beginningSpace);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n\n      const [indentInNode] = matchIndentInNode;\n\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n\n      return node;\n    })\n    .join('\\n');\n}\n\n/**\n * Tokenizer\n */\nexport class _Tokenizer<ParserOutput = string, RendererOutput = string> {\n  options: MarkedOptions<ParserOutput, RendererOutput>;\n  rules!: Rules; // set by the lexer\n  lexer!: _Lexer<ParserOutput, RendererOutput>; // set by the lexer\n\n  constructor(options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    this.options = options || _defaults;\n  }\n\n  space(src: string): Tokens.Space | undefined {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: 'space',\n        raw: cap[0],\n      };\n    }\n  }\n\n  code(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(this.rules.other.codeRemoveIndent, '');\n      return {\n        type: 'code',\n        raw: cap[0],\n        codeBlockStyle: 'indented',\n        text: !this.options.pedantic\n          ? rtrim(text, '\\n')\n          : text,\n      };\n    }\n  }\n\n  fences(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || '', this.rules);\n\n      return {\n        type: 'code',\n        raw,\n        lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, '$1') : cap[2],\n        text,\n      };\n    }\n  }\n\n  heading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n\n      // remove trailing #s\n      if (this.rules.other.endingHash.test(text)) {\n        const trimmed = rtrim(text, '#');\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  hr(src: string): Tokens.Hr | undefined {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: 'hr',\n        raw: rtrim(cap[0], '\\n'),\n      };\n    }\n  }\n\n  blockquote(src: string): Tokens.Blockquote | undefined {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], '\\n').split('\\n');\n      let raw = '';\n      let text = '';\n      const tokens: Token[] = [];\n\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (this.rules.other.blockquoteStart.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n\n        const currentRaw = currentLines.join('\\n');\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(this.rules.other.blockquoteSetextReplace, '\\n    $1')\n          .replace(this.rules.other.blockquoteSetextReplace2, '');\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n\n        const lastToken = tokens.at(-1);\n\n        if (lastToken?.type === 'code') {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === 'blockquote') {\n          // include continuation in nested blockquote\n          const oldToken = lastToken as Tokens.Blockquote;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.blockquote(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n          break;\n        } else if (lastToken?.type === 'list') {\n          // include continuation in nested list\n          const oldToken = lastToken as Tokens.List;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.list(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText.substring(tokens.at(-1)!.raw.length).split('\\n');\n          continue;\n        }\n      }\n\n      return {\n        type: 'blockquote',\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n\n  list(src: string): Tokens.List | undefined {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n\n      const list: Tokens.List = {\n        type: 'list',\n        raw: '',\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : '',\n        loose: false,\n        items: [],\n      };\n\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n\n      if (this.options.pedantic) {\n        bull = isordered ? bull : '[*+-]';\n      }\n\n      // Get next list item\n      const itemRegex = this.rules.other.listItemRegex(bull);\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = '';\n        let itemContents = '';\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n\n        if (this.rules.block.hr.test(src)) { // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n\n        raw = cap[0];\n        src = src.substring(raw.length);\n\n        let line = cap[2].split('\\n', 1)[0].replace(this.rules.other.listReplaceTabs, (t: string) => ' '.repeat(3 * t.length));\n        let nextLine = src.split('\\n', 1)[0];\n        let blankLine = !line.trim();\n\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(this.rules.other.nonSpaceChar); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n\n        if (blankLine && this.rules.other.blankLine.test(nextLine)) { // Items begin with at most one blank line\n          raw += nextLine + '\\n';\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n\n        if (!endEarly) {\n          const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n          const hrRegex = this.rules.other.hrRegex(indent);\n          const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n          const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n          const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split('\\n', 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(this.rules.other.listReplaceNesting, '  ');\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, '    ');\n            }\n\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n\n            if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) { // Dedent if possible\n              itemContents += '\\n' + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(this.rules.other.tabCharGlobal, '    ').search(this.rules.other.nonSpaceChar) >= 4) { // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n\n              itemContents += '\\n' + nextLine;\n            }\n\n            if (!blankLine && !nextLine.trim()) { // Check if current line is blank\n              blankLine = true;\n            }\n\n            raw += rawLine + '\\n';\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (this.rules.other.doubleBlankLine.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n\n        let istask: RegExpExecArray | null = null;\n        let ischecked: boolean | undefined;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = this.rules.other.listIsTask.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== '[ ] ';\n            itemContents = itemContents.replace(this.rules.other.listReplaceTask, '');\n          }\n        }\n\n        list.items.push({\n          type: 'list_item',\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n\n        list.raw += raw;\n      }\n\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      const lastItem = list.items.at(-1);\n      if (lastItem) {\n        lastItem.raw = lastItem.raw.trimEnd();\n        lastItem.text = lastItem.text.trimEnd();\n      } else {\n        // not a list since there were no items\n        return;\n      }\n      list.raw = list.raw.trimEnd();\n\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n          const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n\n      return list;\n    }\n  }\n\n  html(src: string): Tokens.HTML | undefined {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token: Tokens.HTML = {\n        type: 'html',\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style',\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n\n  def(src: string): Tokens.Def | undefined {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, '$1').replace(this.rules.inline.anyPunctuation, '$1') : '';\n      const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, '$1') : cap[3];\n      return {\n        type: 'def',\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n\n  table(src: string): Tokens.Table | undefined {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n\n    if (!this.rules.other.tableDelimiter.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(this.rules.other.tableAlignChars, '').split('|');\n    const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, '').split('\\n') : [];\n\n    const item: Tokens.Table = {\n      type: 'table',\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n\n    for (const align of aligns) {\n      if (this.rules.other.tableAlignRight.test(align)) {\n        item.align.push('right');\n      } else if (this.rules.other.tableAlignCenter.test(align)) {\n        item.align.push('center');\n      } else if (this.rules.other.tableAlignLeft.test(align)) {\n        item.align.push('left');\n      } else {\n        item.align.push(null);\n      }\n    }\n\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n\n    for (const row of rows) {\n      item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n        return {\n          text: cell,\n          tokens: this.lexer.inline(cell),\n          header: false,\n          align: item.align[i],\n        };\n      }));\n    }\n\n    return item;\n  }\n\n  lheading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[2].charAt(0) === '=' ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n\n  paragraph(src: string): Tokens.Paragraph | undefined {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text = cap[1].charAt(cap[1].length - 1) === '\\n'\n        ? cap[1].slice(0, -1)\n        : cap[1];\n      return {\n        type: 'paragraph',\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  text(src: string): Tokens.Text | undefined {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n\n  escape(src: string): Tokens.Escape | undefined {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: 'escape',\n        raw: cap[0],\n        text: cap[1],\n      };\n    }\n  }\n\n  tag(src: string): Tokens.Tag | undefined {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n\n      return {\n        type: 'html',\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n\n  link(src: string): Tokens.Link | Tokens.Image | undefined {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          return;\n        }\n\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], '()');\n        if (lastParenIndex === -2) {\n          // more open parens than closed\n          return;\n        }\n\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = '';\n        }\n      }\n      let href = cap[2];\n      let title = '';\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = this.rules.other.pedanticHrefTitle.exec(href);\n\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : '';\n      }\n\n      href = href.trim();\n      if (this.rules.other.startAngleBracket.test(href)) {\n        if (this.options.pedantic && !(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline.anyPunctuation, '$1') : href,\n        title: title ? title.replace(this.rules.inline.anyPunctuation, '$1') : title,\n      }, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  reflink(src: string, links: Links): Tokens.Link | Tokens.Image | Tokens.Text | undefined {\n    let cap;\n    if ((cap = this.rules.inline.reflink.exec(src))\n      || (cap = this.rules.inline.nolink.exec(src))) {\n      const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: 'text',\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  emStrong(src: string, maskedSrc: string, prevChar = ''): Tokens.Em | Tokens.Strong | undefined {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric)) return;\n\n    const nextChar = match[1] || match[2] || '';\n\n    if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim, rLength, delimTotal = lLength, midDelimTotal = 0;\n\n      const endReg = match[0][0] === '*' ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n\n        if (!rDelim) continue; // skip single * in __abc*abc__\n\n        rLength = [...rDelim].length;\n\n        if (match[3] || match[4]) { // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) { // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n\n        delimTotal -= rLength;\n\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: 'em',\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: 'strong',\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n\n  codespan(src: string): Tokens.Codespan | undefined {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(this.rules.other.newLineCharGlobal, ' ');\n      const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n      const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      return {\n        type: 'codespan',\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n\n  br(src: string): Tokens.Br | undefined {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: 'br',\n        raw: cap[0],\n      };\n    }\n  }\n\n  del(src: string): Tokens.Del | undefined {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: 'del',\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n\n  autolink(src: string): Tokens.Link | undefined {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[1];\n        href = 'mailto:' + text;\n      } else {\n        text = cap[1];\n        href = text;\n      }\n\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  url(src: string): Tokens.Link | undefined {\n    let cap;\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[0];\n        href = 'mailto:' + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? '';\n        } while (prevCapZero !== cap[0]);\n        text = cap[0];\n        if (cap[1] === 'www.') {\n          href = 'http://' + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  inlineText(src: string): Tokens.Text | undefined {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      const escaped = this.lexer.state.inRawBlock;\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        escaped,\n      };\n    }\n  }\n}\n","import { _Tokenizer } from './Tokenizer.ts';\nimport { _defaults } from './defaults.ts';\nimport { other, block, inline } from './rules.ts';\nimport type { Token, TokensList, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Block Lexer\n */\nexport class _Lexer<ParserOutput = string, RendererOutput = string> {\n  tokens: TokensList;\n  options: MarkedOptions<ParserOutput, RendererOutput>;\n  state: {\n    inLink: boolean;\n    inRawBlock: boolean;\n    top: boolean;\n  };\n\n  private tokenizer: _Tokenizer<ParserOutput, RendererOutput>;\n  private inlineQueue: { src: string, tokens: Token[] }[];\n\n  constructor(options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    // TokenList cannot be created in one go\n    this.tokens = [] as unknown as TokensList;\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer<ParserOutput, RendererOutput>();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n\n    const rules = {\n      other,\n      block: block.normal,\n      inline: inline.normal,\n    };\n\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n\n  /**\n   * Static Lex Method\n   */\n  static lex<ParserOutput = string, RendererOutput = string>(src: string, options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    const lexer = new _Lexer<ParserOutput, RendererOutput>(options);\n    return lexer.lex(src);\n  }\n\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline<ParserOutput = string, RendererOutput = string>(src: string, options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    const lexer = new _Lexer<ParserOutput, RendererOutput>(options);\n    return lexer.inlineTokens(src);\n  }\n\n  /**\n   * Preprocessing\n   */\n  lex(src: string) {\n    src = src.replace(other.carriageReturn, '\\n');\n\n    this.blockTokens(src, this.tokens);\n\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n\n    return this.tokens;\n  }\n\n  /**\n   * Lexing\n   */\n  blockTokens(src: string, tokens?: Token[], lastParagraphClipped?: boolean): Token[];\n  blockTokens(src: string, tokens?: TokensList, lastParagraphClipped?: boolean): TokensList;\n  blockTokens(src: string, tokens: Token[] = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(other.tabCharGlobal, '    ').replace(other.spaceLine, '');\n    }\n\n    while (src) {\n      let token: Tokens.Generic | undefined;\n\n      if (this.options.extensions?.block?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // newline\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.raw.length === 1 && lastToken !== undefined) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          lastToken.raw += '\\n';\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        // An indented code block cannot interrupt a paragraph.\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += (lastToken.raw.endsWith('\\n') ? '' : '\\n') + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // fences\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // heading\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // hr\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // blockquote\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // list\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // html\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // def\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += (lastToken.raw.endsWith('\\n') ? '' : '\\n') + token.raw;\n          lastToken.text += '\\n' + token.raw;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // table (gfm)\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // lheading\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        const lastToken = tokens.at(-1);\n        if (lastParagraphClipped && lastToken?.type === 'paragraph') {\n          lastToken.raw += (lastToken.raw.endsWith('\\n') ? '' : '\\n') + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n\n      // text\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += (lastToken.raw.endsWith('\\n') ? '' : '\\n') + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    this.state.top = true;\n    return tokens;\n  }\n\n  inline(src: string, tokens: Token[] = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src: string, tokens: Token[] = []): Token[] {\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match: RegExpExecArray | null = null;\n\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index)\n              + '[' + 'a'.repeat(match[0].length - 2) + ']'\n              + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    }\n\n    // Mask out escaped characters\n    while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n\n    // Mask out other blocks\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n\n    // Mask out blocks from extensions\n    maskedSrc = this.options.hooks?.emStrongMask?.call({ lexer: this }, maskedSrc) ?? maskedSrc;\n\n    let keepPrevChar = false;\n    let prevChar = '';\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = '';\n      }\n      keepPrevChar = false;\n\n      let token: Tokens.Generic | undefined;\n\n      // extensions\n      if (this.options.extensions?.inline?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // escape\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // tag\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // link\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // reflink, nolink\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.type === 'text' && lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // em & strong\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // br\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // del (gfm)\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // autolink\n      if (token = this.tokenizer.autolink(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (token = this.tokenizer.inlineText(cutSrc)) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== '_') { // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    return tokens;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  cleanUrl,\n  escape,\n} from './helpers.ts';\nimport { other } from './rules.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Tokens } from './Tokens.ts';\nimport type { _Parser } from './Parser.ts';\n\n/**\n * Renderer\n */\nexport class _Renderer<ParserOutput = string, RendererOutput = string> {\n  options: MarkedOptions<ParserOutput, RendererOutput>;\n  parser!: _Parser<ParserOutput, RendererOutput>; // set by the parser\n  constructor(options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    this.options = options || _defaults;\n  }\n\n  space(token: Tokens.Space): RendererOutput {\n    return '' as RendererOutput;\n  }\n\n  code({ text, lang, escaped }: Tokens.Code): RendererOutput {\n    const langString = (lang || '').match(other.notSpaceStart)?.[0];\n\n    const code = text.replace(other.endingNewline, '') + '\\n';\n\n    if (!langString) {\n      return '<pre><code>'\n        + (escaped ? code : escape(code, true))\n        + '</code></pre>\\n' as RendererOutput;\n    }\n\n    return '<pre><code class=\"language-'\n      + escape(langString)\n      + '\">'\n      + (escaped ? code : escape(code, true))\n      + '</code></pre>\\n' as RendererOutput;\n  }\n\n  blockquote({ tokens }: Tokens.Blockquote): RendererOutput {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n` as RendererOutput;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  def(token: Tokens.Def): RendererOutput {\n    return '' as RendererOutput;\n  }\n\n  heading({ tokens, depth }: Tokens.Heading): RendererOutput {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n` as RendererOutput;\n  }\n\n  hr(token: Tokens.Hr): RendererOutput {\n    return '<hr>\\n' as RendererOutput;\n  }\n\n  list(token: Tokens.List): RendererOutput {\n    const ordered = token.ordered;\n    const start = token.start;\n\n    let body = '';\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n\n    const type = ordered ? 'ol' : 'ul';\n    const startAttr = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n    return '<' + type + startAttr + '>\\n' + body + '</' + type + '>\\n' as RendererOutput;\n  }\n\n  listitem(item: Tokens.ListItem): RendererOutput {\n    let itemBody = '';\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens[0]?.type === 'paragraph') {\n          item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n          if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n            item.tokens[0].tokens[0].text = checkbox + ' ' + escape(item.tokens[0].tokens[0].text);\n            item.tokens[0].tokens[0].escaped = true;\n          }\n        } else {\n          item.tokens.unshift({\n            type: 'text',\n            raw: checkbox + ' ',\n            text: checkbox + ' ',\n            escaped: true,\n          });\n        }\n      } else {\n        itemBody += checkbox + ' ';\n      }\n    }\n\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n\n    return `<li>${itemBody}</li>\\n` as RendererOutput;\n  }\n\n  checkbox({ checked }: Tokens.Checkbox): RendererOutput {\n    return '<input '\n      + (checked ? 'checked=\"\" ' : '')\n      + 'disabled=\"\" type=\"checkbox\">' as RendererOutput;\n  }\n\n  paragraph({ tokens }: Tokens.Paragraph): RendererOutput {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n` as RendererOutput;\n  }\n\n  table(token: Tokens.Table): RendererOutput {\n    let header = '';\n\n    // header\n    let cell = '';\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell as ParserOutput });\n\n    let body = '';\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n\n      cell = '';\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n\n      body += this.tablerow({ text: cell as ParserOutput });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n\n    return '<table>\\n'\n      + '<thead>\\n'\n      + header\n      + '</thead>\\n'\n      + body\n      + '</table>\\n' as RendererOutput;\n  }\n\n  tablerow({ text }: Tokens.TableRow<ParserOutput>): RendererOutput {\n    return `<tr>\\n${text}</tr>\\n` as RendererOutput;\n  }\n\n  tablecell(token: Tokens.TableCell): RendererOutput {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? 'th' : 'td';\n    const tag = token.align\n      ? `<${type} align=\"${token.align}\">`\n      : `<${type}>`;\n    return tag + content + `</${type}>\\n` as RendererOutput;\n  }\n\n  /**\n   * span level renderer\n   */\n  strong({ tokens }: Tokens.Strong): RendererOutput {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>` as RendererOutput;\n  }\n\n  em({ tokens }: Tokens.Em): RendererOutput {\n    return `<em>${this.parser.parseInline(tokens)}</em>` as RendererOutput;\n  }\n\n  codespan({ text }: Tokens.Codespan): RendererOutput {\n    return `<code>${escape(text, true)}</code>` as RendererOutput;\n  }\n\n  br(token: Tokens.Br): RendererOutput {\n    return '<br>' as RendererOutput;\n  }\n\n  del({ tokens }: Tokens.Del): RendererOutput {\n    return `<del>${this.parser.parseInline(tokens)}</del>` as RendererOutput;\n  }\n\n  link({ href, title, tokens }: Tokens.Link): RendererOutput {\n    const text = this.parser.parseInline(tokens) as string;\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text as RendererOutput;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + (escape(title)) + '\"';\n    }\n    out += '>' + text + '</a>';\n    return out as RendererOutput;\n  }\n\n  image({ href, title, text, tokens }: Tokens.Image): RendererOutput {\n    if (tokens) {\n      text = this.parser.parseInline(tokens, this.parser.textRenderer) as string;\n    }\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return escape(text) as RendererOutput;\n    }\n    href = cleanHref;\n\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${escape(title)}\"`;\n    }\n    out += '>';\n    return out as RendererOutput;\n  }\n\n  text(token: Tokens.Text | Tokens.Escape): RendererOutput {\n    return 'tokens' in token && token.tokens\n      ? this.parser.parseInline(token.tokens) as unknown as RendererOutput\n      : ('escaped' in token && token.escaped ? token.text as RendererOutput : escape(token.text) as RendererOutput);\n  }\n}\n","import type { Tokens } from './Tokens.ts';\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nexport class _TextRenderer<RendererOutput = string> {\n  // no need for block level renderers\n  strong({ text }: Tokens.Strong): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  em({ text }: Tokens.Em): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  codespan({ text }: Tokens.Codespan): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  del({ text }: Tokens.Del): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  text({ text }: Tokens.Text | Tokens.Escape | Tokens.Tag): RendererOutput {\n    return text as RendererOutput;\n  }\n\n  link({ text }: Tokens.Link): RendererOutput {\n    return '' + text as RendererOutput;\n  }\n\n  image({ text }: Tokens.Image): RendererOutput {\n    return '' + text as RendererOutput;\n  }\n\n  br(): RendererOutput {\n    return '' as RendererOutput;\n  }\n}\n","import { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _defaults } from './defaults.ts';\nimport type { MarkedToken, Token, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Parsing & Compiling\n */\nexport class _Parser<ParserOutput = string, RendererOutput = string> {\n  options: MarkedOptions<ParserOutput, RendererOutput>;\n  renderer: _Renderer<ParserOutput, RendererOutput>;\n  textRenderer: _TextRenderer<RendererOutput>;\n  constructor(options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer<ParserOutput, RendererOutput>();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer<RendererOutput>();\n  }\n\n  /**\n   * Static Parse Method\n   */\n  static parse<ParserOutput = string, RendererOutput = string>(tokens: Token[], options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    const parser = new _Parser<ParserOutput, RendererOutput>(options);\n    return parser.parse(tokens);\n  }\n\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline<ParserOutput = string, RendererOutput = string>(tokens: Token[], options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    const parser = new _Parser<ParserOutput, RendererOutput>(options);\n    return parser.parseInline(tokens);\n  }\n\n  /**\n   * Parse Loop\n   */\n  parse(tokens: Token[], top = true): ParserOutput {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const genericToken = anyToken as Tokens.Generic;\n        const ret = this.options.extensions.renderers[genericToken.type].call({ parser: this }, genericToken);\n        if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'def', 'paragraph', 'text'].includes(genericToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'space': {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case 'hr': {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case 'heading': {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case 'code': {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case 'table': {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case 'blockquote': {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case 'list': {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case 'html': {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case 'def': {\n          out += this.renderer.def(token);\n          continue;\n        }\n        case 'paragraph': {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case 'text': {\n          let textToken = token;\n          let body = this.renderer.text(textToken) as string;\n          while (i + 1 < tokens.length && tokens[i + 1].type === 'text') {\n            textToken = tokens[++i] as Tokens.Text;\n            body += ('\\n' + this.renderer.text(textToken));\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: 'paragraph',\n              raw: body,\n              text: body,\n              tokens: [{ type: 'text', raw: body, text: body, escaped: true }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '' as ParserOutput;\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n\n    return out as ParserOutput;\n  }\n\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens: Token[], renderer: _Renderer<ParserOutput, RendererOutput> | _TextRenderer<RendererOutput> = this.renderer): ParserOutput {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const ret = this.options.extensions.renderers[anyToken.type].call({ parser: this }, anyToken);\n        if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(anyToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'escape': {\n          out += renderer.text(token);\n          break;\n        }\n        case 'html': {\n          out += renderer.html(token);\n          break;\n        }\n        case 'link': {\n          out += renderer.link(token);\n          break;\n        }\n        case 'image': {\n          out += renderer.image(token);\n          break;\n        }\n        case 'strong': {\n          out += renderer.strong(token);\n          break;\n        }\n        case 'em': {\n          out += renderer.em(token);\n          break;\n        }\n        case 'codespan': {\n          out += renderer.codespan(token);\n          break;\n        }\n        case 'br': {\n          out += renderer.br(token);\n          break;\n        }\n        case 'del': {\n          out += renderer.del(token);\n          break;\n        }\n        case 'text': {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '' as ParserOutput;\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out as ParserOutput;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\n\nexport class _Hooks<ParserOutput = string, RendererOutput = string> {\n  options: MarkedOptions<ParserOutput, RendererOutput>;\n  block?: boolean;\n\n  constructor(options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    this.options = options || _defaults;\n  }\n\n  static passThroughHooks = new Set([\n    'preprocess',\n    'postprocess',\n    'processAllTokens',\n    'emStrongMask',\n  ]);\n\n  static passThroughHooksRespectAsync = new Set([\n    'preprocess',\n    'postprocess',\n    'processAllTokens',\n  ]);\n\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown: string) {\n    return markdown;\n  }\n\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html: ParserOutput) {\n    return html;\n  }\n\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens: Token[] | TokensList) {\n    return tokens;\n  }\n\n  /**\n   * Mask contents that should not be interpreted as em/strong delimiters\n   */\n  emStrongMask(src: string) {\n    return src;\n  }\n\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse<ParserOutput, RendererOutput> : _Parser.parseInline<ParserOutput, RendererOutput>;\n  }\n}\n","import { _getDefaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { escape } from './helpers.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, Tokens, TokensList } from './Tokens.ts';\n\nexport type MaybePromise = void | Promise<void>;\n\ntype UnknownFunction = (...args: unknown[]) => unknown;\ntype GenericRendererFunction = (...args: unknown[]) => string | false;\n\nexport class Marked<ParserOutput = string, RendererOutput = string> {\n  defaults = _getDefaults<ParserOutput, RendererOutput>();\n  options = this.setOptions;\n\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n\n  Parser = _Parser<ParserOutput, RendererOutput>;\n  Renderer = _Renderer<ParserOutput, RendererOutput>;\n  TextRenderer = _TextRenderer<RendererOutput>;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer<ParserOutput, RendererOutput>;\n  Hooks = _Hooks<ParserOutput, RendererOutput>;\n\n  constructor(...args: MarkedExtension<ParserOutput, RendererOutput>[]) {\n    this.use(...args);\n  }\n\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n    let values: MaybePromise[] = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case 'table': {\n          const tableToken = token as Tokens.Table;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case 'list': {\n          const listToken = token as Tokens.List;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token as Tokens.Generic;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach((childTokens) => {\n              const tokens = genericToken[childTokens].flat(Infinity) as Token[] | TokensList;\n              values = values.concat(this.walkTokens(tokens, callback));\n            });\n          } else if (genericToken.tokens) {\n            values = values.concat(this.walkTokens(genericToken.tokens, callback));\n          }\n        }\n      }\n    }\n    return values;\n  }\n\n  use(...args: MarkedExtension<ParserOutput, RendererOutput>[]) {\n    const extensions: MarkedOptions<ParserOutput, RendererOutput>['extensions'] = this.defaults.extensions || { renderers: {}, childTokens: {} };\n\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack } as MarkedOptions<ParserOutput, RendererOutput>;\n\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error('extension name required');\n          }\n          if ('renderer' in ext) { // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function(...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if ('tokenizer' in ext) { // Tokenizer Extensions\n            if (!ext.level || (ext.level !== 'block' && ext.level !== 'inline')) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) { // Function to check for start of token\n              if (ext.level === 'block') {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === 'inline') {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if ('childTokens' in ext && ext.childTokens) { // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer<ParserOutput, RendererOutput>(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if (['options', 'parser'].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop as Exclude<keyof _Renderer<ParserOutput, RendererOutput>, 'options' | 'parser'>;\n          const rendererFunc = pack.renderer[rendererProp] as GenericRendererFunction;\n          const prevRenderer = renderer[rendererProp] as GenericRendererFunction;\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args: unknown[]) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return (ret || '') as RendererOutput;\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer = this.defaults.tokenizer || new _Tokenizer<ParserOutput, RendererOutput>(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if (['options', 'rules', 'lexer'].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop as Exclude<keyof _Tokenizer<ParserOutput, RendererOutput>, 'options' | 'rules' | 'lexer'>;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp] as UnknownFunction;\n          const prevTokenizer = tokenizer[tokenizerProp] as UnknownFunction;\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args: unknown[]) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks<ParserOutput, RendererOutput>();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if (['options', 'block'].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop as Exclude<keyof _Hooks<ParserOutput, RendererOutput>, 'options' | 'block'>;\n          const hooksFunc = pack.hooks[hooksProp] as UnknownFunction;\n          const prevHook = hooks[hooksProp] as UnknownFunction;\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg: unknown) => {\n              if (this.defaults.async && _Hooks.passThroughHooksRespectAsync.has(prop)) {\n                return (async() => {\n                  const ret = await hooksFunc.call(hooks, arg);\n                  return prevHook.call(hooks, ret);\n                })();\n              }\n\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args: unknown[]) => {\n              if (this.defaults.async) {\n                return (async() => {\n                  let ret = await hooksFunc.apply(hooks, args);\n                  if (ret === false) {\n                    ret = await prevHook.apply(hooks, args);\n                  }\n                  return ret;\n                })();\n              }\n\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function(token) {\n          let values: MaybePromise[] = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n\n      this.defaults = { ...this.defaults, ...opts };\n    });\n\n    return this;\n  }\n\n  setOptions(opt: MarkedOptions<ParserOutput, RendererOutput>) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n\n  lexer(src: string, options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n\n  parser(tokens: Token[], options?: MarkedOptions<ParserOutput, RendererOutput>) {\n    return _Parser.parse<ParserOutput, RendererOutput>(tokens, options ?? this.defaults);\n  }\n\n  private parseMarkdown(blockType: boolean) {\n    type overloadedParse = {\n      (src: string, options: MarkedOptions<ParserOutput, RendererOutput> & { async: true }): Promise<ParserOutput>;\n      (src: string, options: MarkedOptions<ParserOutput, RendererOutput> & { async: false }): ParserOutput;\n      (src: string, options?: MarkedOptions<ParserOutput, RendererOutput> | null): ParserOutput | Promise<ParserOutput>;\n    };\n\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse: overloadedParse = (src: string, options?: MarkedOptions<ParserOutput, RendererOutput> | null): any => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(new Error('marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.'));\n      }\n\n      // throw error in case of non string input\n      if (typeof src === 'undefined' || src === null) {\n        return throwError(new Error('marked(): input parameter is undefined or null'));\n      }\n      if (typeof src !== 'string') {\n        return throwError(new Error('marked(): input parameter is of type '\n          + Object.prototype.toString.call(src) + ', string expected'));\n      }\n\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n\n      if (opt.async) {\n        return (async() => {\n          const processedSrc = opt.hooks ? await opt.hooks.preprocess(src) : src;\n          const lexer = opt.hooks ? await opt.hooks.provideLexer() : (blockType ? _Lexer.lex : _Lexer.lexInline);\n          const tokens = await lexer(processedSrc, opt);\n          const processedTokens = opt.hooks ? await opt.hooks.processAllTokens(tokens) : tokens;\n          if (opt.walkTokens) {\n            await Promise.all(this.walkTokens(processedTokens, opt.walkTokens));\n          }\n          const parser = opt.hooks ? await opt.hooks.provideParser() : (blockType ? _Parser.parse : _Parser.parseInline);\n          const html = await parser(processedTokens, opt);\n          return opt.hooks ? await opt.hooks.postprocess(html) : html;\n        })().catch(throwError);\n      }\n\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src) as string;\n        }\n        const lexer = opt.hooks ? opt.hooks.provideLexer() : (blockType ? _Lexer.lex : _Lexer.lexInline);\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        const parser = opt.hooks ? opt.hooks.provideParser() : (blockType ? _Parser.parse : _Parser.parseInline);\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html);\n        }\n        return html;\n      } catch(e) {\n        return throwError(e as Error);\n      }\n    };\n\n    return parse;\n  }\n\n  private onError(silent: boolean, async: boolean) {\n    return (e: Error): string | Promise<string> => {\n      e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n\n      if (silent) {\n        const msg = '<p>An error occurred:</p><pre>'\n          + escape(e.message + '', true)\n          + '</pre>';\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n"],"names":["$d55025bea272cdc1$exports","globalThis","self","f","module1","exports","G","Object","defineProperty","Re","getOwnPropertyDescriptor","Te","getOwnPropertyNames","Oe","prototype","hasOwnProperty","kt","e","Hooks","S","Lexer","x","Marked","A","Parser","b","Renderer","P","TextRenderer","$","Tokenizer","y","defaults","T","getDefaults","_","lexer","dt","marked","k","options","ot","parse","ct","parseInline","pt","parser","ht","setOptions","at","use","lt","walkTokens","ut","t","get","enumerable","async","breaks","extensions","gfm","hooks","pedantic","renderer","silent","tokenizer","ye","l","n","r","call","value","E","exec","h","source","replace","i","s","m","caret","getRegex","RegExp","codeRemoveIndent","outputLinkReplace","indentCodeCompensation","beginningSpace","endingHash","startingSpaceChar","endingSpaceChar","nonSpaceChar","newLineCharGlobal","tabCharGlobal","multipleSpaceGlobal","blankLine","doubleBlankLine","blockquoteStart","blockquoteSetextReplace","blockquoteSetextReplace2","listReplaceTabs","listReplaceNesting","listIsTask","listReplaceTask","anyLine","hrefBrackets","tableDelimiter","tableAlignChars","tableRowBlankLine","tableAlignRight","tableAlignCenter","tableAlignLeft","startATag","endATag","startPreScriptTag","endPreScriptTag","startAngleBracket","endAngleBracket","pedanticHrefTitle","unicodeAlphaNumeric","escapeTest","escapeReplace","escapeTestNoEncode","escapeReplaceNoEncode","unescapeTest","percentDecode","findPipe","splitPipe","slashPipe","carriageReturn","spaceLine","notSpaceStart","endingNewline","listItemRegex","nextBulletRegex","Math","min","hrRegex","fencesBeginRegex","headingBeginRegex","htmlBeginRegex","C","j","oe","ae","Me","Q","U","Ae","Ie","v","K","Ee","le","W","blockquote","code","def","fences","heading","hr","html","lheading","list","newline","paragraph","table","text","se","Be","qe","ue","D","X","pe","Ze","ce","Fe","he","je","Qe","de","Ue","Ke","We","Xe","Je","Ve","Ye","q","et","ke","ge","tt","ie","J","_backpedal","anyPunctuation","autolink","blockSkip","br","del","emStrongLDelim","emStrongRDelimAst","emStrongRDelimUnd","escape","link","nolink","punctuation","reflink","reflinkSearch","tag","url","nt","F","rt","B","normal","M","st","fe","w","test","V","encodeURI","Y","o","a","u","split","trim","shift","length","pop","splice","push","z","charAt","slice","xe","href","title","other","state","inLink","type","raw","tokens","inlineTokens","rules","space","block","codeBlockStyle","it","match","map","join","lang","inline","depth","c","p","g","top","blockTokens","d","R","O","substring","ordered","start","loose","items","H","repeat","trimStart","search","te","ne","re","be","Z","I","ee","task","checked","trimEnd","filter","some","pre","toLowerCase","header","align","rows","inRawBlock","me","indexOf","emStrong","lastIndex","index","codespan","inlineText","escaped","inlineQueue","links","create","lex","lexInline","src","endsWith","startBlock","forEach","charCodeAt","console","error","Error","keys","includes","lastIndexOf","emStrongMask","startInline","listitem","checkbox","unshift","tablecell","tablerow","strong","em","image","textRenderer","renderers","passThroughHooks","Set","passThroughHooksRespectAsync","preprocess","postprocess","processAllTokens","provideLexer","provideParser","parseMarkdown","concat","childTokens","flat","name","apply","level","has","onError","toString","Promise","all","catch","message","resolve","reject","L","$63a51ab81e297f22$var$cvMd","document","getElementById","innerHTML","marked_exports","__export","_Hooks","_Lexer","_Parser","_Renderer","_TextRenderer","_Tokenizer","_defaults","_getDefaults","__toCommonJS","changeDefaults","newDefaults","noopTest","edit","regex","opt","obj","val","valSource","bull","indent","blockCode","bullet","lheadingCore","lheadingGfm","_paragraph","blockText","_blockLabel","_tag","_comment","blockNormal","gfmTable","blockGfm","blockPedantic","inlineCode","_punctuation","_punctuationOrSpace","_notPunctuationOrSpace","_punctuationGfmStrongEm","_punctuationOrSpaceGfmStrongEm","_notPunctuationOrSpaceGfmStrongEm","emStrongLDelimCore","emStrongLDelimGfm","emStrongRDelimAstCore","emStrongRDelimAstGfm","_inlineComment","_inlineLabel","_caseInsensitiveProtocol","inlineNormal","inlinePedantic","inlineGfm","inlineBreaks","escapeReplacements","getEscapeReplacement","ch","encode","cleanUrl","splitCells","tableRow","count","row","offset","str","curr","cells","rtrim","invert","suffLen","currChar","findClosingBracket","outputLink","cap","token","matchIndentToCode","indentToCode","node","matchIndentInNode","indentInNode","trimmed","lines","inBlockquote","currentLines","currentRaw","currentText","lastToken","oldToken","newText","newToken","isordered","itemRegex","endsWithBlankLine","endEarly","itemContents","line","nextLine","rawLine","nextLineWithoutTabs","istask","ischecked","lastItem","spacers","hasMultipleLineBreaks","headers","aligns","item","cell","trimmedUrl","rtrimSlash","lastParenIndex","linkLen","linkString","maskedSrc","prevChar","lLength","rDelim","rLength","delimTotal","midDelimTotal","endReg","lastCharLength","hasNonSpaceChars","hasSpaceCharsOnBothEnds","prevCapZero","__Lexer","next","lastParagraphClipped","extTokenizer","cutSrc","startIndex","tempSrc","tempStart","getStartIndex","errMsg","keepPrevChar","langString","body","startAttr","itemBody","content","cleanHref","out","__Parser","anyToken","genericToken","ret","textToken","markdown","args","callback","values","tableToken","listToken","pack","opts","ext","prevRenderer","extLevel","prop","rendererProp","rendererFunc","tokenizerProp","tokenizerFunc","prevTokenizer","hooksProp","hooksFunc","prevHook","arg","packWalktokens","blockType","origOpt","throwError","processedSrc","processedTokens","msg","markedInstance"],"version":3,"file":"cv.6514e68f.js.map"}